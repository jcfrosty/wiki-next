{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Sabayon Linux Wiki Sabayon Linux is based on the source-based distro named Gentoo . Gentoo is a highly customizable distro and, using Gentoo's excellent development techniques, we have created a pre-configured distribution with the tenets of Performance, Versatility, and Stability. Sabayon is a rolling release, install once and stay current with entropy package manager. Sabayon offers different repos, from stability to testing and even community repos. You can create your own personal repo to use for yourself or share with the rest of the community. We are starting a fresh wiki and need your help with rebuilding material to help the Community Help by Contributing Wiki IRC and Testing Features .tg {border-collapse:collapse;border-spacing:0;border:none;border-color:#999;} .tg td{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg th{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg .tg-0lax{text-align:left;vertical-align:top} - Multiple Supported Repos - Community Repos - Personal Repos - Rolling Release - Binary - Source - Desktop - Server - Build Your Own Spin - Run From USB - Calamares Installer - Multiple Desktop Environments Site Index .tg {border-collapse:collapse;border-spacing:0;border:none;border-color:#999;} .tg td{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#fff;} .tg th{font-size:20px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg .tg-0lax{text-align:left;vertical-align:top} Development Social Services About us Blog Gitter Github Portage Overlay Forum Chat Facebook Google+ Donate - Contact Us Pastebin Mailing List Releases Archive Wiki Mirrors Bugs Press Documentation","title":"Home"},{"location":"#sabayon-linux-wiki","text":"Sabayon Linux is based on the source-based distro named Gentoo . Gentoo is a highly customizable distro and, using Gentoo's excellent development techniques, we have created a pre-configured distribution with the tenets of Performance, Versatility, and Stability. Sabayon is a rolling release, install once and stay current with entropy package manager. Sabayon offers different repos, from stability to testing and even community repos. You can create your own personal repo to use for yourself or share with the rest of the community. We are starting a fresh wiki and need your help with rebuilding material to help the Community","title":"Sabayon Linux Wiki"},{"location":"#help-by-contributing","text":"Wiki IRC and Testing","title":"Help by Contributing"},{"location":"#features","text":".tg {border-collapse:collapse;border-spacing:0;border:none;border-color:#999;} .tg td{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg th{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg .tg-0lax{text-align:left;vertical-align:top} - Multiple Supported Repos - Community Repos - Personal Repos - Rolling Release - Binary - Source - Desktop - Server - Build Your Own Spin - Run From USB - Calamares Installer - Multiple Desktop Environments","title":"Features"},{"location":"#site-index","text":".tg {border-collapse:collapse;border-spacing:0;border:none;border-color:#999;} .tg td{font-size:18px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#fff;} .tg th{font-size:20px;font-weight:normal;padding:0px 5px;border-style:solid;border-width:0px;overflow:hidden;word-break:normal;border-color:#999;color:#000;background-color:#fff;} .tg .tg-0lax{text-align:left;vertical-align:top} Development Social Services About us Blog Gitter Github Portage Overlay Forum Chat Facebook Google+ Donate - Contact Us Pastebin Mailing List Releases Archive Wiki Mirrors Bugs Press Documentation","title":"Site Index"},{"location":"articles/DEV_DebuggingSymbols/","text":"Enabling Debugging Symbols Packages are, by default, installed without debugging symbols in Sabayon. This saves space, specially for users that are not developers and are not interested in debugging applications. But for those of us who are developers, finding the debug symbols of Entropy packages can come in handy. To do so, change the value of the splitdebug variable to enable in /etc/entropy/client.conf # Enable the installation of debug files # Also known as \"splitdebug\" support # Valid parameters: disable, enable, true, false, disabled, enabled, 0, 1 # Default parameter if unset: disable splitdebug = enable # HOW SPLITDEBUG WORKS with Entropy # Once you enable the \"splitdebug\" feature # you just need to (re)install packages in order to # get /usr/lib/debug metadata files installed. That's it. # You can safely remove /usr/lib/debug without affecting # Operating System functionality, at any time. After modifying this, next time you install a package, you will also get debug symbols installed inside /usr/lib/debug . For example, if you run equo install networkmanager you will get the following debugging files: ### /usr/lib/debug ### /usr/lib/debug/usr ### /usr/lib/debug/usr/bin ### /usr/lib/debug/usr/bin/nm-online.debug ### /usr/lib/debug/usr/bin/nm-tool.debug ### /usr/lib/debug/usr/bin/nmcli.debug ### /usr/lib/debug/usr/lib ### /usr/lib/debug/usr/lib/NetworkManager ### /usr/lib/debug/usr/lib/NetworkManager/libnm-settings-plugin-ifnet.so.debug ### /usr/lib/debug/usr/lib/libnm-glib-vpn.so.1.1.0.debug ### /usr/lib/debug/usr/lib/libnm-glib.so.4.2.0.debug ### /usr/lib/debug/usr/lib/libnm-util.so.2.1.0.debug ### /usr/lib/debug/usr/lib/pppd ### /usr/lib/debug/usr/lib/pppd/2.4.5 ### /usr/lib/debug/usr/lib/pppd/2.4.5/nm-pppd-plugin.so.debug ### /usr/lib/debug/usr/libexec ### /usr/lib/debug/usr/libexec/nm-avahi-autoipd.action.debug ### /usr/lib/debug/usr/libexec/nm-crash-logger.debug ### /usr/lib/debug/usr/libexec/nm-dhcp-client.action.debug ### /usr/lib/debug/usr/libexec/nm-dispatcher.action.debug ### /usr/lib/debug/usr/sbin ### /usr/lib/debug/usr/sbin/NetworkManager.debug glibc missing debug info The following two problems may be resolved by adding debug symbols for the package sys-libs/glibc . GDB: libpthread library mismatch with libthread_db If there is no debug symbols for libpthread library, GDB will not directly say that there is no debugging symbols for libpthread, instead, whenever you start GDB, it will show below warning, warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available. See this [http://bugs.sabayon.org/show_bug.cgi?id=3316] link for more information. Valgrind: Needs a non-stripped LD When executing valgrind with no option in particular (for example: valgrind /bin/true ) you may get the following error message: valgrind: Fatal error at startup: a function redirection valgrind: which is mandatory for this platform-tool combination valgrind: cannot be set up. Details of the redirection are: valgrind: valgrind: A must-be-redirected function valgrind: whose name matches the pattern: strlen valgrind: in an object with soname matching: ld-linux-x86-64.so.2 valgrind: was not found whilst processing valgrind: symbols from the object with soname: ld-linux-x86-64.so.2 valgrind: valgrind: Possible fixes: (1, short term): install glibc's debuginfo valgrind: package on this machine. (2, longer term): ask the packagers valgrind: for your Linux distribution to please in future ship a non- valgrind: stripped ld.so (or whatever the dynamic linker .so is called) valgrind: that exports the above-named function using the standard valgrind: calling conventions for this platform. The package you need valgrind: to install for fix (1) is called valgrind: valgrind: On Debian, Ubuntu: libc6-dbg valgrind: On SuSE, openSuSE, Fedora, RHEL: glibc-debuginfo valgrind: valgrind: Note that if you are debugging a 32 bit process on a valgrind: 64 bit system, you will need a corresponding 32 bit debuginfo valgrind: package (e.g. libc6-dbg:i386). valgrind: valgrind: Cannot continue -- exiting now. Sorry. Resolution To fix both these issues, just enable splitdebug inside /etc/entropy/client.conf and reinstall sys-libs/glibc package. # equo install sys-libs/glibc There is no need to reboot the system or restart anything.","title":"Enabling Debugging Symbols"},{"location":"articles/DEV_DebuggingSymbols/#enabling-debugging-symbols","text":"Packages are, by default, installed without debugging symbols in Sabayon. This saves space, specially for users that are not developers and are not interested in debugging applications. But for those of us who are developers, finding the debug symbols of Entropy packages can come in handy. To do so, change the value of the splitdebug variable to enable in /etc/entropy/client.conf # Enable the installation of debug files # Also known as \"splitdebug\" support # Valid parameters: disable, enable, true, false, disabled, enabled, 0, 1 # Default parameter if unset: disable splitdebug = enable # HOW SPLITDEBUG WORKS with Entropy # Once you enable the \"splitdebug\" feature # you just need to (re)install packages in order to # get /usr/lib/debug metadata files installed. That's it. # You can safely remove /usr/lib/debug without affecting # Operating System functionality, at any time. After modifying this, next time you install a package, you will also get debug symbols installed inside /usr/lib/debug . For example, if you run equo install networkmanager you will get the following debugging files: ### /usr/lib/debug ### /usr/lib/debug/usr ### /usr/lib/debug/usr/bin ### /usr/lib/debug/usr/bin/nm-online.debug ### /usr/lib/debug/usr/bin/nm-tool.debug ### /usr/lib/debug/usr/bin/nmcli.debug ### /usr/lib/debug/usr/lib ### /usr/lib/debug/usr/lib/NetworkManager ### /usr/lib/debug/usr/lib/NetworkManager/libnm-settings-plugin-ifnet.so.debug ### /usr/lib/debug/usr/lib/libnm-glib-vpn.so.1.1.0.debug ### /usr/lib/debug/usr/lib/libnm-glib.so.4.2.0.debug ### /usr/lib/debug/usr/lib/libnm-util.so.2.1.0.debug ### /usr/lib/debug/usr/lib/pppd ### /usr/lib/debug/usr/lib/pppd/2.4.5 ### /usr/lib/debug/usr/lib/pppd/2.4.5/nm-pppd-plugin.so.debug ### /usr/lib/debug/usr/libexec ### /usr/lib/debug/usr/libexec/nm-avahi-autoipd.action.debug ### /usr/lib/debug/usr/libexec/nm-crash-logger.debug ### /usr/lib/debug/usr/libexec/nm-dhcp-client.action.debug ### /usr/lib/debug/usr/libexec/nm-dispatcher.action.debug ### /usr/lib/debug/usr/sbin ### /usr/lib/debug/usr/sbin/NetworkManager.debug","title":"Enabling Debugging Symbols"},{"location":"articles/DEV_DebuggingSymbols/#glibc-missing-debug-info","text":"The following two problems may be resolved by adding debug symbols for the package sys-libs/glibc .","title":"glibc missing debug info"},{"location":"articles/DEV_DebuggingSymbols/#gdb-libpthread-library-mismatch-with-libthread_db","text":"If there is no debug symbols for libpthread library, GDB will not directly say that there is no debugging symbols for libpthread, instead, whenever you start GDB, it will show below warning, warning: Unable to find libthread_db matching inferior's thread library, thread debugging will not be available. See this [http://bugs.sabayon.org/show_bug.cgi?id=3316] link for more information.","title":"GDB: libpthread library mismatch with libthread_db"},{"location":"articles/DEV_DebuggingSymbols/#valgrind-needs-a-non-stripped-ld","text":"When executing valgrind with no option in particular (for example: valgrind /bin/true ) you may get the following error message: valgrind: Fatal error at startup: a function redirection valgrind: which is mandatory for this platform-tool combination valgrind: cannot be set up. Details of the redirection are: valgrind: valgrind: A must-be-redirected function valgrind: whose name matches the pattern: strlen valgrind: in an object with soname matching: ld-linux-x86-64.so.2 valgrind: was not found whilst processing valgrind: symbols from the object with soname: ld-linux-x86-64.so.2 valgrind: valgrind: Possible fixes: (1, short term): install glibc's debuginfo valgrind: package on this machine. (2, longer term): ask the packagers valgrind: for your Linux distribution to please in future ship a non- valgrind: stripped ld.so (or whatever the dynamic linker .so is called) valgrind: that exports the above-named function using the standard valgrind: calling conventions for this platform. The package you need valgrind: to install for fix (1) is called valgrind: valgrind: On Debian, Ubuntu: libc6-dbg valgrind: On SuSE, openSuSE, Fedora, RHEL: glibc-debuginfo valgrind: valgrind: Note that if you are debugging a 32 bit process on a valgrind: 64 bit system, you will need a corresponding 32 bit debuginfo valgrind: package (e.g. libc6-dbg:i386). valgrind: valgrind: Cannot continue -- exiting now. Sorry.","title":"Valgrind: Needs a non-stripped LD"},{"location":"articles/DEV_DebuggingSymbols/#resolution","text":"To fix both these issues, just enable splitdebug inside /etc/entropy/client.conf and reinstall sys-libs/glibc package. # equo install sys-libs/glibc There is no need to reboot the system or restart anything.","title":"Resolution"},{"location":"articles/DEV_Devkit/","text":"Sabayon-devkit NOTICE Repository created with this method, can't be tracked by Eit. Responsability to rebuild the packages when they are broken against main repositories is on your behalf. The Article is still a draft Sabayon Devkit is a suite of tools with the goal of making the life easy when dealing with Sabayon internal structure, mostly contains tools related to package mantaining. Installing It is available on Entropy (see [http://packages.sabayon.org/quicksearch?q=app-misc%2Fsabayon-devkit app-misc/sabayon-devkit], and [http://gpo.zugaina.org/app-misc/sabayon-devkit gpo.zugaina.org] for portage), but you can install on well on other distros from the sources(https://github.com/Sabayon/devkit), the tools leverage Docker and does not modify your running system. From the terminal of your Sabayon box: sudo equo install sabayon-devkit sabayon-entropypreservedlibs When you see messages like this \u261b There are 2 preserved libraries on the system \u2560 /usr/lib64/libkipi.so.11.1.0 [libkipi.so.11:2 - kde-apps/libkipi-15.08.3] \u2560 /usr/lib64/libkipi.so.11 [libkipi.so.11:2 - kde-apps/libkipi-15.08.3] This happens mostly when you mixed Entropy with Portage, or you may still have very old and outdated packages installed. You can use sabayon-entropypreservedlibs to see what packages causes the breakage. sabayon-entropypreservedlibs No packages request outdated libs Prerequisites for the building and repository creator script Docker installed in the machine (''sudo equo i docker''), and the daemon started (''sudo systemctl start docker''). You might want enable it on start ''sudo systemctl enable docker'' if you don't want to run that as root, the user where are you running the script must be in the docker group (''sudo gpasswd -a $USER docker'') or better, having enabled the docker bin in sudoers. Space: At least you will need around 2GB of disk space due to the Docker Image that contains all the needed tools. ''sabayon-buildpackages'' and ''sabayon-createrepo'' are just a script wrapper around the development Docker container. It's strongly encouraged to create a directory for each your project (repository) and run the commands inside to it. Building packages NOTICE This phase requires bandwitdth and disk space that differ for each case. ''E.g. if you decide to compile a package that have a huge dependency list You can build packages by running: sabayon-buildpackages Where '' '' is in the same syntax as Emerge. DOCKER_PULL_IMAGE=1 sabayon-buildpackages app-foo/foobar --equo foo-misc/foobar --layman foo --layman bar foo --layman foobar -- tells the script to add the \"foobar\" overlay from layman --equo foo-misc/foobar -- tells the script to install \"foo-misc/foobar\" before compiling Environment variables: DOCKER_PULL_IMAGE -- tells the script to update the docker image before compiling, enable it with 1, disable with 0 OUTPUT_DIR -- optional, default to \"portage_artifacts\" in your current working directory, it is the path where emerge generated tbz2 are stored (absolute path) LOCAL_OVERLAY -- optional, you can specify the path to your local overlay (absolute path) The arguments are the packages that you want compile, they can be also in the complete form e.g. =foo-bar/misc-1.2 Docker will now pull (if not already) the 64bit Docker Development image. Then will be created a folder in your current working directory named portage_artifacts . That folder will contain packages built with [[Portage]] by the Docker image upon a successful build. Folder structure This is the folder structure of your workspace by default, but you can tweak part of it to your tastes with Environment variables: myproject/ myproject/portage_artifacts/ myproject/entropy_artifacts/ myproject/local_overlay/ myproject/specs/ ''myproject/portage_artifacts/'' -- Created by default when sabayon-buildpackages is used. It contains the portage artifacts, they will be consumed in the next steps ''myproject/entropy_artifacts/'' -- Created when sabayon-createrepo is started. It contains the entropy repository files (It can be already present if you want to update your repository) ''myproject/local_overlay/'' -- is the location of your personal overlay (if necessary) ''myproject/specs'' -- Create it to customize the building process. It can contain custom files for make.conf, uses, envs, masks, unmasks and keywords for package compilation options the specs folder is structured like this and it's merely optional. as long as you create those files inside the spec/ folder they are used: ''custom.unmask'' -- that's the place for custom unmasks ''custom.mask'' -- contain your custom masks ''custom.use'' -- contain your custom use flags ''custom.env'' -- contain your custom env specifications ''custom.keywords'' -- contain your custom keywords ''make.conf'' -- it will replace the make.conf on the container with yours. you can override the Architecture folder in which files are placed specifying in the SAB_ARCH environment variable. Default is \"intel\" (can be armarch as for now) Advanced usage The tool allows customization with environment variables and option that alters it's behavior [https://github.com/Sabayon/devkit/blob/master/README.md#building-package-in-a-clean-environment] Creating repository NOTICE The tools are intended to run subsequentially, but they are completely untied. You can create repository with sabayon-createrepo also if where not compiled with sabayon-buildpackages You can build packages by running on the same directory you run ''sabayon-buildpackages'': sabayon-createrepo REPOSITORY_NAME=mytest REPOSITORY_DESCRIPTION=\"My Wonderful Repository\" sabayon-createrepo REPOSITORY_NAME -- optional, is your repository name id REPOSITORY_DESCRIPTION -- optional, is your repository description PORTAGE_ARTIFACTS -- optional if you use the tools in the same dir, you can specify where portage artifacts (*.tbz2 files) are (absolute path required) OUTPUT_DIR -- optional, you can specify where the entropy repository will be stored You can also put your .tbz2 file externally built inside ''entropy_artifacts/'' in your workspace folder (you can create it if not already present) and run sabayon-createrepo to generate a repository from them. sabayon-createrepo can be called sequentially, and it will update the repository found on ''entropy_artifacts/'' with the packages ( in .tbz2 ) in ''portage_artifacts/''. In both sabayon-createrepo and sabayon-buildpackages you can override the docker image used with the environment variable DOCKER_IMAGE . It will be created an ''entropy_artifacts/'' folder that will contain your repository files generated from the packages built from the step above. NOTICE When running sabayon-createrepo the .tbz2 of the *PORTAGE_ARTIFACTS (''entropy_artifacts/'' by default) folder are removed. Advanced usage The tool allows customization with environment variables and option that alters it's behavior [https://github.com/Sabayon/devkit/blob/master/Documentation.md]","title":"Sabayon-devkit"},{"location":"articles/DEV_Devkit/#sabayon-devkit","text":"","title":"Sabayon-devkit"},{"location":"articles/DEV_Devkit/#notice","text":"Repository created with this method, can't be tracked by Eit. Responsability to rebuild the packages when they are broken against main repositories is on your behalf. The Article is still a draft Sabayon Devkit is a suite of tools with the goal of making the life easy when dealing with Sabayon internal structure, mostly contains tools related to package mantaining.","title":"NOTICE"},{"location":"articles/DEV_Devkit/#installing","text":"It is available on Entropy (see [http://packages.sabayon.org/quicksearch?q=app-misc%2Fsabayon-devkit app-misc/sabayon-devkit], and [http://gpo.zugaina.org/app-misc/sabayon-devkit gpo.zugaina.org] for portage), but you can install on well on other distros from the sources(https://github.com/Sabayon/devkit), the tools leverage Docker and does not modify your running system. From the terminal of your Sabayon box: sudo equo install sabayon-devkit","title":"Installing"},{"location":"articles/DEV_Devkit/#sabayon-entropypreservedlibs","text":"When you see messages like this \u261b There are 2 preserved libraries on the system \u2560 /usr/lib64/libkipi.so.11.1.0 [libkipi.so.11:2 - kde-apps/libkipi-15.08.3] \u2560 /usr/lib64/libkipi.so.11 [libkipi.so.11:2 - kde-apps/libkipi-15.08.3] This happens mostly when you mixed Entropy with Portage, or you may still have very old and outdated packages installed. You can use sabayon-entropypreservedlibs to see what packages causes the breakage. sabayon-entropypreservedlibs No packages request outdated libs","title":"sabayon-entropypreservedlibs"},{"location":"articles/DEV_Devkit/#prerequisites-for-the-building-and-repository-creator-script","text":"Docker installed in the machine (''sudo equo i docker''), and the daemon started (''sudo systemctl start docker''). You might want enable it on start ''sudo systemctl enable docker'' if you don't want to run that as root, the user where are you running the script must be in the docker group (''sudo gpasswd -a $USER docker'') or better, having enabled the docker bin in sudoers. Space: At least you will need around 2GB of disk space due to the Docker Image that contains all the needed tools. ''sabayon-buildpackages'' and ''sabayon-createrepo'' are just a script wrapper around the development Docker container. It's strongly encouraged to create a directory for each your project (repository) and run the commands inside to it.","title":"Prerequisites for the building and repository creator script"},{"location":"articles/DEV_Devkit/#building-packages","text":"","title":"Building packages"},{"location":"articles/DEV_Devkit/#notice_1","text":"This phase requires bandwitdth and disk space that differ for each case. ''E.g. if you decide to compile a package that have a huge dependency list You can build packages by running: sabayon-buildpackages Where '' '' is in the same syntax as Emerge. DOCKER_PULL_IMAGE=1 sabayon-buildpackages app-foo/foobar --equo foo-misc/foobar --layman foo --layman bar foo --layman foobar -- tells the script to add the \"foobar\" overlay from layman --equo foo-misc/foobar -- tells the script to install \"foo-misc/foobar\" before compiling Environment variables: DOCKER_PULL_IMAGE -- tells the script to update the docker image before compiling, enable it with 1, disable with 0 OUTPUT_DIR -- optional, default to \"portage_artifacts\" in your current working directory, it is the path where emerge generated tbz2 are stored (absolute path) LOCAL_OVERLAY -- optional, you can specify the path to your local overlay (absolute path) The arguments are the packages that you want compile, they can be also in the complete form e.g. =foo-bar/misc-1.2 Docker will now pull (if not already) the 64bit Docker Development image. Then will be created a folder in your current working directory named portage_artifacts . That folder will contain packages built with [[Portage]] by the Docker image upon a successful build.","title":"NOTICE"},{"location":"articles/DEV_Devkit/#folder-structure","text":"This is the folder structure of your workspace by default, but you can tweak part of it to your tastes with Environment variables: myproject/ myproject/portage_artifacts/ myproject/entropy_artifacts/ myproject/local_overlay/ myproject/specs/ ''myproject/portage_artifacts/'' -- Created by default when sabayon-buildpackages is used. It contains the portage artifacts, they will be consumed in the next steps ''myproject/entropy_artifacts/'' -- Created when sabayon-createrepo is started. It contains the entropy repository files (It can be already present if you want to update your repository) ''myproject/local_overlay/'' -- is the location of your personal overlay (if necessary) ''myproject/specs'' -- Create it to customize the building process. It can contain custom files for make.conf, uses, envs, masks, unmasks and keywords for package compilation options the specs folder is structured like this and it's merely optional. as long as you create those files inside the spec/ folder they are used: ''custom.unmask'' -- that's the place for custom unmasks ''custom.mask'' -- contain your custom masks ''custom.use'' -- contain your custom use flags ''custom.env'' -- contain your custom env specifications ''custom.keywords'' -- contain your custom keywords ''make.conf'' -- it will replace the make.conf on the container with yours. you can override the Architecture folder in which files are placed specifying in the SAB_ARCH environment variable. Default is \"intel\" (can be armarch as for now)","title":"Folder structure"},{"location":"articles/DEV_Devkit/#advanced-usage","text":"The tool allows customization with environment variables and option that alters it's behavior [https://github.com/Sabayon/devkit/blob/master/README.md#building-package-in-a-clean-environment]","title":"Advanced usage"},{"location":"articles/DEV_Devkit/#creating-repository","text":"","title":"Creating repository"},{"location":"articles/DEV_Devkit/#notice_2","text":"The tools are intended to run subsequentially, but they are completely untied. You can create repository with sabayon-createrepo also if where not compiled with sabayon-buildpackages You can build packages by running on the same directory you run ''sabayon-buildpackages'': sabayon-createrepo REPOSITORY_NAME=mytest REPOSITORY_DESCRIPTION=\"My Wonderful Repository\" sabayon-createrepo REPOSITORY_NAME -- optional, is your repository name id REPOSITORY_DESCRIPTION -- optional, is your repository description PORTAGE_ARTIFACTS -- optional if you use the tools in the same dir, you can specify where portage artifacts (*.tbz2 files) are (absolute path required) OUTPUT_DIR -- optional, you can specify where the entropy repository will be stored You can also put your .tbz2 file externally built inside ''entropy_artifacts/'' in your workspace folder (you can create it if not already present) and run sabayon-createrepo to generate a repository from them. sabayon-createrepo can be called sequentially, and it will update the repository found on ''entropy_artifacts/'' with the packages ( in .tbz2 ) in ''portage_artifacts/''. In both sabayon-createrepo and sabayon-buildpackages you can override the docker image used with the environment variable DOCKER_IMAGE . It will be created an ''entropy_artifacts/'' folder that will contain your repository files generated from the packages built from the step above.","title":"NOTICE"},{"location":"articles/DEV_Devkit/#notice_3","text":"When running sabayon-createrepo the .tbz2 of the *PORTAGE_ARTIFACTS (''entropy_artifacts/'' by default) folder are removed.","title":"NOTICE"},{"location":"articles/DEV_Devkit/#advanced-usage_1","text":"The tool allows customization with environment variables and option that alters it's behavior [https://github.com/Sabayon/devkit/blob/master/Documentation.md]","title":"Advanced usage"},{"location":"articles/DEV_ImagePacker/","text":"Building VMware images Setting up a build environment using VMware Player While we'll be installing the VMware Workstation in these instructions which is not free software, we only need the player and VIX components which are free to use so there's no need to purchase a workstation license. Install app-emulation/vmware-workstation with USE=\"ovftool server vix\" (currently without these use flags in entropy, built in SCR temporarily) If using bash, env-update source /etc/profile Setup virtual networks Copy the following into /etc/vmware/networking VERSION=1,0 answer VNET_1_DHCP yes answer VNET_1_DHCP_CFG_HASH BA0A2ADB438F4A390ADE7333633E4AA8C00B897A answer VNET_1_HOSTONLY_NETMASK 255.255.255.0 answer VNET_1_HOSTONLY_SUBNET 192.168.93.0 answer VNET_1_VIRTUAL_ADAPTER yes answer VNET_8_DHCP yes answer VNET_8_DHCP_CFG_HASH F80579270B94AB020609BA2500257CA9B04050DD answer VNET_8_HOSTONLY_NETMASK 255.255.255.0 answer VNET_8_HOSTONLY_SUBNET 192.168.94.0 answer VNET_8_NAT yes answer VNET_8_VIRTUAL_ADAPTER yes run vmware-netcfg . You need at least vmnet8, type NAT, with local DHCP and Connect virtual host adapter options ticked. Save the changes and verify the network config has been written to /etc/vmware/networking and /etc/vmware/vmnet8/ Get the vmware prerequisites running (kernel modules loaded, networks enabled) # systemctl enable --now vmware.target Clone a copy of https://github.com/Sabayon/packer-templates Building the image Run the packer command to complete the install packer build -var \"flavor=SpinBase\" -var \"vagrant=vagrant\" -only vmware-iso images.json Packer produces a .tar.gz of a vmx directory. In order to import this into ESX, it needs to be converted into an OVA. Extract the tar into a temporary directory, and cd into it Repair the disk images, packer sometimes produces disks that need repair vmware-vdiskmanager -R disk.vmdk ** Run the conversion /opt/vmware/lib/vmware-ovftool/ovftool ./Sabayon\\ VMware\\ SpinBase.vmx ../Sabayon_Linux_DAILY_amd64_SpinBase.ova","title":"Building VMware images"},{"location":"articles/DEV_ImagePacker/#building-vmware-images","text":"","title":"Building VMware images"},{"location":"articles/DEV_ImagePacker/#setting-up-a-build-environment-using-vmware-player","text":"While we'll be installing the VMware Workstation in these instructions which is not free software, we only need the player and VIX components which are free to use so there's no need to purchase a workstation license. Install app-emulation/vmware-workstation with USE=\"ovftool server vix\" (currently without these use flags in entropy, built in SCR temporarily) If using bash, env-update source /etc/profile Setup virtual networks Copy the following into /etc/vmware/networking VERSION=1,0 answer VNET_1_DHCP yes answer VNET_1_DHCP_CFG_HASH BA0A2ADB438F4A390ADE7333633E4AA8C00B897A answer VNET_1_HOSTONLY_NETMASK 255.255.255.0 answer VNET_1_HOSTONLY_SUBNET 192.168.93.0 answer VNET_1_VIRTUAL_ADAPTER yes answer VNET_8_DHCP yes answer VNET_8_DHCP_CFG_HASH F80579270B94AB020609BA2500257CA9B04050DD answer VNET_8_HOSTONLY_NETMASK 255.255.255.0 answer VNET_8_HOSTONLY_SUBNET 192.168.94.0 answer VNET_8_NAT yes answer VNET_8_VIRTUAL_ADAPTER yes run vmware-netcfg . You need at least vmnet8, type NAT, with local DHCP and Connect virtual host adapter options ticked. Save the changes and verify the network config has been written to /etc/vmware/networking and /etc/vmware/vmnet8/ Get the vmware prerequisites running (kernel modules loaded, networks enabled) # systemctl enable --now vmware.target Clone a copy of https://github.com/Sabayon/packer-templates","title":"Setting up a build environment using VMware Player"},{"location":"articles/DEV_ImagePacker/#building-the-image","text":"Run the packer command to complete the install packer build -var \"flavor=SpinBase\" -var \"vagrant=vagrant\" -only vmware-iso images.json Packer produces a .tar.gz of a vmx directory. In order to import this into ESX, it needs to be converted into an OVA. Extract the tar into a temporary directory, and cd into it Repair the disk images, packer sometimes produces disks that need repair vmware-vdiskmanager -R disk.vmdk ** Run the conversion /opt/vmware/lib/vmware-ovftool/ovftool ./Sabayon\\ VMware\\ SpinBase.vmx ../Sabayon_Linux_DAILY_amd64_SpinBase.ova","title":"Building the image"},{"location":"articles/DEV_Molecule/","text":"Molecule Molecule in a nut shell builds custom iso images. If want to make your own custom Sabayon Linux, this is the tool you need. You first need to install the package dev-util/molecule via entropy. You can follow along with the molecule development via our git http://gitweb.sabayon.org/?p=molecule.git;a=summary molecule.git You can also find sample files to view via the git repo. Installing Molecule I assume if you are reading this that you are an advanced user and understand how entropy works. #equo update #equo install dev-util/molecule You now have molecule installed and ready to use. Understanding Molecule What you are going to do is use an existing Sabayon Linux iso image for molecule to use. Which iso image you choose is up to you. Check our [http://www.sabayon.org/download/ mirrors] for an iso image to use. Molecule is going to jump into that iso image, make the changes you tell it to via the spec file and other shell script files. Once molecule has done it's changes that you requested, it will spin out your new custom iso image. There is no gui for this, you run molecule from the command line once you have your spec file and shell scripts set up. The spec file is the heart of your configurations. An [http://gitweb.sabayon.org/?p=molecule.git;a=blob;f=examples/specs/5-x86-g-remaster-add-games.spec;h=5623f42dee8595990663ad2e72697cafd9ce9143;hb=29d45a193430bc8afbda65d0cf19 example spec file] for you to view and use. You can use shell script files to further makes changes. I would consider that an advanced topic as you need to know shell scripting and understand the guts of the existing Sabayon Linux iso. I'm not gonna touch much on that subject, cause I'm not a programmer. I will be using some shell script files in this example, very basic. Getting Started WARNING If using an extra partition for these processes, ensure that it is capable of maintaining proper file attributes. FAT and NTFS are NOT capable, EXT2,3,4 ReiserFS, linux native file systems are. Setting Up Existing ISO Images Structure I like to setup a structure and keep things organized so I can keep track of things. In my home directoy is where I like to store the existing Sabayon iso images. My home goes something like this: This is where I keep my 64bit Sabayon dvd iso images: ~/isos/amd64 Setting up Molecule Structure I keep the molecule work out of my home directory and use the / for this. So I do something like this: I want to give my molecule stuff a home to hold my spec file(s) and shell script file(s), so I create: /spin I need to give a home to my custom ISO images, so I have: /spin/final Since I like to have my own background image added into the new custom ISO image, I create a folder for those image files: /spin/background That covers everything I need to do. I like to use the cache abilities of molecule, saves on downloading for each run. Molecule will create the directories for that on the first run, so molecule will automatically create /sabayon/remaster/pkgs/amd64/5 Spec File Lets take a look at a [https://github.com/wolfden/Coding spec file], looks frightening, but lets go through it section by section. Bare with me as I just wing it here. Description and mission, nothing to touch here: # Sabayon Linux 5 amd64 GNOME Molecule remaster spec file # The aim of this spec file is to add arbitrary applications misc stuff # to an already built ISO image via scripting (providing hooks that call # user-defined scripts). # squashfs, mkisofs needed Some setting we don't need to bother changing, another words, leave it alone as is # Define an alternative execution strategy, in this case, the value must be # \"iso_remaster\" execution_strategy: iso_remaster Straight forward, you want to tell molecule where your existing iso image is, use your directory structure that you created # Path to source ISO file (MANDATORY) source_iso: /home/wolfden/isos/amd64/Sabayon_Linux_amd64_G.iso No idea, safe to ignore this part, nothing to touch, leave as default # Error script command, executed when something went wrong and molecule has to terminate the execution # environment variables exported: # - CHROOT_DIR: path to chroot directory, if any # - CDROOT_DIR: path to livecd root directory, if any # - SOURCE_CHROOT_DIR: path from where chroot is copied for final handling # error_script: /path/to/script/to/be/executed/outside/after I use a shell script here to setup my cache, I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Outer chroot script command, to be executed outside destination chroot before # before entering it (and before inner_chroot_script) outer_chroot_script: /spin/remaster_pre.sh No idea, I leave this default # Inner chroot script command, to be executed inside destination chroot before packing it # - kmerge.sh - setup kernel bins # inner_chroot_script: I use a shell script here to do some clean up after molecule has done it's package installs and removal, I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Inner chroot script command, to be executed inside destination chroot after # packages installation and removal inner_chroot_script_after: /spin/inner_chroot_script_after.sh Another shell script I use to do my background image swap, equo cleanup and more cache work. I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Outer chroot script command, to be executed outside destination chroot before # before entering it (and AFTER inner_chroot_script) outer_chroot_script_after: /spin/remaster_post.sh Leave this area alone, leave as default # Extra mkisofs parameters, perhaps something to include/use your bootloader extra_mkisofs_parameters: -b isolinux/isolinux.bin -c isolinux/boot.cat Leave this area alone, leave as default # Pre-ISO building script. Hook to be able to copy kernel images in place, for example # pre_iso_script: /sabayon/scripts/cdroot.py This is where you tell molecule to save your custom made ISO image, use your directory structure. # Destination directory for the ISO image path (MANDATORY) destination_iso_directory: /spin/final If you are making a cd ISO image, here is where you name it, give it the name and than remove the # in front of the line so molecule will act upon it # Destination ISO image name, call whatever you want.iso, not mandatory # destination_iso_image_name: Sabayon_Linux_Customcd_amd64_G If you are making a DVD ISO image, give it's name here and remove the # in front of the line so molecule can act upon it. # Output iso image title iso_title: Sabayon_Linux_CustomDVD_amd64_G No idea, leave as default # Alternative ISO file mount command (default is: mount -o loop -t iso9660) # iso_mounter: No idea, leave as default # Alternative ISO umounter command (default is: umount) # iso_umounter: No idea, leave as default # Alternative squashfs file mount command (default is: mount -o loop -t squashfs) # squash_mounter: No idea, leave as default # Alternative ISO squashfs umount command (default is: umount) # squash_umounter: No idea, leave as default # Merge directory with destination LiveCD root # merge_livecd_root: /put/more/files/onto/CD/root This is self explanatory, put the packages you want to remove here separated by a comma. Make sure no # is at the beginning of the line so molecule can act upon it. I use foo as an example package name # List of packages that would be removed from chrooted system (comma separated) packages_to_remove: foo, foo2, foo3, foo4, foo5 No idea, leave as default # Custom shell call to packages removal (default is: equo remove) # custom_packages_remove_cmd: This is self explanatory, put the packages you want to add here separated by a comma. Make sure no # is at the beginning of the line so molecule can act upon it. I use foo as an example package name # List of packages that would be added from chrooted system (comma separated) packages_to_add: foo, foo2, foo3, foo4, foo5 No idea, leave as default # Custom shell call to packages add (default is: equo install) # custom_packages_add_cmd: No idea, leave as default # Custom command for updating repositories (default is: equo update) # repositories_update_cmd: While molecule is running, entropy does an equo update to update it's database so you can get the latest packages. You will want this set to yes, otherwise molecule will fail with entropy unable to determine packages since the database isn't updated. # Determine whether repositories update should be run (if packages_to_add is set) # (default is: no), values are: yes, no. execute_repositories_update: yes No idea, leave as default # Directories to remove completely (comma separated) # paths_to_remove: No idea, leave as default # Directories to empty (comma separated) # paths_to_empty: Shell Files I want to stress that these are for the more advanced stuff and are not needed. They need to be executable in order to run them. You need an understanding of existing ISO image. In my case I didn't realize that the root and user accounts were created on the fly, so if you try making preferences directly to the sabayonuser account, it won't work. You need to access the skel files instead. Knowledge is power I always say, sometimes we got to learn things the hard way. Keep in mind that the first time you run molecule, you may see some error messages with these files, but will work ok and the next time it won't report errors. Keep in mind also that these are tailored for my custom ISO image, but they give you an idea and you can adopt what you need. remaster_pre.sh What this does, it sets up my cache. It will store the packages I add so I don't have to keep re-downloading them each time I want to make a spin. A great time saver if you have large files to work with. #!/bin/sh PKGS_DIR=\"/sabayon/remaster/pkgs\" CHROOT_PKGS_DIR=\"${CHROOT_DIR}/var/lib/entropy/client/packages\" [[ ! -d \"${PKGS_DIR}\" ]] mkdir -p \"${PKGS_DIR}\" [[ ! -d \"${CHROOT_PKGS_DIR}\" ]] mkdir -p \"${CHROOT_PKGS_DIR}\" echo \"Mounting packages over\" rm -rf \"${CHROOT_PKGS_DIR}\"/ cp ${PKGS_DIR}/ \"${CHROOT_PKGS_DIR}\"/ -Ra exit 0 remaster_post.sh Again, this is working with the cache files again. Basically the cache works like this, molecule downloads the packages via chroot, once done, it moves the packages to /sabayon/remaster/pkgs for local storage and the next time you run your spin, it copies the files over and back into the chroot so you don't have to re-download all the packages again. I also use this file to change the desktop background to the one I created. I also do an equo clean up to remove packages and reduce ISO image size. #!/bin/sh PKGS_DIR=\"/sabayon/remaster/pkgs\" CHROOT_PKGS_DIR=\"${CHROOT_DIR}/var/lib/entropy/client/packages\" echo \"Merging back packages\" cp \"${CHROOT_PKGS_DIR}\"/ \"${PKGS_DIR}\"/ -Ra rm -rf \"${CHROOT_PKGS_DIR}\"{,-nonfree,-restricted}/ cp /spin/background/sabayon-forensic.png \"${CHROOT_DIR}/usr/share/backgrounds/sabayonlinux.png\" cp /spin/background/sabayon-forensic.jpg \"${CHROOT_DIR}/usr/share/backgrounds/sabayonlinux.jpg\" is_64=$(file \"${CHROOT_DIR}\"/bin/bash | grep \"x86-64\") if [ -n \"${is_64}\" ]; then echo \"equo cleanup\" | chroot \"${CHROOT_DIR}\" else echo \"equo cleanup\" | linux32 chroot \"${CHROOT_DIR}\" fi inner_chroot_script_after.sh I use this script to do some more clean up stuff. It's pretty basic #!/bin/bash #fix clamav freshclam touch /var/log/clamav/freshclam.log chown clamav:clamav /var/log/clamav/freshclam.log #remove desktop icons rm /etc/skel/Desktop/* #remove no longer needed folders/files rm -r /etc/skel/.fluxbox rm -r /etc/skel/.kde4 rm -r /etc/skel/.mozilla rm -r /etc/skel/.emerald rm -r /etc/skel/.xchat2 rm -r /etc/skel/.config/compiz rm -r /etc/skel/.config/lxpanel rm -r /etc/skel/.config/pcmanfm rm -r /etc/skel/.config/Thunar rm -r /etc/skel/.config/xfce4 rm -r /etc/skel/.gconf/apps/compiz rm -r /etc/skel/.gconf/apps/gset-compiz rm /etc/skel/.config/menus/applications-kmenuedit.menu rm /etc/skel/.kderc emaint --fix world Running Molecule So you got your directory structure done, edited a spec file to suit your needs, possibly created some shell script files and ready to roll. Open a terminal window and make sure you are root and issue #molecule /spin/mycustom.spec Replace the mycustom.spec with the name of your spec file of course. Go make some popcorn and grab a soda and watch the magic happen in your terminal","title":"Molecule"},{"location":"articles/DEV_Molecule/#molecule","text":"Molecule in a nut shell builds custom iso images. If want to make your own custom Sabayon Linux, this is the tool you need. You first need to install the package dev-util/molecule via entropy. You can follow along with the molecule development via our git http://gitweb.sabayon.org/?p=molecule.git;a=summary molecule.git You can also find sample files to view via the git repo.","title":"Molecule"},{"location":"articles/DEV_Molecule/#installing-molecule","text":"I assume if you are reading this that you are an advanced user and understand how entropy works. #equo update #equo install dev-util/molecule You now have molecule installed and ready to use.","title":"Installing Molecule"},{"location":"articles/DEV_Molecule/#understanding-molecule","text":"What you are going to do is use an existing Sabayon Linux iso image for molecule to use. Which iso image you choose is up to you. Check our [http://www.sabayon.org/download/ mirrors] for an iso image to use. Molecule is going to jump into that iso image, make the changes you tell it to via the spec file and other shell script files. Once molecule has done it's changes that you requested, it will spin out your new custom iso image. There is no gui for this, you run molecule from the command line once you have your spec file and shell scripts set up. The spec file is the heart of your configurations. An [http://gitweb.sabayon.org/?p=molecule.git;a=blob;f=examples/specs/5-x86-g-remaster-add-games.spec;h=5623f42dee8595990663ad2e72697cafd9ce9143;hb=29d45a193430bc8afbda65d0cf19 example spec file] for you to view and use. You can use shell script files to further makes changes. I would consider that an advanced topic as you need to know shell scripting and understand the guts of the existing Sabayon Linux iso. I'm not gonna touch much on that subject, cause I'm not a programmer. I will be using some shell script files in this example, very basic.","title":"Understanding Molecule"},{"location":"articles/DEV_Molecule/#getting-started","text":"","title":"Getting Started"},{"location":"articles/DEV_Molecule/#warning","text":"If using an extra partition for these processes, ensure that it is capable of maintaining proper file attributes. FAT and NTFS are NOT capable, EXT2,3,4 ReiserFS, linux native file systems are.","title":"WARNING"},{"location":"articles/DEV_Molecule/#setting-up-existing-iso-images-structure","text":"I like to setup a structure and keep things organized so I can keep track of things. In my home directoy is where I like to store the existing Sabayon iso images. My home goes something like this: This is where I keep my 64bit Sabayon dvd iso images: ~/isos/amd64","title":"Setting Up Existing ISO Images Structure"},{"location":"articles/DEV_Molecule/#setting-up-molecule-structure","text":"I keep the molecule work out of my home directory and use the / for this. So I do something like this: I want to give my molecule stuff a home to hold my spec file(s) and shell script file(s), so I create: /spin I need to give a home to my custom ISO images, so I have: /spin/final Since I like to have my own background image added into the new custom ISO image, I create a folder for those image files: /spin/background That covers everything I need to do. I like to use the cache abilities of molecule, saves on downloading for each run. Molecule will create the directories for that on the first run, so molecule will automatically create /sabayon/remaster/pkgs/amd64/5","title":"Setting up Molecule Structure"},{"location":"articles/DEV_Molecule/#spec-file","text":"Lets take a look at a [https://github.com/wolfden/Coding spec file], looks frightening, but lets go through it section by section. Bare with me as I just wing it here. Description and mission, nothing to touch here: # Sabayon Linux 5 amd64 GNOME Molecule remaster spec file # The aim of this spec file is to add arbitrary applications misc stuff # to an already built ISO image via scripting (providing hooks that call # user-defined scripts). # squashfs, mkisofs needed Some setting we don't need to bother changing, another words, leave it alone as is # Define an alternative execution strategy, in this case, the value must be # \"iso_remaster\" execution_strategy: iso_remaster Straight forward, you want to tell molecule where your existing iso image is, use your directory structure that you created # Path to source ISO file (MANDATORY) source_iso: /home/wolfden/isos/amd64/Sabayon_Linux_amd64_G.iso No idea, safe to ignore this part, nothing to touch, leave as default # Error script command, executed when something went wrong and molecule has to terminate the execution # environment variables exported: # - CHROOT_DIR: path to chroot directory, if any # - CDROOT_DIR: path to livecd root directory, if any # - SOURCE_CHROOT_DIR: path from where chroot is copied for final handling # error_script: /path/to/script/to/be/executed/outside/after I use a shell script here to setup my cache, I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Outer chroot script command, to be executed outside destination chroot before # before entering it (and before inner_chroot_script) outer_chroot_script: /spin/remaster_pre.sh No idea, I leave this default # Inner chroot script command, to be executed inside destination chroot before packing it # - kmerge.sh - setup kernel bins # inner_chroot_script: I use a shell script here to do some clean up after molecule has done it's package installs and removal, I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Inner chroot script command, to be executed inside destination chroot after # packages installation and removal inner_chroot_script_after: /spin/inner_chroot_script_after.sh Another shell script I use to do my background image swap, equo cleanup and more cache work. I will post that shell script further down. If you do not have this shell script, simple add a # to comment out the line and molecule will ignore it. You do not need this script, this is for further customization. # Outer chroot script command, to be executed outside destination chroot before # before entering it (and AFTER inner_chroot_script) outer_chroot_script_after: /spin/remaster_post.sh Leave this area alone, leave as default # Extra mkisofs parameters, perhaps something to include/use your bootloader extra_mkisofs_parameters: -b isolinux/isolinux.bin -c isolinux/boot.cat Leave this area alone, leave as default # Pre-ISO building script. Hook to be able to copy kernel images in place, for example # pre_iso_script: /sabayon/scripts/cdroot.py This is where you tell molecule to save your custom made ISO image, use your directory structure. # Destination directory for the ISO image path (MANDATORY) destination_iso_directory: /spin/final If you are making a cd ISO image, here is where you name it, give it the name and than remove the # in front of the line so molecule will act upon it # Destination ISO image name, call whatever you want.iso, not mandatory # destination_iso_image_name: Sabayon_Linux_Customcd_amd64_G If you are making a DVD ISO image, give it's name here and remove the # in front of the line so molecule can act upon it. # Output iso image title iso_title: Sabayon_Linux_CustomDVD_amd64_G No idea, leave as default # Alternative ISO file mount command (default is: mount -o loop -t iso9660) # iso_mounter: No idea, leave as default # Alternative ISO umounter command (default is: umount) # iso_umounter: No idea, leave as default # Alternative squashfs file mount command (default is: mount -o loop -t squashfs) # squash_mounter: No idea, leave as default # Alternative ISO squashfs umount command (default is: umount) # squash_umounter: No idea, leave as default # Merge directory with destination LiveCD root # merge_livecd_root: /put/more/files/onto/CD/root This is self explanatory, put the packages you want to remove here separated by a comma. Make sure no # is at the beginning of the line so molecule can act upon it. I use foo as an example package name # List of packages that would be removed from chrooted system (comma separated) packages_to_remove: foo, foo2, foo3, foo4, foo5 No idea, leave as default # Custom shell call to packages removal (default is: equo remove) # custom_packages_remove_cmd: This is self explanatory, put the packages you want to add here separated by a comma. Make sure no # is at the beginning of the line so molecule can act upon it. I use foo as an example package name # List of packages that would be added from chrooted system (comma separated) packages_to_add: foo, foo2, foo3, foo4, foo5 No idea, leave as default # Custom shell call to packages add (default is: equo install) # custom_packages_add_cmd: No idea, leave as default # Custom command for updating repositories (default is: equo update) # repositories_update_cmd: While molecule is running, entropy does an equo update to update it's database so you can get the latest packages. You will want this set to yes, otherwise molecule will fail with entropy unable to determine packages since the database isn't updated. # Determine whether repositories update should be run (if packages_to_add is set) # (default is: no), values are: yes, no. execute_repositories_update: yes No idea, leave as default # Directories to remove completely (comma separated) # paths_to_remove: No idea, leave as default # Directories to empty (comma separated) # paths_to_empty:","title":"Spec File"},{"location":"articles/DEV_Molecule/#shell-files","text":"I want to stress that these are for the more advanced stuff and are not needed. They need to be executable in order to run them. You need an understanding of existing ISO image. In my case I didn't realize that the root and user accounts were created on the fly, so if you try making preferences directly to the sabayonuser account, it won't work. You need to access the skel files instead. Knowledge is power I always say, sometimes we got to learn things the hard way. Keep in mind that the first time you run molecule, you may see some error messages with these files, but will work ok and the next time it won't report errors. Keep in mind also that these are tailored for my custom ISO image, but they give you an idea and you can adopt what you need.","title":"Shell Files"},{"location":"articles/DEV_Molecule/#remaster_presh","text":"What this does, it sets up my cache. It will store the packages I add so I don't have to keep re-downloading them each time I want to make a spin. A great time saver if you have large files to work with. #!/bin/sh PKGS_DIR=\"/sabayon/remaster/pkgs\" CHROOT_PKGS_DIR=\"${CHROOT_DIR}/var/lib/entropy/client/packages\" [[ ! -d \"${PKGS_DIR}\" ]] mkdir -p \"${PKGS_DIR}\" [[ ! -d \"${CHROOT_PKGS_DIR}\" ]] mkdir -p \"${CHROOT_PKGS_DIR}\" echo \"Mounting packages over\" rm -rf \"${CHROOT_PKGS_DIR}\"/ cp ${PKGS_DIR}/ \"${CHROOT_PKGS_DIR}\"/ -Ra exit 0","title":"remaster_pre.sh"},{"location":"articles/DEV_Molecule/#remaster_postsh","text":"Again, this is working with the cache files again. Basically the cache works like this, molecule downloads the packages via chroot, once done, it moves the packages to /sabayon/remaster/pkgs for local storage and the next time you run your spin, it copies the files over and back into the chroot so you don't have to re-download all the packages again. I also use this file to change the desktop background to the one I created. I also do an equo clean up to remove packages and reduce ISO image size. #!/bin/sh PKGS_DIR=\"/sabayon/remaster/pkgs\" CHROOT_PKGS_DIR=\"${CHROOT_DIR}/var/lib/entropy/client/packages\" echo \"Merging back packages\" cp \"${CHROOT_PKGS_DIR}\"/ \"${PKGS_DIR}\"/ -Ra rm -rf \"${CHROOT_PKGS_DIR}\"{,-nonfree,-restricted}/ cp /spin/background/sabayon-forensic.png \"${CHROOT_DIR}/usr/share/backgrounds/sabayonlinux.png\" cp /spin/background/sabayon-forensic.jpg \"${CHROOT_DIR}/usr/share/backgrounds/sabayonlinux.jpg\" is_64=$(file \"${CHROOT_DIR}\"/bin/bash | grep \"x86-64\") if [ -n \"${is_64}\" ]; then echo \"equo cleanup\" | chroot \"${CHROOT_DIR}\" else echo \"equo cleanup\" | linux32 chroot \"${CHROOT_DIR}\" fi","title":"remaster_post.sh"},{"location":"articles/DEV_Molecule/#inner_chroot_script_aftersh","text":"I use this script to do some more clean up stuff. It's pretty basic #!/bin/bash #fix clamav freshclam touch /var/log/clamav/freshclam.log chown clamav:clamav /var/log/clamav/freshclam.log #remove desktop icons rm /etc/skel/Desktop/* #remove no longer needed folders/files rm -r /etc/skel/.fluxbox rm -r /etc/skel/.kde4 rm -r /etc/skel/.mozilla rm -r /etc/skel/.emerald rm -r /etc/skel/.xchat2 rm -r /etc/skel/.config/compiz rm -r /etc/skel/.config/lxpanel rm -r /etc/skel/.config/pcmanfm rm -r /etc/skel/.config/Thunar rm -r /etc/skel/.config/xfce4 rm -r /etc/skel/.gconf/apps/compiz rm -r /etc/skel/.gconf/apps/gset-compiz rm /etc/skel/.config/menus/applications-kmenuedit.menu rm /etc/skel/.kderc emaint --fix world","title":"inner_chroot_script_after.sh"},{"location":"articles/DEV_Molecule/#running-molecule","text":"So you got your directory structure done, edited a spec file to suit your needs, possibly created some shell script files and ready to roll. Open a terminal window and make sure you are root and issue #molecule /spin/mycustom.spec Replace the mycustom.spec with the name of your spec file of course. Go make some popcorn and grab a soda and watch the magic happen in your terminal","title":"Running Molecule"},{"location":"articles/DEV_SCR/","text":"SCR - Community Repositories Package Requests If you are not familiar with the infrastructure and how to make a Pull Request to get a package inside the community repositories, open a bug request https://bugs.sabayon.org/enter_bug.cgi?product=Community%20Repositories Setup a local testing environment Install vagrant-bin and virtualbox equo install app-emulations/vagrant app-emulation/virtualbox-bin app-emulation/virtualbox-modules Clone a copy of https://github.com/Sabayon/community-buildspec into a local directory and cd into it Startup the SCR vagrant VM vagrant plugin install vagrant-persistent-storage vagrant up Fork a copy of https://github.com/Sabayon/community-repositories in Github. The provisioning script checks out a copy into ./repositories inside your community-buildspec working copy. Update the origin remote URL to point at your own github fork cd repositories git remote set-url origin git@github.com:${your_github_username}/community-repositories.git Make any changes to the repository config files you wish, e.g. adding a new package Run a test build of the repository on your own machine vagrant ssh sudo su - cd /vagrant/repositories/${repo_you_want_to_build}/ ../test.sh Watch the output to see if it builds successfully Raise a pull request against https://github.com/Sabayon/community-repositories to have your changes considered for inclusion into the SCR Clean up caches Docker images List current images: sabayon ~ # docker images REPOSITORY TAG IMAGE ID CREATED SIZE sabayon/builder-amd64-sihnon-common latest de101af3e5f0 4 minutes ago 7.919 GB 5d6b6223c3c6 47 minutes ago 6.747 GB sabayon/builder-amd64-sihnon-server latest 6950337b5b61 2 days ago 8.17 GB 56c4b5cbccb2 2 days ago 6.486 GB sabayon/builder-amd64 latest 023fbad8416f 2 days ago 3.535 GB sabayon/eit-amd64 latest fa07f471556f 2 days ago 1.701 GB Delete an image: sabayon ~ # docker rmi -f sabayon/builder-amd64-sihnon-common Untagged: sabayon/builder-amd64-sihnon-common:latest Deleted: sha256:de101af3e5f0b75e38133e88aefb51f337573f2872d8c5fd334cc7333109a543 Deleted: sha256:af2c266c622af79f5c7cd84ba96a78f5bfde1d2c593d5ba43f70c576ab0b1680 Deleted: sha256:e75ef42c43ab2296ca96bb798f73e8fe2516b215fbe747a5c3b67148c4445c97 Deleted: sha256:57835ffc466aec7f36b932d848419b570f6fc0d1ddc392570e63ed2b3a2c9478","title":"SCR - Community Repositories"},{"location":"articles/DEV_SCR/#scr-community-repositories","text":"","title":"SCR - Community Repositories"},{"location":"articles/DEV_SCR/#package-requests","text":"If you are not familiar with the infrastructure and how to make a Pull Request to get a package inside the community repositories, open a bug request https://bugs.sabayon.org/enter_bug.cgi?product=Community%20Repositories","title":"Package Requests"},{"location":"articles/DEV_SCR/#setup-a-local-testing-environment","text":"Install vagrant-bin and virtualbox equo install app-emulations/vagrant app-emulation/virtualbox-bin app-emulation/virtualbox-modules Clone a copy of https://github.com/Sabayon/community-buildspec into a local directory and cd into it Startup the SCR vagrant VM vagrant plugin install vagrant-persistent-storage vagrant up Fork a copy of https://github.com/Sabayon/community-repositories in Github. The provisioning script checks out a copy into ./repositories inside your community-buildspec working copy. Update the origin remote URL to point at your own github fork cd repositories git remote set-url origin git@github.com:${your_github_username}/community-repositories.git Make any changes to the repository config files you wish, e.g. adding a new package Run a test build of the repository on your own machine vagrant ssh sudo su - cd /vagrant/repositories/${repo_you_want_to_build}/ ../test.sh Watch the output to see if it builds successfully Raise a pull request against https://github.com/Sabayon/community-repositories to have your changes considered for inclusion into the SCR","title":"Setup a local testing environment"},{"location":"articles/DEV_SCR/#clean-up-caches","text":"","title":"Clean up caches"},{"location":"articles/DEV_SCR/#docker-images","text":"List current images: sabayon ~ # docker images REPOSITORY TAG IMAGE ID CREATED SIZE sabayon/builder-amd64-sihnon-common latest de101af3e5f0 4 minutes ago 7.919 GB 5d6b6223c3c6 47 minutes ago 6.747 GB sabayon/builder-amd64-sihnon-server latest 6950337b5b61 2 days ago 8.17 GB 56c4b5cbccb2 2 days ago 6.486 GB sabayon/builder-amd64 latest 023fbad8416f 2 days ago 3.535 GB sabayon/eit-amd64 latest fa07f471556f 2 days ago 1.701 GB Delete an image: sabayon ~ # docker rmi -f sabayon/builder-amd64-sihnon-common Untagged: sabayon/builder-amd64-sihnon-common:latest Deleted: sha256:de101af3e5f0b75e38133e88aefb51f337573f2872d8c5fd334cc7333109a543 Deleted: sha256:af2c266c622af79f5c7cd84ba96a78f5bfde1d2c593d5ba43f70c576ab0b1680 Deleted: sha256:e75ef42c43ab2296ca96bb798f73e8fe2516b215fbe747a5c3b67148c4445c97 Deleted: sha256:57835ffc466aec7f36b932d848419b570f6fc0d1ddc392570e63ed2b3a2c9478","title":"Docker images"},{"location":"articles/DEV_SoftwareTesting/","text":"Joining Software Testing Team If you wish to assist with software testing for Sabayon Linux, assistance is always welcome. We need testers to download ISO images and make sure they boot, install, no crashes/failures, and live on limbo repository. I wouldn't recommend this to someone who isn't familiar with virtual machines, partitioning, or is afraid of losing data on their machine. If you feel comfortable with those requirements, you may be a great candidate! Please contact someone in the #sabayon-dev IRC channel and let them know you're interested in joining the testing team. You will be contacted and request your email to be added to the testing group. What kind of skills do I need (or need to learn) to join testing? That actually depends on what skills you have and would like to learn. We're flexible and can teach you what you need to know. You just need to be prepared in case your machine loses its data. Backups! We plan to perform installs on virtual machines(BIOS/UEFI), bare metal machines(BIOS/UEFI), configure machines to our preferences, test graphics and wireless drivers/cards, check md5sums of ISO images, check the mirrors for up to date images, check that all hardware is recognized and working out of the box, run benchmarks, check for regressions, and look for solutions. The point is to catch problems before they arise for normal users looking for a mainstream release. You'll be living on the Sabayon bleeding edge in the limbo repository getting package updates before the rest of our users. Do you use your linux machine in a way that many people don't? Even better! this gives us more thorough testing. Even if you're fairly new to Linux, as long as you have the drive, patience, and willingness to learn. We can teach you what you need and/or want to know. IRC isn't always a quick communication method and tends to be used like old BBS message boards at times. You may not get an immediate response. We're all volunteers that have families and day jobs. So if you don't get an immediate response, leave the chat window open. You'll get a response sometime within the day. Some of us are even open to using alternative chat methods such as hangouts for direct contact. What if the issue isn't Sabayon Linux, but a piece of software? We lookup where to report the bugs and we file them accordingly. KDE, Gnome, atom, libreoffice, VLC, etc. gdb will be useful. They all have a place to report bugs. The more data on the bug and the more users reporting it, the easier it will be to get it fixed. Get comfortable with some [https://wiki.sabayon.org/index.php?title=Debugging_Symbols_-_splitdebug debugging] if you can. I'm a Software Tester! Where do I start? First there's the CORE. Hardware support, Virtual Machine support, Booting, Installing, Pre-installed basics. Next there's Spin dependent test. KDE- K3b working? QT5 working? systemsettings5 segfaulting? What if I notice an issue? This issue could be limited by hardware or a fluke by corruption or easily fixed. Time to communicate, email testing@sabayonlinux.org with your findings. We can all test and search out a fix together or file a bug with developers and mark a bug as \"confirmed\" by having multiple people post findings in the bug. This raises validity and priority. What if I'm looking at software that isn't installed by default? Same procedure! We can all look at the problem together to get updates, new software in the repository, patches, etc. CORE LIST Does Sabayon greeter work? (GUI only) Does Calamares Installer work? Does Custom partitioning, LVM and/or encryption work? Does it boot after install? (UEFI and BIOS) Is your graphics card recognized? Does 3D acceleration work (OpenGL, Vulkan)? Does sound work? Does dmesg present any obvious errors? Does journalctl -xe present any obvious errors? Does USB3.X and/or type-C work? Does wireless/bluetooth work? (Intel, Broadcom, Atheros, Realtek, etc) Check for Library issues? (sudo equo libtest) Do bundled applications work? Perms issues? (allowed to ping as a user? Lockscreen not unlocking?) Found CVEs or Security Flaws? Test Rigo and Entropy? SPIN DEPENDENT Many of these spin dependent softwares can be tested on a full running install with the limbo repository. Using an already running install is no replacement for Live disc and Install testing, but can let you test for broken software before its released. KDE - systemsettings5, gwenview, okular, k3b, dolphin, networkmanager, lockscreen, libreoffice, plasma5, MTP, steam, chrome. Gnome - brasero, control center, lockscreen, MTP, nm-applet, steam, tweaktool, libreoffice, chrome. MATE - Similar to Gnome package list + guake. LXQt - Does not use Anaconda by default. Should have (experimental) Calamares. Please test Calamares installer. CORE LIST + LXQt desktop, settings, file manager. Xfce - CORE LIST + Xfce desktop, settings, file manager. Server Minimal - CORE LIST CLI-Only (No GUI) LOOKING DEEPER If you're curious and wish to look at performance changes and regressions. You're welcome to dig into newer software and kernels in search of fixes and performance boosts. Some software that could help with that could be as simple as a few free steam games such as DOTA2 and benchmark tools like [https://benchmark.unigine.com/heaven Unigine Benchmarks], or [http://www.iozone.org/ iozone]. Check [https://www.kernel.org kernel.org] and browse the git tree for linux-next to track long awaited fixes. Follow [https://www.phoronix.com forums and news] sites to track big changes within the linux community. Use the testing Mailing List to discuss upcoming upgrades, patches, kernels, etc.","title":"***Joining Software Testing Team***"},{"location":"articles/DEV_SoftwareTesting/#joining-software-testing-team","text":"If you wish to assist with software testing for Sabayon Linux, assistance is always welcome. We need testers to download ISO images and make sure they boot, install, no crashes/failures, and live on limbo repository. I wouldn't recommend this to someone who isn't familiar with virtual machines, partitioning, or is afraid of losing data on their machine. If you feel comfortable with those requirements, you may be a great candidate! Please contact someone in the #sabayon-dev IRC channel and let them know you're interested in joining the testing team. You will be contacted and request your email to be added to the testing group.","title":"Joining Software Testing Team"},{"location":"articles/DEV_SoftwareTesting/#what-kind-of-skills-do-i-need-or-need-to-learn-to-join-testing","text":"That actually depends on what skills you have and would like to learn. We're flexible and can teach you what you need to know. You just need to be prepared in case your machine loses its data. Backups! We plan to perform installs on virtual machines(BIOS/UEFI), bare metal machines(BIOS/UEFI), configure machines to our preferences, test graphics and wireless drivers/cards, check md5sums of ISO images, check the mirrors for up to date images, check that all hardware is recognized and working out of the box, run benchmarks, check for regressions, and look for solutions. The point is to catch problems before they arise for normal users looking for a mainstream release. You'll be living on the Sabayon bleeding edge in the limbo repository getting package updates before the rest of our users. Do you use your linux machine in a way that many people don't? Even better! this gives us more thorough testing. Even if you're fairly new to Linux, as long as you have the drive, patience, and willingness to learn. We can teach you what you need and/or want to know. IRC isn't always a quick communication method and tends to be used like old BBS message boards at times. You may not get an immediate response. We're all volunteers that have families and day jobs. So if you don't get an immediate response, leave the chat window open. You'll get a response sometime within the day. Some of us are even open to using alternative chat methods such as hangouts for direct contact.","title":"What kind of skills do I need (or need to learn) to join testing?"},{"location":"articles/DEV_SoftwareTesting/#what-if-the-issue-isnt-sabayon-linux-but-a-piece-of-software","text":"We lookup where to report the bugs and we file them accordingly. KDE, Gnome, atom, libreoffice, VLC, etc. gdb will be useful. They all have a place to report bugs. The more data on the bug and the more users reporting it, the easier it will be to get it fixed. Get comfortable with some [https://wiki.sabayon.org/index.php?title=Debugging_Symbols_-_splitdebug debugging] if you can.","title":"What if the issue isn't Sabayon Linux, but a piece of software?"},{"location":"articles/DEV_SoftwareTesting/#im-a-software-tester-where-do-i-start","text":"First there's the CORE. Hardware support, Virtual Machine support, Booting, Installing, Pre-installed basics. Next there's Spin dependent test. KDE- K3b working? QT5 working? systemsettings5 segfaulting? What if I notice an issue? This issue could be limited by hardware or a fluke by corruption or easily fixed. Time to communicate, email testing@sabayonlinux.org with your findings. We can all test and search out a fix together or file a bug with developers and mark a bug as \"confirmed\" by having multiple people post findings in the bug. This raises validity and priority. What if I'm looking at software that isn't installed by default? Same procedure! We can all look at the problem together to get updates, new software in the repository, patches, etc.","title":"I'm a Software Tester! Where do I start?"},{"location":"articles/DEV_SoftwareTesting/#core-list","text":"Does Sabayon greeter work? (GUI only) Does Calamares Installer work? Does Custom partitioning, LVM and/or encryption work? Does it boot after install? (UEFI and BIOS) Is your graphics card recognized? Does 3D acceleration work (OpenGL, Vulkan)? Does sound work? Does dmesg present any obvious errors? Does journalctl -xe present any obvious errors? Does USB3.X and/or type-C work? Does wireless/bluetooth work? (Intel, Broadcom, Atheros, Realtek, etc) Check for Library issues? (sudo equo libtest) Do bundled applications work? Perms issues? (allowed to ping as a user? Lockscreen not unlocking?) Found CVEs or Security Flaws? Test Rigo and Entropy?","title":"CORE LIST"},{"location":"articles/DEV_SoftwareTesting/#spin-dependent","text":"Many of these spin dependent softwares can be tested on a full running install with the limbo repository. Using an already running install is no replacement for Live disc and Install testing, but can let you test for broken software before its released. KDE - systemsettings5, gwenview, okular, k3b, dolphin, networkmanager, lockscreen, libreoffice, plasma5, MTP, steam, chrome. Gnome - brasero, control center, lockscreen, MTP, nm-applet, steam, tweaktool, libreoffice, chrome. MATE - Similar to Gnome package list + guake. LXQt - Does not use Anaconda by default. Should have (experimental) Calamares. Please test Calamares installer. CORE LIST + LXQt desktop, settings, file manager. Xfce - CORE LIST + Xfce desktop, settings, file manager. Server Minimal - CORE LIST CLI-Only (No GUI)","title":"SPIN DEPENDENT"},{"location":"articles/DEV_SoftwareTesting/#looking-deeper","text":"If you're curious and wish to look at performance changes and regressions. You're welcome to dig into newer software and kernels in search of fixes and performance boosts. Some software that could help with that could be as simple as a few free steam games such as DOTA2 and benchmark tools like [https://benchmark.unigine.com/heaven Unigine Benchmarks], or [http://www.iozone.org/ iozone]. Check [https://www.kernel.org kernel.org] and browse the git tree for linux-next to track long awaited fixes. Follow [https://www.phoronix.com forums and news] sites to track big changes within the linux community. Use the testing Mailing List to discuss upcoming upgrades, patches, kernels, etc.","title":"LOOKING DEEPER"},{"location":"articles/LUKS/","text":"Mounting LUKS Encrypted Volumes/Partitions NOTICE If you have lost or do not remember the passphrase you set, your data is just gone and there is nothing that can be done about it. Dont even ask. Using LVM If you are also using LVM then all of the steps found in that how-to EXCEPT issuing the mount command must be done first. The LVM must be prepped prior to your decrypting it. A change should also be noted that with LVM instead of decrypting something like /dev/sda3 you instead will find the volume to decrypt in /dev/mapper. You will have to do this manually, as the script that is in place in the LVM how-to automatically mounts the appropriate LVM volumes. If you use that script anyways and things dont work, dont say you haven't been warned. Mounting/Decrypting From the livecd you will need to go root, on the livecd the password for root is root. $ su Password: Next we will need a little information, namely which partition that the encrypted volume is on. If you have used encryption and LVM together you will have to mount the LVM first as documented elsewhere. For now, if you dont know or remember which partition you installed on we need to find out. # fdisk -lu There is no real way to see which exactly is the encrypted partition. What we can do here is look to see which is the largest partition with a linux type. If you have a single linux install, then typically this will be the largest partition listed as linux in the table. In other words look at how many blocks each has. Now that we have it we can set up to mount it. cd /mnt mkdir enc This made a mount point that we can use in a moment. Next we get to actually get the system to recognize and make the partition usable. cryptsetup luksOpen /dev/ encrypted Note that the are not used in the actual command /dev/sda2 is an example of what you might put there. We also assigned a name to it, that will come in handy in a moment. Finally we will mount the volume with: # mount /dev/mapper/encrypted /mnt/enc There we go, your volume is mounted. You now have access your data, make changes, chroot in, or whatever else that you needed to access the volume from the outside. Once you are done with whatever it was make sure to cleanly unmount the volume with : umount /mnt/enc cryptsetup luksClose /dev/mapper/encrypted Have a great one ~Az","title":"Mounting LUKS Encrypted Volumes/Partitions"},{"location":"articles/LUKS/#mounting-luks-encrypted-volumespartitions","text":"","title":"Mounting LUKS Encrypted Volumes/Partitions"},{"location":"articles/LUKS/#notice","text":"If you have lost or do not remember the passphrase you set, your data is just gone and there is nothing that can be done about it. Dont even ask.","title":"NOTICE"},{"location":"articles/LUKS/#using-lvm","text":"If you are also using LVM then all of the steps found in that how-to EXCEPT issuing the mount command must be done first. The LVM must be prepped prior to your decrypting it. A change should also be noted that with LVM instead of decrypting something like /dev/sda3 you instead will find the volume to decrypt in /dev/mapper. You will have to do this manually, as the script that is in place in the LVM how-to automatically mounts the appropriate LVM volumes. If you use that script anyways and things dont work, dont say you haven't been warned.","title":"Using LVM"},{"location":"articles/LUKS/#mountingdecrypting","text":"From the livecd you will need to go root, on the livecd the password for root is root. $ su Password: Next we will need a little information, namely which partition that the encrypted volume is on. If you have used encryption and LVM together you will have to mount the LVM first as documented elsewhere. For now, if you dont know or remember which partition you installed on we need to find out. # fdisk -lu There is no real way to see which exactly is the encrypted partition. What we can do here is look to see which is the largest partition with a linux type. If you have a single linux install, then typically this will be the largest partition listed as linux in the table. In other words look at how many blocks each has. Now that we have it we can set up to mount it.","title":"Mounting/Decrypting"},{"location":"articles/LUKS/#cd-mnt","text":"","title":"cd /mnt"},{"location":"articles/LUKS/#mkdir-enc","text":"This made a mount point that we can use in a moment. Next we get to actually get the system to recognize and make the partition usable.","title":"mkdir enc"},{"location":"articles/LUKS/#cryptsetup-luksopen-dev-encrypted","text":"","title":"cryptsetup luksOpen /dev/ encrypted"},{"location":"articles/LUKS/#umount-mntenc","text":"","title":"umount /mnt/enc"},{"location":"articles/LUKS/#cryptsetup-luksclose-devmapperencrypted","text":"Have a great one ~Az","title":"cryptsetup luksClose /dev/mapper/encrypted"},{"location":"articles/LVM/","text":"LVM - Logical Volume Managment LVM stands for Logical Volume Management. It is a system of managing logical volumes, or filesystems, that is much more advanced and flexible than the traditional method of partitioning a disk into one or more segments and formatting that partition with a filesystem. Why use LVM? So why would you want to use LVM when you can normal partitions just fine? The answer is that lvm can do resizes, moves, and normal things you could do with typical partitions, but includes tools for easier mgmt and snapshots. The Basics There are 3 things that LVM manages: **Volume Groups **Physical Volumes **Logical Volumes A Volume Group is a named collection of physical and logical volumes. Typical systems only need one Volume Group to contain all of the physical and logical volumes on the system. Physical Volumes correspond to disks; they are block devices that provide the space to store logical volumes. Logical volumes correspond to partitions: they hold a filesystem. Unlike partitions though, logical volumes get names rather than numbers, they can span across multiple disks, and do not have to be physically contiguous. The Specifics One of the biggest advantages LVM has is that most operations can be done on the fly, while the system is running. Most operations that you can do with gparted require that the partitions you are trying to manipulate not be in use at the time. You have to boot from a live image to perform the necessary resize, move, etc functions. LVM also circumvents the limits of the msdos partition table format with gparted, limiting you to only 4 primary partitions, and all logical partitions must be contained within one contiguous extended partition. Resizing Partitions With gparted you can expand and shrink partitions, but only if they are not in use. LVM can expand a partition while it is mounted, if the filesystem used on it also supports that ( like the usual ext3/4 ). When expanding a partition, gparted can only expand it into adjacent free space, but LVM can use free space anywhere in the Volume Group, even on another disk. Using typical paritions often means that you must move other partitions around to make space to expand one, which is a very time consuming process that can result in massive data loss if it fails or is interrupted ( power loss ). Moving Partitions Moving partitions with gparted is usually only necessary in the first place because of the requirement that partitions be physically contiguous. LVM isn't restricted in this way. LVM can move a partition while it is in use, and will not corrupt your data if it is interrupted. In the event that your system crashes or loses power during the move, you can simply restart it after rebooting and it will finish normally. One example would be installing a new SSD drive. Simply plug it in, boot it up, and ask lvm to move the running root filesystem to the new drive in the background while you continue working uninterrupted. Another reason you might want to move is to replace an old disk with a new, larger one. You can migrate the system to the new disk while using it, and then remove the old one later. Many Partitions If you like to test various Linux distributions, or run a server with many services, cloud storage, file sharing, etc. you can quickly end up with quite a few partitions. With conventional msdos partitions, this becomes problematic due to its limitations. With LVM you can create as many Logical Volumes as you wish, and it is usually quite easy since you usually have plenty of free space left. Usually people allocate the entire drive to one partition when they first install, but since extending a partition is so easy with LVM, there is no reason to do this. It is better to allocate only what you think you will need, and leave the rest of the space free for future use. If you end up running out of the initial allocation, adding more space to that volume is just one command that completes immediately while the system is running normally. Snapshots This is something you simply can not do without LVM or a filesystem using a snapshot function such as btrfs and zfs. It allows you to freeze an existing Logical Volume in time, at any moment, even while the system is running. You can continue to use the original volume normally, but the snapshot volume appears to be an image of the original, frozen in time at the moment you created it. You can use this to get a consistent filesystem image to back up, without shutting down the system. You can also use it to save the state of the system, so that you can later return to that state if you mess things up. You can even mount the snapshot volume and make changes to it, without affecting the original. So how do I start using LVM? Sadly Calamares support for LVM is severely lacking. You'll need to create your Logical Volume (lv) using parted , partitionmanager , or gparted before you can install on top of it. First, you need to know if you're using UEFI or old BIOS. If your machine was built after 2010, you'll most likely be using UEFI BIOS. UEFI booting requires the use of an EFI partition \"/boot/efi\" the size of 100M-300M at the beginning of the drive (sda1). Next you'll need another physical boot parition the size of 300M to 500M for /boot (sda2). Some machines cannot read a boot partition past 100G into the hard drive so keeping it closer to the beginning of the drive is wise. Using LVM could accidently let you move your boot partition into an unbootable location. Afterwards, you can use the rest of the space for a single LVM partition (sda3). Now there are a couple ways to proceed from here. Having an LVM partition does not immediately give you a Logical Volume. The Partition(s) which are Physical Volumes (pv) must be initialized with and added to a Volume Group (vg) and then the Volume Group (vg) acts as a \"virtual hard drive\" in which you must create partitions or Logical Volumes (lv). This can be done in KDE's partitionmanager , Gnome/MATE/XFCE's gparted , or in CLI. I'll assume the GUI methods can be self explanitory if you look around them, so I'll just show you the CLI way. Once you have your LVM partition, you need to initialize it as a Physical Volume. Assuming this partition is /dev/sda3: sudo pvcreate /dev/sda3 This writes the LVM header to the partition, which identifies it as a Physical Volume, and sets up a small area to hold the metadata describing everything about the Volume Group, and the the rest of the partition as unused Physical Extents. After that, you need to create a Volume Group and name it: sudo vgcreate {Your VG Name Here} /dev/sda3 Now you have a named Volume Group. It contains only one Physical Volume. Now you'll want to create a Logical Volume from some of the free space in your volume group: sudo lvcreate -n {Your LV Name Here} -L 500g {Your VG Name Here} This creates a named Logical Volume in your named Volume Group using 500 GB of space. If you are installing, you probably want to create a Logical Volume like this to use as a root filesystem, and one for swap, and maybe one for /home. You can find the block device for this Logical Volume in '/dev/{Your VG Name Here}/{Your LV Name Here}' or 'dev/mapper/{Your VG Name Here}-{Your LV Name Here}'. You might also want to try the lvs and pvs commands, which list the Logical Volumes and Physical Volumes respectively, and their more detailed variants; lvdisplay and pvdisplay . If you are doing this from the live image, once you have created your Logical Volumes from the terminal, you can run the calamres installer, and use manual partitioning to select how to use each Logical Volume, and then install. Resizing Partitions You can extend a Logical Volume with: sudo lvextend -L +5g {Your VG Name Here}/{Your LV Name Here} This will add 5 GB to the bar Logical Volume in the Volume Group. You can specify an absolute size if you want instead of a relative size by omitting the leading +. The space is allocated from any free space anywhere in the bar Volume Group. If you have multiple Physical Volumes you can add the names of one or more of them to the end of the command to limit which ones should be used to satisfy the request. After extending the Logical Volume you need to expand the filesystem to use the new space. For ext 3/4, you simply run: sudo resize2fs /dev/{Your VG Name Here}/{Your LV Name Here} Moving Partitions If you only have one Physical Volume then you probably will not ever need to move, but if you add a new disk, you might want to. To move the Logical Volume bar off of Physical Volume /dev/sda3, you run: sudo pvmove -n bar /dev/sda3 If you omit the -n bar argument, then all Logical Volumes on the /dev/sda3 Physical Volume will be moved. If you only have one other Physical Volume, then that is where it will be moved to, or you can add the name of one or more specific Physical Volumes that should be used to satisfy the request, instead of any Physical Volume in the Volume Group with free space. This process can be resumed safely if interrupted by a crash or power failure, and can be done while the Logical Volume(s) in question are in use. You can also add -b to perform the move in the background and return immediately, or -i s to have it print how much progress it has made every s seconds. If you background the move, you can check its progress with the lvs command. Snapshots When you create a snapshot, you create a new Logical Volume to act as a clone of the original Logical Volume. The snapshot volume initially does not use any space, but as changes are made to the original volume, the changed blocks are copied to the snapshot volume before they are changed, in order to preserve them. This means that the more changes you make to the origin, the more space the snapshot needs. If the snapshot volume uses all of the space allocated to it, then the snapshot is broken and can not be used any more, leaving you only with the modified origin. The lvs command will tell you how much space has been used in a snapshot Logical Volume. If it starts to get full, you might want to extend it with the lvextend command. To create a snapshot of the bar Logical Volume and name it snap, run: sudo lvcreate -s -n snap -L 5g {Your VG Name Here}/{Your LV Name Here} This will create a snapshot named snap of the original Logical Volume bar and allocate 5 GB of space for it. Since the snapshot volume only stores the ares of the disk that have changed since it was created, it can be much smaller than the original volume. While you have the snapshot, you can mount it if you wish and will see the original filesystem as it appeared when you made the snapshot. In the above example you would mount the /dev/{Your VG Name Here}/snap device. You can modify the snapshot without affecting the original, and the original without affecting the snapshot. If you take a snapshot of your root Logical Volume, and then upgrade some packages, or to the next whole distribution release, and then decide it isn't working out, you can merge the snapshot back into the origin volume, effectively reverting to the state at the time you made the snapshot. To do this, you simply run: sudo lvconvert --merge {Your VG Name Here}/snap If the origin volume of foo/snap is in use, it will inform you that the merge will take place the next time the volumes are activated. If this is the root volume, then you will need to reboot for this to happen. At the next boot, the volume will be activated and the merge will begin in the background, so your system will boot up as if you had never made the changes since the snapshot was created, and the actual data movement will take place in the background while you work. Mounting Additional LVMs Manually Mounting an LVM may seem a bit intimidating, it's not. In reality, despite the length of this entry, you will only be running a handful of commands, and most of those just to get the needed information. Do not despair, this will be as painless as possible. All of these commands will be run as root from a terminal. Please also remember that your volume names may differ from the guide, please make sure to adjust accordingly. root@localhost # pvs This should give you an output similar to root@localhost # pvs PV VG Fmt Attr PSize PFree /dev/sdb1 VolGroup00 lvm2 a- 7.88G 32.00M If we look closely we can see that /dev/sdb1 holds a lvm that is 7.88 gig in size. In this case, that's the one we want, as it is the only one. So now we want to see what is actually in that lvm root@localhost # lvdisplay /dev/VolGroup00 --- Logical volume --- LV Name /dev/VolGroup00/LogVol00 VG Name VolGroup00 LV UUID SWp2V0-1xPU-0tOP-UnPs-snxF-THUl-pZMKb2 LV Write Access read/write LV Status available # open 0 LV Size 6.88 GB Current LE 220 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 251:0 --- Logical volume --- LV Name /dev/VolGroup00/LogVol01 VG Name VolGroup00 LV UUID MGBeJP-ohrX-KLju-5V78-iJOi-pP3w-huaOmC LV Write Access read/write LV Status available # open 0 LV Size 992.00 MB Current LE 31 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 251:1 We are looking for two things out of that list: LV name and LV Size . We have one that is 6.88 GB and one that is 992 MB . We can safely assume that the smaller of the two is /swap so the larger must be our real filesystem. That one is named /dev/VolGroup00/LogVol00 . So now we have all the information that we need. We need only to make a mount point and actually mount the volume. cd /mnt mkdir lvm vgscan --mknodes lvchange -a y /dev/VolGroup00/LogVol00 mount /dev/VolGroup00/LogVol00 /mnt/lvm If all went well then we can now get inside and look around, make changes, chroot in, or whatever caused us to want to mount the LVM in the first place. Mounting Additional LVMs Automatically using a script The following is a script that will do all of that for you, in a slightly different way. You need only copy and paste the text in the box below to a text file that you make on your system. Once you copy and paste, save the file and go root, alternately you may download the script file [http://forum.sabayonlinux.org/viewtopic.php?f=86 t=17272 p=99187#p99187 this thread] from the forums. If you download from the forums, don't forget to rename the file lvm-mount.sh . Either way you do it, after the file is saved you need to go root and run the following commands: # chmod a+x lvm-mount.sh # sh lvm-mount.sh The script will then run and let you know where is mounted your LVM(s) for you. It will also print instructions on your screen as to how to chroot in to the LVM if that was what you were needing to do. lvm-mount.sh ! /bin/bash This script is released under the GPL version 2 copyright (2009) James Cook Thanks goes to Klaus Knopper who reminded me of something very simple that I had forgotten at the time, thanks bud. the author may be contacted at: azerthoth (at) gmail.com Check for user is root Thanks to micia for the suggestion if [ $UID -ne 0 ]; then echo \"You need to be root to run this script!\" exit 1 fi get them all into /dev/mapper modprobe dm-mod 2 /dev/null || : vgscan --ignorelockingfailure --mknodes || : vgchange -aly --ignorelockingfailure || return 2 clear mkdir /LVM cd /dev/mapper Create directories and mount for FILE in *; do test -b \"$FILE\" mkdir /LVM/$FILE mount /dev/mapper/$FILE /LVM/$FILE 2 /dev/null done List good partitions echo \"Cleaning up LVMs that were swap partitions or with unsupported\" echo \"File Systems from the list. This will not effect those partitions\" echo \"There is just no need to list or parse them\" rmdir /LVM/Vol* 2 /dev/null\" echo \" \" echo \"The following LVM(s) were mounted for you and are ready to use\" echo \" \" ls /LVM echo \" \" echo \"You can find them in /LVM\" echo \" \" chroot instructions echo \"If you are rescuing/fixing a previous installation please issue\" echo \"the following commands\" echo \"cp -L /etc/resolv.conf /LVM/ /etc/resolv.conf\" echo \"mount -t proc none /LVM/ /proc\" echo \"mount -o bind /dev /LVM/ /dev\" echo \"chroot /LVM/ /bin/bash\" echo \"env-update\" echo \"source /etc/profile\" this process may also be interactively automated in the future more coffee and ambition is needed","title":"LVM - Logical Volume Managment"},{"location":"articles/LVM/#lvm-logical-volume-managment","text":"LVM stands for Logical Volume Management. It is a system of managing logical volumes, or filesystems, that is much more advanced and flexible than the traditional method of partitioning a disk into one or more segments and formatting that partition with a filesystem.","title":"LVM - Logical Volume Managment"},{"location":"articles/LVM/#why-use-lvm","text":"So why would you want to use LVM when you can normal partitions just fine? The answer is that lvm can do resizes, moves, and normal things you could do with typical partitions, but includes tools for easier mgmt and snapshots.","title":"Why use LVM?"},{"location":"articles/LVM/#the-basics","text":"There are 3 things that LVM manages: **Volume Groups **Physical Volumes **Logical Volumes A Volume Group is a named collection of physical and logical volumes. Typical systems only need one Volume Group to contain all of the physical and logical volumes on the system. Physical Volumes correspond to disks; they are block devices that provide the space to store logical volumes. Logical volumes correspond to partitions: they hold a filesystem. Unlike partitions though, logical volumes get names rather than numbers, they can span across multiple disks, and do not have to be physically contiguous.","title":"The Basics"},{"location":"articles/LVM/#the-specifics","text":"One of the biggest advantages LVM has is that most operations can be done on the fly, while the system is running. Most operations that you can do with gparted require that the partitions you are trying to manipulate not be in use at the time. You have to boot from a live image to perform the necessary resize, move, etc functions. LVM also circumvents the limits of the msdos partition table format with gparted, limiting you to only 4 primary partitions, and all logical partitions must be contained within one contiguous extended partition.","title":"The Specifics"},{"location":"articles/LVM/#resizing-partitions","text":"With gparted you can expand and shrink partitions, but only if they are not in use. LVM can expand a partition while it is mounted, if the filesystem used on it also supports that ( like the usual ext3/4 ). When expanding a partition, gparted can only expand it into adjacent free space, but LVM can use free space anywhere in the Volume Group, even on another disk. Using typical paritions often means that you must move other partitions around to make space to expand one, which is a very time consuming process that can result in massive data loss if it fails or is interrupted ( power loss ).","title":"Resizing Partitions"},{"location":"articles/LVM/#moving-partitions","text":"Moving partitions with gparted is usually only necessary in the first place because of the requirement that partitions be physically contiguous. LVM isn't restricted in this way. LVM can move a partition while it is in use, and will not corrupt your data if it is interrupted. In the event that your system crashes or loses power during the move, you can simply restart it after rebooting and it will finish normally. One example would be installing a new SSD drive. Simply plug it in, boot it up, and ask lvm to move the running root filesystem to the new drive in the background while you continue working uninterrupted. Another reason you might want to move is to replace an old disk with a new, larger one. You can migrate the system to the new disk while using it, and then remove the old one later.","title":"Moving Partitions"},{"location":"articles/LVM/#many-partitions","text":"If you like to test various Linux distributions, or run a server with many services, cloud storage, file sharing, etc. you can quickly end up with quite a few partitions. With conventional msdos partitions, this becomes problematic due to its limitations. With LVM you can create as many Logical Volumes as you wish, and it is usually quite easy since you usually have plenty of free space left. Usually people allocate the entire drive to one partition when they first install, but since extending a partition is so easy with LVM, there is no reason to do this. It is better to allocate only what you think you will need, and leave the rest of the space free for future use. If you end up running out of the initial allocation, adding more space to that volume is just one command that completes immediately while the system is running normally.","title":"Many Partitions"},{"location":"articles/LVM/#snapshots","text":"This is something you simply can not do without LVM or a filesystem using a snapshot function such as btrfs and zfs. It allows you to freeze an existing Logical Volume in time, at any moment, even while the system is running. You can continue to use the original volume normally, but the snapshot volume appears to be an image of the original, frozen in time at the moment you created it. You can use this to get a consistent filesystem image to back up, without shutting down the system. You can also use it to save the state of the system, so that you can later return to that state if you mess things up. You can even mount the snapshot volume and make changes to it, without affecting the original.","title":"Snapshots"},{"location":"articles/LVM/#so-how-do-i-start-using-lvm","text":"Sadly Calamares support for LVM is severely lacking. You'll need to create your Logical Volume (lv) using parted , partitionmanager , or gparted before you can install on top of it. First, you need to know if you're using UEFI or old BIOS. If your machine was built after 2010, you'll most likely be using UEFI BIOS. UEFI booting requires the use of an EFI partition \"/boot/efi\" the size of 100M-300M at the beginning of the drive (sda1). Next you'll need another physical boot parition the size of 300M to 500M for /boot (sda2). Some machines cannot read a boot partition past 100G into the hard drive so keeping it closer to the beginning of the drive is wise. Using LVM could accidently let you move your boot partition into an unbootable location. Afterwards, you can use the rest of the space for a single LVM partition (sda3). Now there are a couple ways to proceed from here. Having an LVM partition does not immediately give you a Logical Volume. The Partition(s) which are Physical Volumes (pv) must be initialized with and added to a Volume Group (vg) and then the Volume Group (vg) acts as a \"virtual hard drive\" in which you must create partitions or Logical Volumes (lv). This can be done in KDE's partitionmanager , Gnome/MATE/XFCE's gparted , or in CLI. I'll assume the GUI methods can be self explanitory if you look around them, so I'll just show you the CLI way. Once you have your LVM partition, you need to initialize it as a Physical Volume. Assuming this partition is /dev/sda3: sudo pvcreate /dev/sda3 This writes the LVM header to the partition, which identifies it as a Physical Volume, and sets up a small area to hold the metadata describing everything about the Volume Group, and the the rest of the partition as unused Physical Extents. After that, you need to create a Volume Group and name it: sudo vgcreate {Your VG Name Here} /dev/sda3 Now you have a named Volume Group. It contains only one Physical Volume. Now you'll want to create a Logical Volume from some of the free space in your volume group: sudo lvcreate -n {Your LV Name Here} -L 500g {Your VG Name Here} This creates a named Logical Volume in your named Volume Group using 500 GB of space. If you are installing, you probably want to create a Logical Volume like this to use as a root filesystem, and one for swap, and maybe one for /home. You can find the block device for this Logical Volume in '/dev/{Your VG Name Here}/{Your LV Name Here}' or 'dev/mapper/{Your VG Name Here}-{Your LV Name Here}'. You might also want to try the lvs and pvs commands, which list the Logical Volumes and Physical Volumes respectively, and their more detailed variants; lvdisplay and pvdisplay . If you are doing this from the live image, once you have created your Logical Volumes from the terminal, you can run the calamres installer, and use manual partitioning to select how to use each Logical Volume, and then install.","title":"So how do I start using LVM?"},{"location":"articles/LVM/#resizing-partitions_1","text":"You can extend a Logical Volume with: sudo lvextend -L +5g {Your VG Name Here}/{Your LV Name Here} This will add 5 GB to the bar Logical Volume in the Volume Group. You can specify an absolute size if you want instead of a relative size by omitting the leading +. The space is allocated from any free space anywhere in the bar Volume Group. If you have multiple Physical Volumes you can add the names of one or more of them to the end of the command to limit which ones should be used to satisfy the request. After extending the Logical Volume you need to expand the filesystem to use the new space. For ext 3/4, you simply run: sudo resize2fs /dev/{Your VG Name Here}/{Your LV Name Here}","title":"Resizing Partitions"},{"location":"articles/LVM/#moving-partitions_1","text":"If you only have one Physical Volume then you probably will not ever need to move, but if you add a new disk, you might want to. To move the Logical Volume bar off of Physical Volume /dev/sda3, you run: sudo pvmove -n bar /dev/sda3 If you omit the -n bar argument, then all Logical Volumes on the /dev/sda3 Physical Volume will be moved. If you only have one other Physical Volume, then that is where it will be moved to, or you can add the name of one or more specific Physical Volumes that should be used to satisfy the request, instead of any Physical Volume in the Volume Group with free space. This process can be resumed safely if interrupted by a crash or power failure, and can be done while the Logical Volume(s) in question are in use. You can also add -b to perform the move in the background and return immediately, or -i s to have it print how much progress it has made every s seconds. If you background the move, you can check its progress with the lvs command.","title":"Moving Partitions"},{"location":"articles/LVM/#snapshots_1","text":"When you create a snapshot, you create a new Logical Volume to act as a clone of the original Logical Volume. The snapshot volume initially does not use any space, but as changes are made to the original volume, the changed blocks are copied to the snapshot volume before they are changed, in order to preserve them. This means that the more changes you make to the origin, the more space the snapshot needs. If the snapshot volume uses all of the space allocated to it, then the snapshot is broken and can not be used any more, leaving you only with the modified origin. The lvs command will tell you how much space has been used in a snapshot Logical Volume. If it starts to get full, you might want to extend it with the lvextend command. To create a snapshot of the bar Logical Volume and name it snap, run: sudo lvcreate -s -n snap -L 5g {Your VG Name Here}/{Your LV Name Here} This will create a snapshot named snap of the original Logical Volume bar and allocate 5 GB of space for it. Since the snapshot volume only stores the ares of the disk that have changed since it was created, it can be much smaller than the original volume. While you have the snapshot, you can mount it if you wish and will see the original filesystem as it appeared when you made the snapshot. In the above example you would mount the /dev/{Your VG Name Here}/snap device. You can modify the snapshot without affecting the original, and the original without affecting the snapshot. If you take a snapshot of your root Logical Volume, and then upgrade some packages, or to the next whole distribution release, and then decide it isn't working out, you can merge the snapshot back into the origin volume, effectively reverting to the state at the time you made the snapshot. To do this, you simply run: sudo lvconvert --merge {Your VG Name Here}/snap If the origin volume of foo/snap is in use, it will inform you that the merge will take place the next time the volumes are activated. If this is the root volume, then you will need to reboot for this to happen. At the next boot, the volume will be activated and the merge will begin in the background, so your system will boot up as if you had never made the changes since the snapshot was created, and the actual data movement will take place in the background while you work.","title":"Snapshots"},{"location":"articles/LVM/#mounting-additional-lvms-manually","text":"Mounting an LVM may seem a bit intimidating, it's not. In reality, despite the length of this entry, you will only be running a handful of commands, and most of those just to get the needed information. Do not despair, this will be as painless as possible. All of these commands will be run as root from a terminal. Please also remember that your volume names may differ from the guide, please make sure to adjust accordingly. root@localhost # pvs This should give you an output similar to root@localhost # pvs PV VG Fmt Attr PSize PFree /dev/sdb1 VolGroup00 lvm2 a- 7.88G 32.00M If we look closely we can see that /dev/sdb1 holds a lvm that is 7.88 gig in size. In this case, that's the one we want, as it is the only one. So now we want to see what is actually in that lvm root@localhost # lvdisplay /dev/VolGroup00 --- Logical volume --- LV Name /dev/VolGroup00/LogVol00 VG Name VolGroup00 LV UUID SWp2V0-1xPU-0tOP-UnPs-snxF-THUl-pZMKb2 LV Write Access read/write LV Status available # open 0 LV Size 6.88 GB Current LE 220 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 251:0 --- Logical volume --- LV Name /dev/VolGroup00/LogVol01 VG Name VolGroup00 LV UUID MGBeJP-ohrX-KLju-5V78-iJOi-pP3w-huaOmC LV Write Access read/write LV Status available # open 0 LV Size 992.00 MB Current LE 31 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 256 Block device 251:1 We are looking for two things out of that list: LV name and LV Size . We have one that is 6.88 GB and one that is 992 MB . We can safely assume that the smaller of the two is /swap so the larger must be our real filesystem. That one is named /dev/VolGroup00/LogVol00 . So now we have all the information that we need. We need only to make a mount point and actually mount the volume.","title":"Mounting Additional LVMs Manually"},{"location":"articles/LVM/#cd-mnt","text":"","title":"cd /mnt"},{"location":"articles/LVM/#mkdir-lvm","text":"","title":"mkdir lvm"},{"location":"articles/LVM/#vgscan-mknodes","text":"","title":"vgscan --mknodes"},{"location":"articles/LVM/#lvchange-a-y-devvolgroup00logvol00","text":"","title":"lvchange -a y /dev/VolGroup00/LogVol00"},{"location":"articles/LVM/#mount-devvolgroup00logvol00-mntlvm","text":"If all went well then we can now get inside and look around, make changes, chroot in, or whatever caused us to want to mount the LVM in the first place.","title":"mount /dev/VolGroup00/LogVol00 /mnt/lvm"},{"location":"articles/LVM/#mounting-additional-lvms-automatically-using-a-script","text":"The following is a script that will do all of that for you, in a slightly different way. You need only copy and paste the text in the box below to a text file that you make on your system. Once you copy and paste, save the file and go root, alternately you may download the script file [http://forum.sabayonlinux.org/viewtopic.php?f=86 t=17272 p=99187#p99187 this thread] from the forums. If you download from the forums, don't forget to rename the file lvm-mount.sh . Either way you do it, after the file is saved you need to go root and run the following commands: # chmod a+x lvm-mount.sh # sh lvm-mount.sh The script will then run and let you know where is mounted your LVM(s) for you. It will also print instructions on your screen as to how to chroot in to the LVM if that was what you were needing to do. lvm-mount.sh","title":"Mounting Additional LVMs Automatically using a script"},{"location":"articles/LVM/#binbash","text":"","title":"! /bin/bash"},{"location":"articles/LVM/#this-script-is-released-under-the-gpl-version-2","text":"","title":"This script is released under the GPL version 2"},{"location":"articles/LVM/#copyright-2009-james-cook","text":"","title":"copyright (2009) James Cook"},{"location":"articles/LVM/#thanks-goes-to-klaus-knopper-who-reminded-me-of-something","text":"","title":"Thanks goes to Klaus Knopper who reminded me of something"},{"location":"articles/LVM/#very-simple-that-i-had-forgotten-at-the-time-thanks-bud","text":"","title":"very simple that I had forgotten at the time, thanks bud."},{"location":"articles/LVM/#the-author-may-be-contacted-at","text":"","title":"the author may be contacted at:"},{"location":"articles/LVM/#azerthoth-at-gmailcom","text":"","title":"azerthoth (at) gmail.com"},{"location":"articles/LVM/#check-for-user-is-root","text":"","title":"Check for user is root"},{"location":"articles/LVM/#thanks-to-micia-for-the-suggestion","text":"if [ $UID -ne 0 ]; then echo \"You need to be root to run this script!\" exit 1 fi","title":"Thanks to micia for the suggestion"},{"location":"articles/LVM/#get-them-all-into-devmapper","text":"modprobe dm-mod 2 /dev/null || : vgscan --ignorelockingfailure --mknodes || : vgchange -aly --ignorelockingfailure || return 2 clear mkdir /LVM cd /dev/mapper","title":"get them all into /dev/mapper"},{"location":"articles/LVM/#create-directories-and-mount","text":"for FILE in *; do test -b \"$FILE\" mkdir /LVM/$FILE mount /dev/mapper/$FILE /LVM/$FILE 2 /dev/null done","title":"Create directories and mount"},{"location":"articles/LVM/#list-good-partitions","text":"echo \"Cleaning up LVMs that were swap partitions or with unsupported\" echo \"File Systems from the list. This will not effect those partitions\" echo \"There is just no need to list or parse them\" rmdir /LVM/Vol* 2 /dev/null\" echo \" \" echo \"The following LVM(s) were mounted for you and are ready to use\" echo \" \" ls /LVM echo \" \" echo \"You can find them in /LVM\" echo \" \"","title":"List good partitions"},{"location":"articles/LVM/#chroot-instructions","text":"echo \"If you are rescuing/fixing a previous installation please issue\" echo \"the following commands\" echo \"cp -L /etc/resolv.conf /LVM/ /etc/resolv.conf\" echo \"mount -t proc none /LVM/ /proc\" echo \"mount -o bind /dev /LVM/ /dev\" echo \"chroot /LVM/ /bin/bash\" echo \"env-update\" echo \"source /etc/profile\"","title":"chroot instructions"},{"location":"articles/LVM/#this-process-may-also-be-interactively-automated-in-the-future","text":"","title":"this process may also be interactively automated in the future"},{"location":"articles/LVM/#more-coffee-and-ambition-is-needed","text":"","title":"more coffee and ambition is needed"},{"location":"articles/Removing_DEs/","text":"KDE WARNING Before removing a Desktop Environment like KDE, you have to keep a few things in mind; it will remove tons and tons of stuff, probably more than you want to be removed. Removing too much might leave your system unusable. * Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates,there is no real harm in having kde installed. If you don't use it, it won't hinder performance. Preparation For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial KDE will be replaced with XFCE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install @xfce --ask from Rigo: enter: xfce4-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install xfce4-meta accept the licence agreement. logoff, and logon again into the fresh installed Environment. (NOT KDE) Removing KDE So now we're logged in with XFCE. open your favourite terminal, and become root. enter following in the terminal: equo remove kdelibs --ask --deep check the package list before proceeding. NOTICE It might very well be possible, that Entropy wants to remove vital packages for XFCE as well., so chances are that after a reboot the system is unusable. In that case, when KDE is removed., before rebooting, (just in case) simply reinstall your new DE, eg.: equo install @xfce Final Steps When done, a few final steps, enter equo conf update to check if configuration files needs to be updated, manually. perform a equo deptest and equo libtest . and remove the .kde4 directory in your home folder... rm -rf /home/your-username/.kde4 and .kderc : rm -rf /home/your-username/.kderc Gnome WARNING Before removing any Desktop Environment such as Gnome, you have to keep a few things in mind: Many libraries are shared with other DE's, so you don't want them to be removed. Removing too much might leave your system unusable. * Be sure to have an alternative DM installed. (lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, There is no real harm in having Gnome installed. If you don't use it, it won't hinder performance. Preparation For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial Gnome will be replaced with XFCE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: this can be KDE (plasma-meta), mate, etc. We're using xfce for this demonstration. # equo install @xfce --ask from Rigo: enter: xfce4-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install xfce4-meta accept the licence agreement. GDM will also be removed, so install a alternative LoginManager: (in this case, i choose lightdm, it works with everything) # equo install lightdm Switching DMs Remove from boot entry starting GDM: # systemctl disable gdm.service Now enable new LoginManager to start at boot: # systemctl enable lightdm.service When done, logoff, and logon again into the fresh installed Environment. (NOT Gnome) Removing Gnome WARNING Don't forget --nodeps without the \"--nodeps\", KDE, XFCE, important libraries, and even nvidia-drivers get pulled. This can wreck your system! So now we're logged in with XFCE. install and open your favorite terminal (except Gnome-terminal), and become root. enter following in the terminal: equo install gentoolkit equery list \"*\" | grep 'gnome|evolution|folks|evince|deja-dup|brasero|totem|mutter|shotwell|eog|cheese|gedit|libgdata|geocode-glib|gnote|baobab|caribou|rhythmbox|grilo|libgweather|alacarte' | xargs equo remove --nodeps WARNING Do NOT Reboot! Do NOT reboot until you've performed the final steps! Final Steps Now we need to check for possible broken dependencies and libraries that may pull something back in. # equo deptest # equo libtest # equo conf update # reboot MATE NOTICE Before removing a Desktop Environment, you have to keep a few things in mind; Removing too much might leave your system unusable. Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, there is no real harm in having Mate installed. If you don't use it, it won't hinder performance. Preparation For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial Mate will be replaced with KDE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install kde-meta --ask from Rigo: enter: kde-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install kde-meta . Removing Mate So now we're logged in with KDE. open your favourite terminal, and become root. enter following in the terminal: equo query installed mate | xargs equo remove --nodeps ignore all the warnings NOTICE without the \"--nodeps\", \"sys-auth/pambase-20101024-r2\" got pulled, and aborts the mission. Also, don't use the --deep flag here Final Steps NOTICE before rebooting, you must reinstall \"sys-apps/dbus\" and \"x11-apps/scripts\" otherwise the system becomes unusable. equo install sys-apps/dbus x11-apps/scripts When done, a final step, enter equo conf update to check if configuration files needs to be updated, manually. XFCE NOTICE Before removing a Desktop Environment like XFCE, you have to keep a few things in mind; Removing too much might leave your system unusable. Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, there is no real harm in having XFCE installed. If you don't use it, it won't hinder performance. Preparation For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial XFCE will be replaced with Mate. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install mate --ask from Rigo: enter: mate in the searchbox, select the meta package, and click install, or install directly using a shortcut in the searchbox: do:install mate . With removing XFCE, lightdm stays untouched, so we don't have to install a alternative LoginManager. When done, logoff, and logon again into the fresh installed Environment. (NOT XFCE) Removing XFCE So now we're logged in with Mate. open your favourite terminal, and become root. enter following in the terminal: equo remove libxfce4util xfconf --ask check the package list before proceeding. NOTICE In contrary with removing KDE, DON'T use the \"--deep\" flag here. With the \"--deep\" flag enabled, it removes also some system files, which deptest and libtest don't recover, so chances are that after a reboot the system is unusable. WARNING The packages \"mate-base/mate\" and \"virtual/notification-daemon\" are going to be removed as well !!! Before you reboot, you MUST first reinstall those packages., please see Final steps. Final Steps When done, a few final steps. In the terminal, as root type: # equo install mate and: # equo install notification-daemon from Rigo: enter: mate in the searchbox, select the meta package, and click install, and repeat the same steps for the daemon, replacing mate with: notification-daemon or install directly using a shortcut in the searchbox: do:install mate / do:install notification-daemon Enter equo conf update in the terminal to check if configuration files needs to be updated, manually. You could perform a equo deptest and equo libtest ., although not really needed. and eventually you could remove the packages \"gtk-engines-xfce\" and \"xfce4-taskmanager\" equo remove gtk-engines-xfce xfce4-taskmanager","title":"KDE"},{"location":"articles/Removing_DEs/#kde","text":"","title":"KDE"},{"location":"articles/Removing_DEs/#warning","text":"Before removing a Desktop Environment like KDE, you have to keep a few things in mind; it will remove tons and tons of stuff, probably more than you want to be removed. Removing too much might leave your system unusable. * Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates,there is no real harm in having kde installed. If you don't use it, it won't hinder performance.","title":"WARNING"},{"location":"articles/Removing_DEs/#preparation","text":"For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial KDE will be replaced with XFCE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install @xfce --ask from Rigo: enter: xfce4-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install xfce4-meta accept the licence agreement. logoff, and logon again into the fresh installed Environment. (NOT KDE)","title":"Preparation"},{"location":"articles/Removing_DEs/#removing-kde","text":"So now we're logged in with XFCE. open your favourite terminal, and become root. enter following in the terminal: equo remove kdelibs --ask --deep check the package list before proceeding.","title":"Removing KDE"},{"location":"articles/Removing_DEs/#notice","text":"It might very well be possible, that Entropy wants to remove vital packages for XFCE as well., so chances are that after a reboot the system is unusable. In that case, when KDE is removed., before rebooting, (just in case) simply reinstall your new DE, eg.: equo install @xfce","title":"NOTICE"},{"location":"articles/Removing_DEs/#final-steps","text":"When done, a few final steps, enter equo conf update to check if configuration files needs to be updated, manually. perform a equo deptest and equo libtest . and remove the .kde4 directory in your home folder... rm -rf /home/your-username/.kde4 and .kderc : rm -rf /home/your-username/.kderc","title":"Final Steps"},{"location":"articles/Removing_DEs/#gnome","text":"","title":"Gnome"},{"location":"articles/Removing_DEs/#warning_1","text":"Before removing any Desktop Environment such as Gnome, you have to keep a few things in mind: Many libraries are shared with other DE's, so you don't want them to be removed. Removing too much might leave your system unusable. * Be sure to have an alternative DM installed. (lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, There is no real harm in having Gnome installed. If you don't use it, it won't hinder performance.","title":"WARNING"},{"location":"articles/Removing_DEs/#preparation_1","text":"For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial Gnome will be replaced with XFCE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: this can be KDE (plasma-meta), mate, etc. We're using xfce for this demonstration. # equo install @xfce --ask from Rigo: enter: xfce4-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install xfce4-meta accept the licence agreement. GDM will also be removed, so install a alternative LoginManager: (in this case, i choose lightdm, it works with everything) # equo install lightdm","title":"Preparation"},{"location":"articles/Removing_DEs/#switching-dms","text":"Remove from boot entry starting GDM: # systemctl disable gdm.service Now enable new LoginManager to start at boot: # systemctl enable lightdm.service When done, logoff, and logon again into the fresh installed Environment. (NOT Gnome)","title":"Switching DMs"},{"location":"articles/Removing_DEs/#removing-gnome","text":"","title":"Removing Gnome"},{"location":"articles/Removing_DEs/#warning_2","text":"Don't forget --nodeps without the \"--nodeps\", KDE, XFCE, important libraries, and even nvidia-drivers get pulled. This can wreck your system! So now we're logged in with XFCE. install and open your favorite terminal (except Gnome-terminal), and become root. enter following in the terminal: equo install gentoolkit equery list \"*\" | grep 'gnome|evolution|folks|evince|deja-dup|brasero|totem|mutter|shotwell|eog|cheese|gedit|libgdata|geocode-glib|gnote|baobab|caribou|rhythmbox|grilo|libgweather|alacarte' | xargs equo remove --nodeps","title":"WARNING"},{"location":"articles/Removing_DEs/#warning_3","text":"Do NOT Reboot! Do NOT reboot until you've performed the final steps!","title":"WARNING"},{"location":"articles/Removing_DEs/#final-steps_1","text":"Now we need to check for possible broken dependencies and libraries that may pull something back in. # equo deptest # equo libtest # equo conf update # reboot","title":"Final Steps"},{"location":"articles/Removing_DEs/#mate","text":"","title":"MATE"},{"location":"articles/Removing_DEs/#notice_1","text":"Before removing a Desktop Environment, you have to keep a few things in mind; Removing too much might leave your system unusable. Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, there is no real harm in having Mate installed. If you don't use it, it won't hinder performance.","title":"NOTICE"},{"location":"articles/Removing_DEs/#preparation_2","text":"For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial Mate will be replaced with KDE. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install kde-meta --ask from Rigo: enter: kde-meta in the searchbox, select the package, and click install, or install directly using a shortcut in the searchbox: do:install kde-meta .","title":"Preparation"},{"location":"articles/Removing_DEs/#removing-mate","text":"So now we're logged in with KDE. open your favourite terminal, and become root. enter following in the terminal: equo query installed mate | xargs equo remove --nodeps ignore all the warnings","title":"Removing Mate"},{"location":"articles/Removing_DEs/#notice_2","text":"without the \"--nodeps\", \"sys-auth/pambase-20101024-r2\" got pulled, and aborts the mission. Also, don't use the --deep flag here","title":"NOTICE"},{"location":"articles/Removing_DEs/#final-steps_2","text":"","title":"Final Steps"},{"location":"articles/Removing_DEs/#notice_3","text":"before rebooting, you must reinstall \"sys-apps/dbus\" and \"x11-apps/scripts\" otherwise the system becomes unusable. equo install sys-apps/dbus x11-apps/scripts When done, a final step, enter equo conf update to check if configuration files needs to be updated, manually.","title":"NOTICE"},{"location":"articles/Removing_DEs/#xfce","text":"","title":"XFCE"},{"location":"articles/Removing_DEs/#notice_4","text":"Before removing a Desktop Environment like XFCE, you have to keep a few things in mind; Removing too much might leave your system unusable. Be sure to have an alternative DM installed. (gdm or lightdm) That said, unless you are running out of hard drive space or have limited bandwidth for updates, there is no real harm in having XFCE installed. If you don't use it, it won't hinder performance.","title":"NOTICE"},{"location":"articles/Removing_DEs/#preparation_3","text":"For this to work, the best way of doing this is to first install a alternative Desktop Environment. In this tutorial XFCE will be replaced with Mate. open a console/terminal and become root. (of course you can also do this with Rigo install your alternative Desktop Environment: # equo install mate --ask from Rigo: enter: mate in the searchbox, select the meta package, and click install, or install directly using a shortcut in the searchbox: do:install mate . With removing XFCE, lightdm stays untouched, so we don't have to install a alternative LoginManager. When done, logoff, and logon again into the fresh installed Environment. (NOT XFCE)","title":"Preparation"},{"location":"articles/Removing_DEs/#removing-xfce","text":"So now we're logged in with Mate. open your favourite terminal, and become root. enter following in the terminal: equo remove libxfce4util xfconf --ask check the package list before proceeding.","title":"Removing XFCE"},{"location":"articles/Removing_DEs/#notice_5","text":"In contrary with removing KDE, DON'T use the \"--deep\" flag here. With the \"--deep\" flag enabled, it removes also some system files, which deptest and libtest don't recover, so chances are that after a reboot the system is unusable.","title":"NOTICE"},{"location":"articles/Removing_DEs/#warning_4","text":"The packages \"mate-base/mate\" and \"virtual/notification-daemon\" are going to be removed as well !!! Before you reboot, you MUST first reinstall those packages., please see Final steps.","title":"WARNING"},{"location":"articles/Removing_DEs/#final-steps_3","text":"When done, a few final steps. In the terminal, as root type: # equo install mate and: # equo install notification-daemon from Rigo: enter: mate in the searchbox, select the meta package, and click install, and repeat the same steps for the daemon, replacing mate with: notification-daemon or install directly using a shortcut in the searchbox: do:install mate / do:install notification-daemon Enter equo conf update in the terminal to check if configuration files needs to be updated, manually. You could perform a equo deptest and equo libtest ., although not really needed. and eventually you could remove the packages \"gtk-engines-xfce\" and \"xfce4-taskmanager\" equo remove gtk-engines-xfce xfce4-taskmanager","title":"Final Steps"},{"location":"articles/SSH_Single_Signon/","text":"SSH Single SignOn (SSO) Concept If you work with multiple *nix-based machines via ssh, you are probably tired of constantly having to enter your password every time you want to access another box. There is a secure way to allow you to access every machine, that you have ssh access to, without having to enter another password (other than the one you signed on with originally.) This is actually quite simple to do, you basically just create a public/private key pair to authenticate yourself to your other machines, then have PAM spawn an agent to load your keys after you logon, providing a single signon solution to accessing all your remote machines. This guide will walk you through setting this up. Equo Stuff First of all, we are going to need the pam_ssh module. You may already have this installed, if not equo it. I'm going to assume you already have openssh installed, as every system should. # equo install pam_ssh Create Key Pair Now we need to create the key pair to authenticate yourself across the network. To do so, run this as your regular user . WARNING: This should NOT be done as root, and you should never, ever ssh using the root account $ ssh-keygen -t dsa This will ask where to save the file, just press enter as the default is what we want. After that it will ask for the passphrase you want to use. It is important to set the passphrase to the exact same password as your normal logon password for this user. This is the password for the user on the current machine, not the one for other machines, even if they differ. When that is done, two files should of been created ~/.ssh/id_dsa and ~/.ssh/id_dsa.pub . NOTE: It is very important to keep ~/.ssh/id_dsa private , it should be only readable by your user, to make sure of this, run this command: $ chmod 600 ~/.ssh/id_dsa Distribute Public Key Now we need to give all of our remote machines our public key so we can use it to authenticate. This is very simple to do, run the following command as your user for each remote system you want to setup the passwordless authentication for. $ ssh-copy-id -i ~/.ssh/id_dsa.pub username@remotehostname Configure PAM We need to tell PAM to use our logon password to spawn an ssh-agent and load the rsa key we just made. There are two lines for pam_ssh.so we need to add, so your system-auth should look something like this: /etc/pam.d/system-auth auth required pam_env.so Add this line here auth sufficient pam_ssh.so auth sufficient pam_unix.so try_first_pass likeauth nullok auth required pam_deny.so account required pam_unix.so password required pam_cracklib.so difok=2 minlen=8 dcredit=2 ocredit=2 try_first_pass retry=3 password sufficient pam_unix.so try_first_pass use_authtok nullok md5 shadow password required pam_deny.so session required pam_limits.so session required pam_unix.so Add this line to the end session optional pam_ssh.so Summary That's all we need to do, you should be able to logout and log back in with the ability to ssh to your remote hosts without a password. You may need to restart your login manager with systemctl restart lightdm or simply reboot. WARNING: This WILL remove some aspect of physical security on whatever machine you set this up on. If physical security is a concern, please use a locking screensaver or logout whenever you leave your system unattended. This is something you should do anyway to protect your local machine from malicious passersby Troubleshooting If you are having problems creating or distributing your keys, take a look at http://gentoo-wiki.com/SECURITY_SSH_without_a_password for more information on that task. If you are still prompted for a password after completing this guide, there are a few files that you may need to check. Make sure both of these entries are set to \"yes\" on your remote hosts. /etc/ssh/sshd_config Allow Identity Auth for SSH1? RSAAuthentication yes # Allow Identity Auth for SSH2? PubkeyAuthentication yes Make sure these entries are in your local machine's config. /etc/ssh/sshd_config Host * Port 22 IdentityFile ~/.ssh/id_dsa","title":"SSH Single SignOn (SSO)"},{"location":"articles/SSH_Single_Signon/#ssh-single-signon-sso","text":"","title":"SSH Single SignOn (SSO)"},{"location":"articles/SSH_Single_Signon/#concept","text":"If you work with multiple *nix-based machines via ssh, you are probably tired of constantly having to enter your password every time you want to access another box. There is a secure way to allow you to access every machine, that you have ssh access to, without having to enter another password (other than the one you signed on with originally.) This is actually quite simple to do, you basically just create a public/private key pair to authenticate yourself to your other machines, then have PAM spawn an agent to load your keys after you logon, providing a single signon solution to accessing all your remote machines. This guide will walk you through setting this up.","title":"Concept"},{"location":"articles/SSH_Single_Signon/#equo-stuff","text":"First of all, we are going to need the pam_ssh module. You may already have this installed, if not equo it. I'm going to assume you already have openssh installed, as every system should. # equo install pam_ssh","title":"Equo Stuff"},{"location":"articles/SSH_Single_Signon/#create-key-pair","text":"Now we need to create the key pair to authenticate yourself across the network. To do so, run this as your regular user . WARNING: This should NOT be done as root, and you should never, ever ssh using the root account $ ssh-keygen -t dsa This will ask where to save the file, just press enter as the default is what we want. After that it will ask for the passphrase you want to use. It is important to set the passphrase to the exact same password as your normal logon password for this user. This is the password for the user on the current machine, not the one for other machines, even if they differ. When that is done, two files should of been created ~/.ssh/id_dsa and ~/.ssh/id_dsa.pub . NOTE: It is very important to keep ~/.ssh/id_dsa private , it should be only readable by your user, to make sure of this, run this command: $ chmod 600 ~/.ssh/id_dsa","title":"Create Key Pair"},{"location":"articles/SSH_Single_Signon/#distribute-public-key","text":"Now we need to give all of our remote machines our public key so we can use it to authenticate. This is very simple to do, run the following command as your user for each remote system you want to setup the passwordless authentication for. $ ssh-copy-id -i ~/.ssh/id_dsa.pub username@remotehostname","title":"Distribute Public Key"},{"location":"articles/SSH_Single_Signon/#configure-pam","text":"We need to tell PAM to use our logon password to spawn an ssh-agent and load the rsa key we just made. There are two lines for pam_ssh.so we need to add, so your system-auth should look something like this: /etc/pam.d/system-auth auth required pam_env.so","title":"Configure PAM"},{"location":"articles/SSH_Single_Signon/#add-this-line-here","text":"auth sufficient pam_ssh.so auth sufficient pam_unix.so try_first_pass likeauth nullok auth required pam_deny.so account required pam_unix.so password required pam_cracklib.so difok=2 minlen=8 dcredit=2 ocredit=2 try_first_pass retry=3 password sufficient pam_unix.so try_first_pass use_authtok nullok md5 shadow password required pam_deny.so session required pam_limits.so session required pam_unix.so","title":"Add this line here"},{"location":"articles/SSH_Single_Signon/#add-this-line-to-the-end","text":"session optional pam_ssh.so","title":"Add this line to the end"},{"location":"articles/SSH_Single_Signon/#summary","text":"That's all we need to do, you should be able to logout and log back in with the ability to ssh to your remote hosts without a password. You may need to restart your login manager with systemctl restart lightdm or simply reboot. WARNING: This WILL remove some aspect of physical security on whatever machine you set this up on. If physical security is a concern, please use a locking screensaver or logout whenever you leave your system unattended. This is something you should do anyway to protect your local machine from malicious passersby","title":"Summary"},{"location":"articles/SSH_Single_Signon/#troubleshooting","text":"If you are having problems creating or distributing your keys, take a look at http://gentoo-wiki.com/SECURITY_SSH_without_a_password for more information on that task. If you are still prompted for a password after completing this guide, there are a few files that you may need to check. Make sure both of these entries are set to \"yes\" on your remote hosts. /etc/ssh/sshd_config","title":"Troubleshooting"},{"location":"articles/SSH_Single_Signon/#allow-identity-auth-for-ssh1","text":"RSAAuthentication yes # Allow Identity Auth for SSH2? PubkeyAuthentication yes Make sure these entries are in your local machine's config. /etc/ssh/sshd_config Host * Port 22 IdentityFile ~/.ssh/id_dsa","title":"Allow Identity Auth for SSH1?"},{"location":"articles/UUIDs/","text":"UUID What is UUID? A Universally Unique Identifier (UUID) is an identifier standard used in software construction, standardized by the Open Software Foundation (OSF) as part of the Distributed Computing Environment (DCE). With UUID Linux kernel should automatically find and map (read as mount to exact location) volumes to storage device. This saves lots of time and avoid /etc/fstab breaks. How do I find the UUID to my drive? Let's say I have /dev/sda5 and I want to find out the UUID, as root: # vol_id --uuid /dev/sda5 62c289ef-ba8f-43bf-98bd-5150c7821ad8 How do I list all my volumes? #blkid /dev/sda1: UUID=\"F6EC3083EC304063\" LABEL=\"winxp\" TYPE=\"ntfs\" /dev/sda5: UUID=\"62c289ef-ba8f-43bf-98bd-5150c7821ad8\" TYPE=\"ext4dev\" /dev/sdb1: UUID=\"14901BF4C42926A1\" LABEL=\"Vista\" TYPE=\"ntfs\" /dev/sdb5: LABEL=\"tux2\" UUID=\"8b3d5c13-e858-4a21-9aa7-491770d40d3b\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb6: LABEL=\"tux3\" UUID=\"943a2d7c-dbe9-45e1-9238-adbcf73f31c7\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb7: LABEL=\"boot\" UUID=\"6d993171-1fbf-4e13-a2f8-945da575eb62\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb8: UUID=\"063b6f7d-e2e7-45ee-bd81-365039f42479\" TYPE=\"ext4dev\" /dev/sdc5: LABEL=\"STORAGE\" UUID=\"421D-AF1D\" TYPE=\"vfat\" /dev/sdd5: LABEL=\"MOVIES\" UUID=\"43F7-33C3\" TYPE=\"vfat\" /dev/sdd6: UUID=\"ddef8913-3dfd-4d8a-96da-997c500db8b5\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdd7: TYPE=\"swap\" UUID=\"4a56fa8f-c951-4d4c-8d16-164cb4d3467b\" /dev/sdd8: LABEL=\"Arch\" UUID=\"f2d7c692-e8f0-483f-85ca-366da0759c63\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdd9: UUID=\"EC4EC2504EC212EE\" LABEL=\"Misc\" TYPE=\"ntfs\" UUID and fstab How do I add this to my fstab? You will need to make a directory first. Lets say I have /dev/sdb5 as storage so I need to set that up for mounting # mkdir -p /media/storage Now I can add the line to my /etc/fstab file #UUID=8b3d5c13-e858-4a21-9aa7-491770d40d3b /media/storage ext3 defaults,errors=remount-ro 0 1 Now every time I boot, it auto-mounts it for me I need to learn fstab I would suggest reading this page http://www.tuxfiles.org/linuxhelp/fstab.html Handy ls commands List devices: By volume label: $ ls /dev/disk/by-label -lah By id: $ ls /dev/disk/by-id -lah By uuid: $ ls /dev/disk/by-uuid -lah Renaming a Label e2label As time goes on you make changes and may need to change the name of a label. Very simple with e2label : # e2label So, for example, if I want to change my sdb5 name from storage to music, I would use the command: # e2label /dev/sdb5 music ''Note'': will not work on FAT or NTFS volumes","title":"UUID"},{"location":"articles/UUIDs/#uuid","text":"","title":"UUID"},{"location":"articles/UUIDs/#what-is-uuid","text":"A Universally Unique Identifier (UUID) is an identifier standard used in software construction, standardized by the Open Software Foundation (OSF) as part of the Distributed Computing Environment (DCE). With UUID Linux kernel should automatically find and map (read as mount to exact location) volumes to storage device. This saves lots of time and avoid /etc/fstab breaks.","title":"What is UUID?"},{"location":"articles/UUIDs/#how-do-i-find-the-uuid-to-my-drive","text":"Let's say I have /dev/sda5 and I want to find out the UUID, as root: # vol_id --uuid /dev/sda5 62c289ef-ba8f-43bf-98bd-5150c7821ad8","title":"How do I find the UUID to my drive?"},{"location":"articles/UUIDs/#how-do-i-list-all-my-volumes","text":"#blkid /dev/sda1: UUID=\"F6EC3083EC304063\" LABEL=\"winxp\" TYPE=\"ntfs\" /dev/sda5: UUID=\"62c289ef-ba8f-43bf-98bd-5150c7821ad8\" TYPE=\"ext4dev\" /dev/sdb1: UUID=\"14901BF4C42926A1\" LABEL=\"Vista\" TYPE=\"ntfs\" /dev/sdb5: LABEL=\"tux2\" UUID=\"8b3d5c13-e858-4a21-9aa7-491770d40d3b\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb6: LABEL=\"tux3\" UUID=\"943a2d7c-dbe9-45e1-9238-adbcf73f31c7\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb7: LABEL=\"boot\" UUID=\"6d993171-1fbf-4e13-a2f8-945da575eb62\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdb8: UUID=\"063b6f7d-e2e7-45ee-bd81-365039f42479\" TYPE=\"ext4dev\" /dev/sdc5: LABEL=\"STORAGE\" UUID=\"421D-AF1D\" TYPE=\"vfat\" /dev/sdd5: LABEL=\"MOVIES\" UUID=\"43F7-33C3\" TYPE=\"vfat\" /dev/sdd6: UUID=\"ddef8913-3dfd-4d8a-96da-997c500db8b5\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdd7: TYPE=\"swap\" UUID=\"4a56fa8f-c951-4d4c-8d16-164cb4d3467b\" /dev/sdd8: LABEL=\"Arch\" UUID=\"f2d7c692-e8f0-483f-85ca-366da0759c63\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" /dev/sdd9: UUID=\"EC4EC2504EC212EE\" LABEL=\"Misc\" TYPE=\"ntfs\"","title":"How do I list all my volumes?"},{"location":"articles/UUIDs/#uuid-and-fstab","text":"","title":"UUID and fstab"},{"location":"articles/UUIDs/#how-do-i-add-this-to-my-fstab","text":"You will need to make a directory first. Lets say I have /dev/sdb5 as storage so I need to set that up for mounting # mkdir -p /media/storage Now I can add the line to my /etc/fstab file #UUID=8b3d5c13-e858-4a21-9aa7-491770d40d3b /media/storage ext3 defaults,errors=remount-ro 0 1 Now every time I boot, it auto-mounts it for me","title":"How do I add this to my fstab?"},{"location":"articles/UUIDs/#i-need-to-learn-fstab","text":"I would suggest reading this page http://www.tuxfiles.org/linuxhelp/fstab.html","title":"I need to learn fstab"},{"location":"articles/UUIDs/#handy-ls-commands","text":"List devices:","title":"Handy ls commands"},{"location":"articles/UUIDs/#by-volume-label","text":"$ ls /dev/disk/by-label -lah","title":"By volume label:"},{"location":"articles/UUIDs/#by-id","text":"$ ls /dev/disk/by-id -lah","title":"By id:"},{"location":"articles/UUIDs/#by-uuid","text":"$ ls /dev/disk/by-uuid -lah","title":"By uuid:"},{"location":"articles/UUIDs/#renaming-a-label","text":"","title":"Renaming a Label"},{"location":"articles/UUIDs/#e2label","text":"As time goes on you make changes and may need to change the name of a label. Very simple with e2label : # e2label So, for example, if I want to change my sdb5 name from storage to music, I would use the command: # e2label /dev/sdb5 music ''Note'': will not work on FAT or NTFS volumes","title":"e2label"},{"location":"articles/documentation/","text":"How to Edit an Article You can edit articles from the browser or by using git to clone and do a pull request. Browser Click the pencil icon on the screen Make your changes Submit your changes Git Go to https://github.com/Sabayon/wiki-next and click the Fork button at top left of the screen and create your own fork. Make the changes needed in your local fork Do a Pull Request If you are new to using git, you can start looking at some great guides How to Add and New Page You will need to Fork the repo You will create a new .md file Follow this page for a guide Don't forget to update the mkdocs.yml file to reflect your new page, if you don't, nobody can see the new page Do a Pull Request when done","title":"Wiki"},{"location":"articles/documentation/#how-to-edit-an-article","text":"You can edit articles from the browser or by using git to clone and do a pull request.","title":"How to Edit an Article"},{"location":"articles/documentation/#browser","text":"Click the pencil icon on the screen Make your changes Submit your changes","title":"Browser"},{"location":"articles/documentation/#git","text":"Go to https://github.com/Sabayon/wiki-next and click the Fork button at top left of the screen and create your own fork. Make the changes needed in your local fork Do a Pull Request If you are new to using git, you can start looking at some great guides","title":"Git"},{"location":"articles/documentation/#how-to-add-and-new-page","text":"You will need to Fork the repo You will create a new .md file Follow this page for a guide Don't forget to update the mkdocs.yml file to reflect your new page, if you don't, nobody can see the new page Do a Pull Request when done","title":"How to Add and New Page"},{"location":"articles/entropy/","text":"Entropy - Package Manager About Entropy is the name of the Sabayon Linux binary package management system. This is the name for the complete infrastructure, composed by Equo client (textual), and Rigo client (graphical). Sabayon is based on Gentoo's testing branch, which is about on par with Debian Sid releases. Entropy takes packages from Gentoo testing and they are pre-compiled, then offered to you in binary form. There is a time delay from when Sabayon compiles these packages for Entropy and when you receive them. It is recommended to only use 1 of the package managers(either Entropy or Portage) to avoid any possible conflicts as a result of the time delay. Generally, Entropy packages will be slightly more stable because they will have already been released in Gentoo testing for a period of time(exact amount of time varies), prior to being released in Entropy. Some highlights: Gentoo Linux compatible (caution, mixing entropy and portage is for advanced users) Takes the best from Portage, Yum and APT Fast as lightning SQLite-powered (embedded) Smart and User-centric Powerful Packages: multiple packages inside one single archive (Smart Packages) Supports self-contained applications (Smart Applications) Backward Compatible Packages: they can be used in Gentoo Linux after a quick conversion Multiple branches support (each branch is a release version) Database corruptions aware: rescue and system health scanning tools included Easy to deploy and use in a Network Environment Multiple repositories aware: everyone can create one Extensible and Human Understandable API Strongest Artificial Intelligence (Entropy has a brain) Great sense of humour, and much more... Basic Usage Equo is the command line client-side application for the Entropy package management system, and should be always performed as Root. It is capable of installing, removing and updating packages, resolving dependences, reverse dependency handling and configuration file handling and that's just to start with. Basic Usage There are several options you can use when using Equo, a few of the basic commands are shown below. Searching for a package can be accomplished by running the equo search command: equo search foo To install a package use the install function, the --ask amendment is optional but recommended. equo install foo --ask To remove a package use the remove function as shown below: equo remove foo --ask To upgrade all your packages to the latest versions use this command: equo upgrade --ask As you can see from the examples above, the \"--ask\" amendment is optional, but highly recommended, as it not only gives you more information about the packages being installed, but also the dependencies that may come with them, giving you more control about what is going to be installed, followed by a confirmation/abortion of the command. You can always use help to see a complete list of commands equo --help Rigo Rigo is the graphical user interface for package management. Features \"google search\" like interface very simple and straight forward Rigo is faster and more responsive append the various packages by browsing Easy manage repositories Show list of pending configuration files to update Very detailed Package information List of Installed Applications \"Activity\" button (bottom notification box), that shows the current app management queue. Send votes and add comments to Packages and much more... Kernel-Switcher kernel-switcher is an easy-to-use tool to simplify upgrading the kernel in Sabayon Linux. Remember, doing regular upgrades will not upgrade major version of the kernel, only minor (I.e. 3.12.3 \u2192 3.12.4: YES || 3.12.3 \u2192 3.13.0: NO). To upgrade major version of the kernel, you need to invoke a kernel change. # kernel-switcher --help kernel-switcher - Sabayon Linux Kernel Switcher BETA switch kernel: kernel-switcher switch kernel package list kernels: kernel-switcher list this help: kernel-switcher help The kernel-switcher list command is a nice feature, but can be overwhelming as it lists all kernels currently available in the repository. You may prefer to use equo search linux-sabayon as linux-sabayon is the Sabayon kernel package. With equo search linux-sabayon you can see if any newer kernels exist. For example, if you find that linux-sabayon-3.8.0 is available as an upgrade, you would upgrade to it as follows: # kernel-switcher switch linux-sabayon-3.8.0 @@ Calculating dependencies \u2026 ## [U] [sabayonlinux.org] sys-kernel/linux-firmwares-3.8.0|0 [3.8.0|0] ## [N] [sabayonlinux.org] sys-kernel/linux-sabayon-3.8.0|0 ## [N] [sabayonlinux.org] net-wireless/broadcom-sta-5.100.82.38-r1#3.8.0-sabayon|0 ## [N] [sabayonlinux.org] x11-drivers/nvidia-drivers-260.19.29#3.8.0-sabayon|0","title":"Entropy Package Manager"},{"location":"articles/entropy/#entropy-package-manager","text":"","title":"Entropy - Package Manager"},{"location":"articles/entropy/#about","text":"Entropy is the name of the Sabayon Linux binary package management system. This is the name for the complete infrastructure, composed by Equo client (textual), and Rigo client (graphical). Sabayon is based on Gentoo's testing branch, which is about on par with Debian Sid releases. Entropy takes packages from Gentoo testing and they are pre-compiled, then offered to you in binary form. There is a time delay from when Sabayon compiles these packages for Entropy and when you receive them. It is recommended to only use 1 of the package managers(either Entropy or Portage) to avoid any possible conflicts as a result of the time delay. Generally, Entropy packages will be slightly more stable because they will have already been released in Gentoo testing for a period of time(exact amount of time varies), prior to being released in Entropy. Some highlights: Gentoo Linux compatible (caution, mixing entropy and portage is for advanced users) Takes the best from Portage, Yum and APT Fast as lightning SQLite-powered (embedded) Smart and User-centric Powerful Packages: multiple packages inside one single archive (Smart Packages) Supports self-contained applications (Smart Applications) Backward Compatible Packages: they can be used in Gentoo Linux after a quick conversion Multiple branches support (each branch is a release version) Database corruptions aware: rescue and system health scanning tools included Easy to deploy and use in a Network Environment Multiple repositories aware: everyone can create one Extensible and Human Understandable API Strongest Artificial Intelligence (Entropy has a brain) Great sense of humour, and much more...","title":"About"},{"location":"articles/entropy/#basic-usage","text":"Equo is the command line client-side application for the Entropy package management system, and should be always performed as Root. It is capable of installing, removing and updating packages, resolving dependences, reverse dependency handling and configuration file handling and that's just to start with. Basic Usage There are several options you can use when using Equo, a few of the basic commands are shown below. Searching for a package can be accomplished by running the equo search command: equo search foo To install a package use the install function, the --ask amendment is optional but recommended. equo install foo --ask To remove a package use the remove function as shown below: equo remove foo --ask To upgrade all your packages to the latest versions use this command: equo upgrade --ask As you can see from the examples above, the \"--ask\" amendment is optional, but highly recommended, as it not only gives you more information about the packages being installed, but also the dependencies that may come with them, giving you more control about what is going to be installed, followed by a confirmation/abortion of the command. You can always use help to see a complete list of commands equo --help","title":"Basic Usage"},{"location":"articles/entropy/#rigo","text":"Rigo is the graphical user interface for package management. Features \"google search\" like interface very simple and straight forward Rigo is faster and more responsive append the various packages by browsing Easy manage repositories Show list of pending configuration files to update Very detailed Package information List of Installed Applications \"Activity\" button (bottom notification box), that shows the current app management queue. Send votes and add comments to Packages and much more...","title":"Rigo"},{"location":"articles/entropy/#kernel-switcher","text":"kernel-switcher is an easy-to-use tool to simplify upgrading the kernel in Sabayon Linux. Remember, doing regular upgrades will not upgrade major version of the kernel, only minor (I.e. 3.12.3 \u2192 3.12.4: YES || 3.12.3 \u2192 3.13.0: NO). To upgrade major version of the kernel, you need to invoke a kernel change. # kernel-switcher --help kernel-switcher - Sabayon Linux Kernel Switcher BETA switch kernel: kernel-switcher switch kernel package list kernels: kernel-switcher list this help: kernel-switcher help The kernel-switcher list command is a nice feature, but can be overwhelming as it lists all kernels currently available in the repository. You may prefer to use equo search linux-sabayon as linux-sabayon is the Sabayon kernel package. With equo search linux-sabayon you can see if any newer kernels exist. For example, if you find that linux-sabayon-3.8.0 is available as an upgrade, you would upgrade to it as follows: # kernel-switcher switch linux-sabayon-3.8.0 @@ Calculating dependencies \u2026 ## [U] [sabayonlinux.org] sys-kernel/linux-firmwares-3.8.0|0 [3.8.0|0] ## [N] [sabayonlinux.org] sys-kernel/linux-sabayon-3.8.0|0 ## [N] [sabayonlinux.org] net-wireless/broadcom-sta-5.100.82.38-r1#3.8.0-sabayon|0 ## [N] [sabayonlinux.org] x11-drivers/nvidia-drivers-260.19.29#3.8.0-sabayon|0","title":"Kernel-Switcher"},{"location":"articles/firewall/","text":"On Sabayon systems the firewall is controlled by firewalld Starting or stopping the firewall service on a Sabayon can be done with these commands: To stop the firewall service: # systemctl stop firewalld To start the firewall service: # systemctl start firewalld To system wide disable the firewall at system boot: # systemctl disable firewalld To check the firewall status: # systemctl status firewalld","title":"Firewall"},{"location":"articles/firewall/#on-sabayon-systems-the-firewall-is-controlled-by-firewalld","text":"Starting or stopping the firewall service on a Sabayon can be done with these commands: To stop the firewall service: # systemctl stop firewalld To start the firewall service: # systemctl start firewalld To system wide disable the firewall at system boot: # systemctl disable firewalld To check the firewall status: # systemctl status firewalld","title":"On Sabayon systems the firewall is controlled by firewalld"},{"location":"articles/freshinstall/","text":"So you just installed a fresh copy of Sabayon Lixux and are wondering what to do next. Entropy is the package manager and will be vital to know. First thing you will want to do is sort your mirrors. All commands must be run as root, so su or sudo. It is a good idea to optimize the sorting of mirrors so that all package upgrades will be downloaded as quickly as possible. The choice will depend on what repository you are using, choices are: limbo(sabayon-limbo) - main(sabayonlinux.org) - weekly(sabayon-weekly) | to see which one your system is using simply do: equo status Issue the proper command(s) according to your status equo repo mirrorsort sabayon-weekly equo repo mirrorsort sabayonlinux.org equo repo mirrorsort sabayon-limbo Now update the package lists from the mirrors equo update If you run into problems with that then try: equo update --force Once you have that completed it is vital to get Entropy upgraded to the latest version before doing a full system upgrade. Upgrade will bring your system to current development. equo install sys-apps/entropy rigo equo --relaxed If you have config files to update equo conf update Once the Entropy code is upgraded to the latest version, fully upgrade the rest of your system with these two commands: equo update To get a list of available updates and choose yes to continue updates equo upgrade --ask Follow what is happening on the screen, as Entropy will show you what it is going to do and ask for confirmations. The 'equo update' command will update the database on your PC with the latest information on packages available in the Entropy repositories; The 'equo upgrade' command will download from the repositories the binary files for new versions of packages installed on your PC and then install the new versions of those packages. Time of process depends on how many packages, bandwidth and hardware. After it is done and if you have config files to update, make sure to: equo conf update You will want to make your selection but you really should get to know your config files as they will change your system. More than likely most will select -5. I always look over the config files as I don't want some of my configs getting overwritten. The final step is to run the following commands, checking for missing dependencies and stability: equo deptest Followed by equo libtest After this has finished, reboot and enjoy your freshly installed fully updated Sabayon. There is a graphical user interface(gui) that you can use instead called Rigo. Rigo will allow you to sort your mirrors, manage repositories, do system upgrades with a click of a button and deal with config files. Get to know how to use equo incase you can't access Rigo. A Note on Repositories: Limbo - testing packages, things may break, advanced users Main - After limbo and made sure things are stable the package is moved to Main Weekly - The most stable as packages have been through limbo and main. You can manage repositories with equo or Rigo equo repo disable sabayon-limbo equo repo enable sabayon-limbo Now you're set to use equo: To install a package, the --ask amendment is optional but recommended. equo install foo --ask Removing Packages equo remove foo --ask Search for a Package equo search foo Cleanup downloaded packages Every now and then you will want to cleanup the packages that Entropy downloaded: equo cleanup See help for more equo commands equo --help","title":"Freshinstall"},{"location":"articles/graphics_drivers/","text":"TEAM RED - AMD ######### SED ######### In these instructions you'll notice the sed command. This may make some people leary as not everyone understands this command. \"sed\" stands for \"stream editor\". It can edit the edit file for you by substituting lines, words, strings, etc. In this case we are using it to remove a line in blacklist.conf and nomodeset command in grub config files. If you don't feel fully comfortable about this command. Back up your file or use nano (vi etc.) to edit the file! EXPERIMENTAL AMDGPU ######### Not all AMD Display Code is not mainline! ######### This contains incomplete code that has yet not been adopted into the mainline kernel. Results may vary and this may not be the same as the finalized versions of code. Beware, this is experimental and you're on your own. This is not a supported setup. It only allows you early access to AMDGPU upgrades. You'll also want to be aware that you should still keep your current kernel in case anything goes wrong. That will allow you to continue booting into your system from the advanced options in GRUB by selecting the older kernel. Lets get started with prep work! localhost root # equo repo enable sabayon-limbo localhost root # equo update; equo upgrade localhost root # equo install v86d bison make cmake automake gcc genkernel-next dracut sabayon-dracut git Now lets download a kernel with display code. localhost root # git clone -b amd-staging-drm-next --depth=1 git://people.freedesktop.org/~agd5f/linux localhost root # mv linux /usr/src/linux-5.0.0-rc1+ localhost root # cd /usr/src localhost root # rm -rf linux localhost root # ln -s linux-5.0.0-rc1+/ linux localhost root # cd linux Now we finish configuring and building the kernel. Now's you chance to make any other config changes you want. If you use lvm or luks add the --lvm or --luks flag to the genkernel command. You can also double check Device Drivers - Graphics Support - Display Engine Configuration - AMD DC is enabled as well as Raven family if you plan on owning an APU based on Raven. localhost root # zcat /proc/config.gz /usr/src/config localhost root # genkernel --kernel-config=/usr/src/config --menuconfig --splash=sabayon kernel localhost root # dracut -H -q -f -o systemd -o systemd-initrd -o systemd-networkd -o dracut-systemd --kver=5.0.0-rc1+ /boot/initramfs-genkernel-x86_64-5.0.0-rc1+ localhost root # grub2-mkconfig -o /boot/grub/grub.cfg You can watch the git repo for updates/fixes/changes etc at https://cgit.freedesktop.org/~agd5f/linux/log/?h=amd-staging-drm-next to decide if you want to update the kernel again. If you do this, none of the sed commands are necessary for the config as /proc/config.gz will already have the updated config changes. TEAM GREEN - NVIDIA Booting live/installer disc with vesa graphics on older GPUs Can't seem to get the GUI on the installer disc and seem stuck at a black screen or terminal? We've got you covered. When selecting an option from the boot screen edit the boot line and include the following at the end of the line. modprobe.blacklist=nvidia xdriver=vesa This should get you into the live session to perform an install. Afterwards, you'll need to either switch to Nouveau or a proprietary driver version that supports your card. Proprietary Sabayon should already come with the latest nvidia-drivers, but if for some reason you don't have correct proprietary Nvidia drivers installed there are simple steps to follow. Prepare if returning from nouveau Because we use the proprietary drivers by default, the opensource driver is usually already blacklisted; but if you switched to the opensource driver and are returning to the proprietary offerings, you must first blacklist the opensource driver. localhost root # sed -i s/'#blacklist nouveau'/'blacklist nouveau'/ /etc/modprobe.d/blacklist.conf Available driver version To get a list of all drivers for all kernels that are available: localhost root # equo search -qv nvidia-drivers List of all drivers versions available for currently running kernel: localhost root # equo search -qv nvidia-drivers#$(uname -r) Newest drivers for currently running kernel localhost root # equo install --ask nvidia-driver#$(uname -r) nvidia-userspace Will install newest driver available for currently running kernel. Older drivers for currently running kernel ######### Not supported or Guaranteed ######### It has been noticed that depending on the old GPU or GPU drivers version, they may or may not work. This seems pretty hit and miss.Mobile GPUs and non-discrete GPUs (integrated in the motherboard) appear to be affected by this. If you're using an GPU older than Fermi or an integrated GPU, we recommend using the open source nouveau driver. List Nvidia drivers for your current kernel (insturctions above), and install it along with corresponding '''nvidia-userspace''', e.g.: localhost root # equo install --ask nvidia-drivers-340.104#$(uname -r) nvidia-drivers-340.104 now lets switch from opensource opengl libraries to proprietary nvidia opengl libraries localhost root # eselect opengl set nvidia Open Source - Switching to Nouveau drivers ### WARNING! FERMI AND OLDER CARDS HAVE NO RECLOCKING SUPPORT Fermi cards (Geforce 400 and 500 series cards) and older do not have reclocking support. What does this mean exactly? Basically your GPU boots up in a power saving state. The pstate is on \"LOW\" This means the cards will boot up with extremely low clock speeds. Without reclocking support you cannot change the power state to force the GPU into performance mode, making it able to play games. This driver is not recommended for GPUs older than Geforce 600 Series unless you're using it for basic productivity tasks. If Sabayon is installed you reboot and you find you're stuck at a login terminal or just wan to switch to open source drivers, this is a simple fix. Just login with your user you created. Then we'll remove the proprietary drivers and the blacklist for nouveau using the following: Unblock nouveau driver Because we use the proprietary drivers by default, the opensource driver is blacklisted. You must first unblock the driver from being loaded. localhost root # sed -i s/'blacklist nouveau'/'#blacklist nouveau'/ /etc/modprobe.d/blacklist.conf You still must block or remove the proprietary driver. Now that both drivers have the ability to load, it will most likely lock up the machine on boot or cause instability. Both drivers cannot be loaded at the same time. Removal of proprietary driver You can blacklist the nvidia drivers OR remove them entirely. Removal is the simplest method. localhost root # equo update; equo remove nvidia-drivers nvidia-userspace Now lets make sure we're using the correct opengl libraries localhost root # eselect opengl set xorg-x11 Not done yet. We need to rebuild initramfs so that it doesn't include nvidia-drivers upon boot. localhost root # sabayon-dracut --rebuild-all Now reboot and you'll be using nouveau. If you ever feel like returning to proprietary drivers, you'll need to blacklist nouveau again.","title":"TEAM RED - AMD"},{"location":"articles/graphics_drivers/#team-red-amd","text":"######### SED ######### In these instructions you'll notice the sed command. This may make some people leary as not everyone understands this command. \"sed\" stands for \"stream editor\". It can edit the edit file for you by substituting lines, words, strings, etc. In this case we are using it to remove a line in blacklist.conf and nomodeset command in grub config files. If you don't feel fully comfortable about this command. Back up your file or use nano (vi etc.) to edit the file!","title":"TEAM RED - AMD"},{"location":"articles/graphics_drivers/#experimental-amdgpu","text":"######### Not all AMD Display Code is not mainline! ######### This contains incomplete code that has yet not been adopted into the mainline kernel. Results may vary and this may not be the same as the finalized versions of code. Beware, this is experimental and you're on your own. This is not a supported setup. It only allows you early access to AMDGPU upgrades. You'll also want to be aware that you should still keep your current kernel in case anything goes wrong. That will allow you to continue booting into your system from the advanced options in GRUB by selecting the older kernel. Lets get started with prep work! localhost root # equo repo enable sabayon-limbo localhost root # equo update; equo upgrade localhost root # equo install v86d bison make cmake automake gcc genkernel-next dracut sabayon-dracut git Now lets download a kernel with display code. localhost root # git clone -b amd-staging-drm-next --depth=1 git://people.freedesktop.org/~agd5f/linux localhost root # mv linux /usr/src/linux-5.0.0-rc1+ localhost root # cd /usr/src localhost root # rm -rf linux localhost root # ln -s linux-5.0.0-rc1+/ linux localhost root # cd linux Now we finish configuring and building the kernel. Now's you chance to make any other config changes you want. If you use lvm or luks add the --lvm or --luks flag to the genkernel command. You can also double check Device Drivers - Graphics Support - Display Engine Configuration - AMD DC is enabled as well as Raven family if you plan on owning an APU based on Raven. localhost root # zcat /proc/config.gz /usr/src/config localhost root # genkernel --kernel-config=/usr/src/config --menuconfig --splash=sabayon kernel localhost root # dracut -H -q -f -o systemd -o systemd-initrd -o systemd-networkd -o dracut-systemd --kver=5.0.0-rc1+ /boot/initramfs-genkernel-x86_64-5.0.0-rc1+ localhost root # grub2-mkconfig -o /boot/grub/grub.cfg You can watch the git repo for updates/fixes/changes etc at https://cgit.freedesktop.org/~agd5f/linux/log/?h=amd-staging-drm-next to decide if you want to update the kernel again. If you do this, none of the sed commands are necessary for the config as /proc/config.gz will already have the updated config changes.","title":"EXPERIMENTAL AMDGPU"},{"location":"articles/graphics_drivers/#team-green-nvidia","text":"","title":"TEAM GREEN - NVIDIA"},{"location":"articles/graphics_drivers/#booting-liveinstaller-disc-with-vesa-graphics-on-older-gpus","text":"Can't seem to get the GUI on the installer disc and seem stuck at a black screen or terminal? We've got you covered. When selecting an option from the boot screen edit the boot line and include the following at the end of the line. modprobe.blacklist=nvidia xdriver=vesa This should get you into the live session to perform an install. Afterwards, you'll need to either switch to Nouveau or a proprietary driver version that supports your card.","title":"Booting live/installer disc with vesa graphics on older GPUs"},{"location":"articles/graphics_drivers/#proprietary","text":"Sabayon should already come with the latest nvidia-drivers, but if for some reason you don't have correct proprietary Nvidia drivers installed there are simple steps to follow.","title":"Proprietary"},{"location":"articles/graphics_drivers/#prepare-if-returning-from-nouveau","text":"Because we use the proprietary drivers by default, the opensource driver is usually already blacklisted; but if you switched to the opensource driver and are returning to the proprietary offerings, you must first blacklist the opensource driver. localhost root # sed -i s/'#blacklist nouveau'/'blacklist nouveau'/ /etc/modprobe.d/blacklist.conf","title":"Prepare if returning from nouveau"},{"location":"articles/graphics_drivers/#available-driver-version","text":"To get a list of all drivers for all kernels that are available: localhost root # equo search -qv nvidia-drivers List of all drivers versions available for currently running kernel: localhost root # equo search -qv nvidia-drivers#$(uname -r)","title":"Available driver version"},{"location":"articles/graphics_drivers/#newest-drivers-for-currently-running-kernel","text":"localhost root # equo install --ask nvidia-driver#$(uname -r) nvidia-userspace Will install newest driver available for currently running kernel.","title":"Newest drivers for currently running kernel"},{"location":"articles/graphics_drivers/#older-drivers-for-currently-running-kernel","text":"######### Not supported or Guaranteed ######### It has been noticed that depending on the old GPU or GPU drivers version, they may or may not work. This seems pretty hit and miss.Mobile GPUs and non-discrete GPUs (integrated in the motherboard) appear to be affected by this. If you're using an GPU older than Fermi or an integrated GPU, we recommend using the open source nouveau driver. List Nvidia drivers for your current kernel (insturctions above), and install it along with corresponding '''nvidia-userspace''', e.g.: localhost root # equo install --ask nvidia-drivers-340.104#$(uname -r) nvidia-drivers-340.104 now lets switch from opensource opengl libraries to proprietary nvidia opengl libraries localhost root # eselect opengl set nvidia","title":"Older drivers for currently running kernel"},{"location":"articles/graphics_drivers/#open-source-switching-to-nouveau-drivers","text":"","title":"Open Source - Switching to Nouveau drivers"},{"location":"articles/graphics_drivers/#warning-fermi-and-older-cards-have-no-reclocking-support","text":"Fermi cards (Geforce 400 and 500 series cards) and older do not have reclocking support. What does this mean exactly? Basically your GPU boots up in a power saving state. The pstate is on \"LOW\" This means the cards will boot up with extremely low clock speeds. Without reclocking support you cannot change the power state to force the GPU into performance mode, making it able to play games. This driver is not recommended for GPUs older than Geforce 600 Series unless you're using it for basic productivity tasks. If Sabayon is installed you reboot and you find you're stuck at a login terminal or just wan to switch to open source drivers, this is a simple fix. Just login with your user you created. Then we'll remove the proprietary drivers and the blacklist for nouveau using the following:","title":"### WARNING! FERMI AND OLDER CARDS HAVE NO RECLOCKING SUPPORT"},{"location":"articles/graphics_drivers/#unblock-nouveau-driver","text":"Because we use the proprietary drivers by default, the opensource driver is blacklisted. You must first unblock the driver from being loaded. localhost root # sed -i s/'blacklist nouveau'/'#blacklist nouveau'/ /etc/modprobe.d/blacklist.conf You still must block or remove the proprietary driver. Now that both drivers have the ability to load, it will most likely lock up the machine on boot or cause instability. Both drivers cannot be loaded at the same time.","title":"Unblock nouveau driver"},{"location":"articles/graphics_drivers/#removal-of-proprietary-driver","text":"You can blacklist the nvidia drivers OR remove them entirely. Removal is the simplest method. localhost root # equo update; equo remove nvidia-drivers nvidia-userspace Now lets make sure we're using the correct opengl libraries localhost root # eselect opengl set xorg-x11 Not done yet. We need to rebuild initramfs so that it doesn't include nvidia-drivers upon boot. localhost root # sabayon-dracut --rebuild-all Now reboot and you'll be using nouveau. If you ever feel like returning to proprietary drivers, you'll need to blacklist nouveau again.","title":"Removal of proprietary driver"},{"location":"articles/howto/","text":"Desktop Environment Removing Desktop Environments Hardware How to install Graphics Drivers Installation Advanced Install From Stage3 Tarball Networking | Internet Firewall - firewalld LAMP SSH SSO Wireguard VPN Software Management Entropy Equo after Fresh Install Software Applications System Operations Regenerate initramfs User Management Using Systemd Understanding UUIDs Understanding LVM Understanding LUKS Encryption Developer Enable Debugging Symbols Sabayon Dev Kit Building VMware Appliances Building Custom ISOs Building a Community Repository Joining Software Testing","title":"How To Index"},{"location":"articles/howto/#desktop-environment","text":"Removing Desktop Environments","title":"Desktop Environment"},{"location":"articles/howto/#hardware","text":"How to install Graphics Drivers","title":"Hardware"},{"location":"articles/howto/#installation","text":"Advanced Install From Stage3 Tarball","title":"Installation"},{"location":"articles/howto/#networking-internet","text":"Firewall - firewalld LAMP SSH SSO Wireguard VPN","title":"Networking | Internet"},{"location":"articles/howto/#software-management","text":"Entropy Equo after Fresh Install","title":"Software Management"},{"location":"articles/howto/#software-applications","text":"","title":"Software Applications"},{"location":"articles/howto/#system-operations","text":"Regenerate initramfs User Management Using Systemd Understanding UUIDs Understanding LVM Understanding LUKS Encryption","title":"System Operations"},{"location":"articles/howto/#developer","text":"Enable Debugging Symbols Sabayon Dev Kit Building VMware Appliances Building Custom ISOs Building a Community Repository Joining Software Testing","title":"Developer"},{"location":"articles/initramfs/","text":"Regenerate initramfs Sabayon uses Dracut as initramfs generator, for further customizations you can refer to the dracut wiki . sabayon-dracut Sabayon ships an helper tool to aid user to regenerate initramfs, sabayon-dracut . You can use it to regenerate initramfs against specific kernel, or for every single one installed in your system. To install sabayon-dracut , if not already present in your system, run as root : equo install sys-kernel/sabayon-dracut Now if you would like to rebuild the initramfs, for let's say your kernel 4.18, you can just run: sabayon-dracut --rebuild 4.18 To rebuild the initramfs for all the kernel installed in your system: sabayon-dracut --rebuild-all You can also check the initramfs present in your system with: sabayon-dracut -L .","title":"Regenerate initramfs"},{"location":"articles/initramfs/#regenerate-initramfs","text":"Sabayon uses Dracut as initramfs generator, for further customizations you can refer to the dracut wiki .","title":"Regenerate initramfs"},{"location":"articles/initramfs/#sabayon-dracut","text":"Sabayon ships an helper tool to aid user to regenerate initramfs, sabayon-dracut . You can use it to regenerate initramfs against specific kernel, or for every single one installed in your system. To install sabayon-dracut , if not already present in your system, run as root : equo install sys-kernel/sabayon-dracut Now if you would like to rebuild the initramfs, for let's say your kernel 4.18, you can just run: sabayon-dracut --rebuild 4.18 To rebuild the initramfs for all the kernel installed in your system: sabayon-dracut --rebuild-all You can also check the initramfs present in your system with: sabayon-dracut -L .","title":"sabayon-dracut"},{"location":"articles/irc/","text":"Freenode #sabayon - this is our main support channel #sabayon-dev - is our developer channel, interested in helping out with the project, come join us #sabayon-chat - general off-topic chat Support We depend on the community to help each other out and at times the irc channels can be quiet. Be Polite Be Patient Respect the Operators We are always in need of volunteers to help the community. Testers We are always looking for people to test our latest stuff. Our -dev isos are a great way to get involved with testing. Grab your favorite dev flavored iso and try it out, report any issues Our Limbo repo is another great way to test, simply add the repo Report issues to our Mailing List or #sabayon-dev channel, Mailing List would probably be best, that way it won't get lost. Please include: Which ISO you are using Your Hardware How to replicate Log Files if any or Error Messages Get to know journalctl for Logs Without the above information it is really hard to track down the issue.","title":"IRC|Testers"},{"location":"articles/irc/#freenode","text":"","title":"Freenode"},{"location":"articles/irc/#sabayon-this-is-our-main-support-channel","text":"","title":"#sabayon - this is our main support channel"},{"location":"articles/irc/#sabayon-dev-is-our-developer-channel-interested-in-helping-out-with-the-project-come-join-us","text":"","title":"#sabayon-dev - is our developer channel, interested in helping out with the project, come join us"},{"location":"articles/irc/#sabayon-chat-general-off-topic-chat","text":"","title":"#sabayon-chat - general off-topic chat"},{"location":"articles/irc/#support","text":"We depend on the community to help each other out and at times the irc channels can be quiet. Be Polite Be Patient Respect the Operators We are always in need of volunteers to help the community.","title":"Support"},{"location":"articles/irc/#testers","text":"We are always looking for people to test our latest stuff. Our -dev isos are a great way to get involved with testing. Grab your favorite dev flavored iso and try it out, report any issues Our Limbo repo is another great way to test, simply add the repo Report issues to our Mailing List or #sabayon-dev channel, Mailing List would probably be best, that way it won't get lost. Please include: Which ISO you are using Your Hardware How to replicate Log Files if any or Error Messages Get to know journalctl for Logs Without the above information it is really hard to track down the issue.","title":"Testers"},{"location":"articles/lamp/","text":"Install and configure a basic LAMP Installation Packages needed www-servers/apache dev-lang/php dev-db/mariadb Some packages have multiple slot/version and they're can be install in the same time like dev-lang/php You can manage multiple PHP version on your server : PHP5 or PHP7 can be installed in the same time (or more PHP version) Multiple PHP slots # equo search dev-lang/php dev-lang/php-5.6.36 dev-lang/php-7.1.18 or # equo s dev-lang/php | grep Slot Slot: 5.6 Slot: 7.1 The PHP versions shown may differ from those in the repositories Install packages # equo i www-servers/apache dev-db/mariadb dev-lang/php --ask This will install Apache and Mariadb database and PHP to higher version available on repository. If you need a different PHP version or multiple PHP versions, different slots need to be installed. PHP-5.6 only # equo i dev-lang/php:5.6 PHP-5.6 and PHP-7 # equo i dev-lang/php:5.6 dev-lang/php:7.1 Configure Database MariaDBis a MySQL alternative used by SabayonLinux. MariaDB intends to maintain high compatibility with MySQL, ensuring a \"drop-in\" replacement capability with library binary equivalency and exact matching with MySQL APIs and commands.It includes the XtraDB storage engine for replacing InnoDB,as well as a new storage engine, Aria, that intends to be both a transactional and non-transactional engine perhaps even included in future versions of MySQL Configure user and password database # emerge --config dev-db/mariadb Default MySql configuration file /etc/mysql/my.conf The following options will be passed to all MySQL clients [client] password = your_password port = 3306 socket = /var/run/mysqld/mysqld.sock [mysql] character-sets-dir=/usr/share/mysql/charsets default-character-set=utf8 [mysqladmin] character-sets-dir=/usr/share/mysql/charsets default-character-set=utf8 By default all databases will be stored to /var/lib/mysql . Configure Apache2 web server Apache2 configuration file is stored at /etc/conf.d/apache2 Basically we need to edit APACHE2_OPTS option. Configure Apache and all PHP versions installed /etc/conf.d/apache2 APACHE2_OPTS=\"-D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D LANGUAGE -D PHP\" With \"-D PHP\" option you can manage multiple PHP version installed in your system. eselect php command can help you to do this. # eselect php list apache2 [1] php5.6 * [2] php7.0 Set PHP version you want ; Example : php7.0 # eselect php set apache2 2 Back to php5.6 version # eselect php set apache2 1 Apache and MySQL services Now is time to start all configured services . # systemctl start mariadb Check if service is running # systemctl status mariadb \u25cf mariadb.service - MariaDB database server Loaded: loaded (/usr/lib64/systemd/system/mariadb.service; enabled; vendor preset: disabled) Active: active (running) since sab 2017-05-27 20:39:37 CEST; 9min ago Process: 7512 ExecStartPost=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Process: 7371 ExecStartPre=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] VAR= || VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ] systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 (code=exited, status=0/SUCCESS) Process: 7368 ExecStartPre=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Main PID: 7481 (mysqld) Status: \"Taking your SQL requests now...\" CGroup: /system.slice/mariadb.service \u2514\u25007481 /usr/sbin/mysqld mag 27 20:39:36 sabayon.local systemd[1]: Starting MariaDB database server... mag 27 20:39:37 sabayon.local mysqld[7481]: 2017-05-27 20:39:37 140257335244800 [Note] /usr/sbin/mysqld (mysqld 10.1.23-MariaDB) starting a...7481 ... mag 27 20:39:37 sabayon.local systemd[1]: Started MariaDB database server. Hint: Some lines were ellipsized, use -l to show in full. Start Apache Web Server # systemctl start apache2 Check if service is running # systemctl status apache2 \u25cf apache2.service - The Apache HTTP Server Loaded: loaded (/usr/lib64/systemd/system/apache2.service; disabled; vendor preset: disabled) Active: active (running) since sab 2017-05-27 20:47:26 CEST; 2s ago Process: 8415 ExecStop=/usr/sbin/apache2 $APACHE2_OPTS -k graceful-stop (code=exited, status=1/FAILURE) Main PID: 8532 (apache2) CGroup: /system.slice/apache2.service \u251c\u25008532 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008534 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008535 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008536 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008537 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008538 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u2514\u25008539 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND mag 27 20:47:26 sabayon.local systemd[1]: Started The Apache HTTP Server. or simply go to http://localhost or http:// Apache offers many external modules and addictional functions as www-apache/mod_ and you can find them on Sabayon Repository or Portage. Please, be sure to read Apache Docs before installing them. VirtualHosts configuration files can be found at : /etc/apache2/httpd.conf /etc/apache2/vhosts.d/00_default_*.conf To enable Apache and MariaDB service at boot just type # systemctl enable apache2 systemctl enable mariadb. Manage MySQL/MariaDB : PhpMyAdmin PhpMyAdminis a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB. Frequently used operations (managing databases, tables, columns, relations, indexes, users, permissions, etc) can be performed via the user interface, while you still have the ability to directly execute any SQL statement. Install PhpMyAdmin # equo i dev-db/phpmyadmin --ask Go to http://localhost/phpmyadmin or http:// /phpmyadmin to configure your PhpMyAdmin installation. By default PhpMyAdmin will be installed to /var/www/localhost/htdocs (the default apache2 working directory) as /var/www/localhost/htdocs/phpmyadmin","title":"Lamp"},{"location":"articles/lamp/#install-and-configure-a-basic-lamp-installation","text":"Packages needed www-servers/apache dev-lang/php dev-db/mariadb Some packages have multiple slot/version and they're can be install in the same time like dev-lang/php You can manage multiple PHP version on your server : PHP5 or PHP7 can be installed in the same time (or more PHP version) Multiple PHP slots # equo search dev-lang/php dev-lang/php-5.6.36 dev-lang/php-7.1.18 or # equo s dev-lang/php | grep Slot Slot: 5.6 Slot: 7.1 The PHP versions shown may differ from those in the repositories","title":"Install and configure a basic LAMP Installation"},{"location":"articles/lamp/#install-packages","text":"# equo i www-servers/apache dev-db/mariadb dev-lang/php --ask This will install Apache and Mariadb database and PHP to higher version available on repository. If you need a different PHP version or multiple PHP versions, different slots need to be installed. PHP-5.6 only # equo i dev-lang/php:5.6 PHP-5.6 and PHP-7 # equo i dev-lang/php:5.6 dev-lang/php:7.1","title":"Install packages"},{"location":"articles/lamp/#configure-database","text":"MariaDBis a MySQL alternative used by SabayonLinux. MariaDB intends to maintain high compatibility with MySQL, ensuring a \"drop-in\" replacement capability with library binary equivalency and exact matching with MySQL APIs and commands.It includes the XtraDB storage engine for replacing InnoDB,as well as a new storage engine, Aria, that intends to be both a transactional and non-transactional engine perhaps even included in future versions of MySQL Configure user and password database # emerge --config dev-db/mariadb Default MySql configuration file /etc/mysql/my.conf The following options will be passed to all MySQL clients [client] password = your_password port = 3306 socket = /var/run/mysqld/mysqld.sock [mysql] character-sets-dir=/usr/share/mysql/charsets default-character-set=utf8 [mysqladmin] character-sets-dir=/usr/share/mysql/charsets default-character-set=utf8 By default all databases will be stored to /var/lib/mysql .","title":"Configure Database"},{"location":"articles/lamp/#configure-apache2-web-server","text":"Apache2 configuration file is stored at /etc/conf.d/apache2 Basically we need to edit APACHE2_OPTS option. Configure Apache and all PHP versions installed /etc/conf.d/apache2 APACHE2_OPTS=\"-D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D LANGUAGE -D PHP\" With \"-D PHP\" option you can manage multiple PHP version installed in your system. eselect php command can help you to do this. # eselect php list apache2 [1] php5.6 * [2] php7.0 Set PHP version you want ; Example : php7.0 # eselect php set apache2 2 Back to php5.6 version # eselect php set apache2 1","title":"Configure Apache2 web server"},{"location":"articles/lamp/#apache-and-mysql-services","text":"Now is time to start all configured services . # systemctl start mariadb Check if service is running # systemctl status mariadb \u25cf mariadb.service - MariaDB database server Loaded: loaded (/usr/lib64/systemd/system/mariadb.service; enabled; vendor preset: disabled) Active: active (running) since sab 2017-05-27 20:39:37 CEST; 9min ago Process: 7512 ExecStartPost=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Process: 7371 ExecStartPre=/bin/sh -c [ ! -e /usr/bin/galera_recovery ] VAR= || VAR=`/usr/bin/galera_recovery`; [ $? -eq 0 ] systemctl set-environment _WSREP_START_POSITION=$VAR || exit 1 (code=exited, status=0/SUCCESS) Process: 7368 ExecStartPre=/bin/sh -c systemctl unset-environment _WSREP_START_POSITION (code=exited, status=0/SUCCESS) Main PID: 7481 (mysqld) Status: \"Taking your SQL requests now...\" CGroup: /system.slice/mariadb.service \u2514\u25007481 /usr/sbin/mysqld mag 27 20:39:36 sabayon.local systemd[1]: Starting MariaDB database server... mag 27 20:39:37 sabayon.local mysqld[7481]: 2017-05-27 20:39:37 140257335244800 [Note] /usr/sbin/mysqld (mysqld 10.1.23-MariaDB) starting a...7481 ... mag 27 20:39:37 sabayon.local systemd[1]: Started MariaDB database server. Hint: Some lines were ellipsized, use -l to show in full. Start Apache Web Server # systemctl start apache2 Check if service is running # systemctl status apache2 \u25cf apache2.service - The Apache HTTP Server Loaded: loaded (/usr/lib64/systemd/system/apache2.service; disabled; vendor preset: disabled) Active: active (running) since sab 2017-05-27 20:47:26 CEST; 2s ago Process: 8415 ExecStop=/usr/sbin/apache2 $APACHE2_OPTS -k graceful-stop (code=exited, status=1/FAILURE) Main PID: 8532 (apache2) CGroup: /system.slice/apache2.service \u251c\u25008532 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008534 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008535 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008536 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008537 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u251c\u25008538 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND \u2514\u25008539 /usr/sbin/apache2 -D DEFAULT_VHOST -D INFO -D SSL -D SSL_DEFAULT_VHOST -D SUEXEC -D LANGUAGE -DFOREGROUND mag 27 20:47:26 sabayon.local systemd[1]: Started The Apache HTTP Server. or simply go to http://localhost or http:// Apache offers many external modules and addictional functions as www-apache/mod_ and you can find them on Sabayon Repository or Portage. Please, be sure to read Apache Docs before installing them. VirtualHosts configuration files can be found at : /etc/apache2/httpd.conf /etc/apache2/vhosts.d/00_default_*.conf To enable Apache and MariaDB service at boot just type # systemctl enable apache2 systemctl enable mariadb.","title":"Apache and MySQL services"},{"location":"articles/lamp/#manage-mysqlmariadb-phpmyadmin","text":"PhpMyAdminis a free software tool written in PHP, intended to handle the administration of MySQL over the Web. phpMyAdmin supports a wide range of operations on MySQL and MariaDB. Frequently used operations (managing databases, tables, columns, relations, indexes, users, permissions, etc) can be performed via the user interface, while you still have the ability to directly execute any SQL statement. Install PhpMyAdmin # equo i dev-db/phpmyadmin --ask Go to http://localhost/phpmyadmin or http:// /phpmyadmin to configure your PhpMyAdmin installation. By default PhpMyAdmin will be installed to /var/www/localhost/htdocs (the default apache2 working directory) as /var/www/localhost/htdocs/phpmyadmin","title":"Manage MySQL/MariaDB : PhpMyAdmin"},{"location":"articles/stage3/","text":"Installing from Stage3 Tarball This HOWTO brings the gentoo installation method (as in the Handbook) to Sabayon. Please note that \"an existing Linux system\" can be either an installed system (then you cannot use that partition for sabayon), or a live linux system. The first part is about installing a very basic gentoo system in a chrooted partition; in the second part we will use portage to install entropy and equo . We will then use equo to install a full sabayon system in the third and last part. Part 1: Gentoo install Please refer to http://www.gentoo.org/doc/en/gentoo-x86-quickinstall.xml and http://www.gentoo.org/doc/en/handbook/index.xml for more in-depth details about gentoo installation. Partitioning Do your thing and partition your disk(s). You need at least a root partition (/). Create filesystems for your partitions according to your likings. Remember that you will need to install the *progs packages for your filesystem(s). From now on we will assume that your root filesystem is mounted under /mnt/sabayon . Also if you have a /var , /boot , /usr , /home ... filesystems, create the mountpoints relative to /mnt/sabayon and mount them now. Get Gentoo installation files We will assume an x86_64 architecture here. If you're on x86 (32 bits), change \"amd64\" with \"x86\". export ARCH=\"amd64\" Pick up a mirror near you from this list: http://www.gentoo.org/main/en/mirrors.xml export MIRROR=\"ftp://distfiles.gentoo.org/pub/gentoo\" We will refer to your arch as $ARCH and to your chosen mirror as $MIRROR from now on. Download and verify stage3 archive wget -r $MIRROR/releases/$ARCH/current-stage3/ cat stage3-$ARCH-*.tar.bz2.DIGESTS & & md5sum stage3-$ARCH-*.tar.bz2 & & sha1sum stage3-$ARCH-*.tar.bz2 Download and verify portage snapshot wget $MIRROR/snapshots/portage-latest.tar.bz2 wget $MIRROR/snapshots/portage-latest.tar.bz2.md5sum cat portage-latest.tar.bz2.DIGESTS & & md5sum portage-latest.tar.bz2 & & sha1sum portage-latest.tar.bz2 Unpack stage3 and portage tar xfpj stage3-$ARCH-*.tar.bz2 -C /mnt/sabayon tar xfpj portage-latest.tar.bz2 -C /mnt/sabayon/usr Note the p option: it's for preserving file permissions and it's very important! Chroot into your new Gentoo Everything that follows is done while in /mnt/sabayon : cd /mnt/sabayon Mounting filesystems mount -o bind /dev ./dev mount -t devpts none ./dev/pts mount -t tmpfs none ./dev/shm mount -t proc none ./proc mount -t sysfs none ./sys Copying /etc/resolv.conf cp /etc/resolv.conf ./etc Chroot! chroot /mnt/sabayon /bin/bash Now you are on your Gentoo chroot! Configure environnment export LANG=en_US export LANGUAGE=${LANG} export LC_ALL=${LANG}.UTF-8 env-update eselect python set 1 #sets python 2.7 as default source /etc/profile Some early configuration Set up a root password As I '''regulary''' forget to setup the root password, let's do that as first thing: passwd Timezone cd /etc/ ln -sf ../usr/share/zoneinfo/ / localtime Where is your region and the nearest big city. Hostname Be original and change \"localhost\" to something else. Update /etc/hosts accordingly. nano -w /etc/conf.d/hostname nano -w /etc/hosts Mount points nano -w /etc/fstab Part 2: Sabayon overlay setup and installation of entropy + equo Layman layman is a gentoo tool to manage portage overlays. We will use it to get our hands on the sabayon overlay. {{Note|entropy and equo are in regular portage, hence: '''skip this step'''. # emerge --sync # make sure portage is fully up to date... or not. Up to you. portage snapshots are done daily, i see no need to sync. # USE=\"git\" emerge -avt layman # now equo is in regular portage! # layman -a sabayon # see above Entropy and Equo emerge -avt equo --autounmask-write etc-update emerge -avt equo Now we have entropy and equo installed. To make use of it, we should first generate the entropy database ('''only the very first time!'''): equo rescue generate Yes, you are sure about this. You should answer yes three times to make it happy. Perfect. Now we need to setup sabayon repositories. As an example, we use '''sabayonlinux.org''' (i.e. updated daily), but you can use '''sabayon-weekly''' instead if you want to upgrade less often. See [[En:Entropy#Package_Repositories]]. cd /etc/entropy/repositories.conf.d cp entropy_sabayonlinux.org.example entropy_sabayonlinux.org cd - Let's use equo to populate the repo db (if you used sabayon-weekly, substitute \"sabayonlinux.org\" with sabayon-weekly here): equo update equo repo mirrorsort sabayonlinux.org We're set! equo is now in a working state! Optional: Entropy: the missing bits So you will be using portage and/or want to have the same portage settings used to build your sabayon packages? Very well, here's how! When you install entropy you'll miss some vital portage bits, namely the /etc/portage/* files used to build the sabayon packages. Hopefully you can find those here: http://github.com/Sabayon/build Let's make use of them! fetch the bits! cd /opt git clone git://github.com/Sabayon/build.git sabayon-build cd /opt/sabayon-build/conf/intel/portage keep your specific stuff in \"myconf\" branch: git checkout -b myconf symlink to your : ln -sf make.conf.amd64 make.conf ln -sf package.env.amd64 package.env add commit: git add make.conf package.env git config --global user.name \"Your Name\" git config --global user.email \"your@email\" git commit rename the gentoo /etc/make.conf and /etc/portage/: cd /etc/ mv portage portage-gentoo mv make.conf make.conf-gentoo symlink to sabayon /etc/make.conf /etc/portage/: ln -sf /opt/sabayon-build/conf/intel/portage portage Of course, change make.conf.amd64 and package.env.amd64 to make.conf.x86 and package.env.x86 if you are not on x86_64. If you want to change some USE flags on certain packages you should: update your /etc/portage/package.use mask the package in /etc/entropy/packages/package.mask so that emerge will use your specified USE flags and entropy will not handle the specified package again. i.e. you want ruby support for app-editors/vim : cd /etc/portage sed -i package.use -e \"s,app-editors/vim vim-pager,app-editors/vim vim-pager ruby\" # or just use VIM! git add package.use git commit -m \"app-editors/vim +ruby\" equo mask app-editors/vim Part 3: Finish installation using equo eix To make your life easier, let's install eix (a tool for portage searching) and also the sabayon-distribution overlay (i.e. the entropy packages as a portage overlay): equo install eix layman -a sabayon-distro cd /etc/portage echo \"source /var/lib/layman/make.conf\" >> make.conf git commit -m \"source layman/make.conf in /etc/make.conf\" eix-sync Now you can use eix to quickly search for installed/installable/upgradable packages and see their versions and use flags. Filesystem progs From gentoo quickinstall, code listing 2.27: equo install xfsprogs # (if you use the XFS file system) equo install jfsutils # (if you use the JFS file system) Network stuff equo install dhcpcd # (if you need a DHCP client) equo install ppp # (if you need PPPoE ADSL connectivity) equo install wireless-tools # (if you need wireless connectivity) equo install wpa_supplicant # (if you need WPA/WPA2 authentication) equo install wicd # (if you do like wicd) Kernel bootloader equo install linux-sabayon equo install grub2 nano -w /etc/default/sabayon-grub /etc/default/sabayon-grub example: GRUB_CMDLINE_LINUX=\" console=tty1 splash=silent,theme:sabayon quiet\" Put boot options according to your system. It should at least be able to mount your rootfs (/). Run grub2-mkconfig to generate /boot/grub/grub.cfg mount /boot grub2-mkconfig -o /boot/grub/grub.cfg umount /boot System logger and Cron daemon equo install syslog-ng vixie-cron systemctl enable syslog-ng systemctl enable vixie-cron This is just a suggestion: please go for the system logger and cron daemon of your choice! Everything else Install any other packages you want using equo: equo install For example, if you want KDE, the base packages needed can be installed with equo install kdebase-meta Exit cleanup Exit the chroot exit Unmount filesystems cd /mnt/sabayon umount ./sys umount ./proc umount ./dev/shm umount ./dev/pts umount ./dev Unmount any other filesystem inside /mnt/sabayon. Then unmount the root filesystem of your new sabayon system: umount /mnt/sabayon Reboot You are now ready to reboot (well, you were ready since the \"setup grub\" step, actually) reboot Enjoy your new shiny Sabayon system installed like it should be! (please forgive the troll in me)","title":"Installing from Stage3 Tarball"},{"location":"articles/stage3/#installing-from-stage3-tarball","text":"This HOWTO brings the gentoo installation method (as in the Handbook) to Sabayon. Please note that \"an existing Linux system\" can be either an installed system (then you cannot use that partition for sabayon), or a live linux system. The first part is about installing a very basic gentoo system in a chrooted partition; in the second part we will use portage to install entropy and equo . We will then use equo to install a full sabayon system in the third and last part.","title":"Installing from Stage3 Tarball"},{"location":"articles/stage3/#part-1-gentoo-install","text":"Please refer to http://www.gentoo.org/doc/en/gentoo-x86-quickinstall.xml and http://www.gentoo.org/doc/en/handbook/index.xml for more in-depth details about gentoo installation.","title":"Part 1: Gentoo install"},{"location":"articles/stage3/#partitioning","text":"Do your thing and partition your disk(s). You need at least a root partition (/). Create filesystems for your partitions according to your likings. Remember that you will need to install the *progs packages for your filesystem(s). From now on we will assume that your root filesystem is mounted under /mnt/sabayon . Also if you have a /var , /boot , /usr , /home ... filesystems, create the mountpoints relative to /mnt/sabayon and mount them now.","title":"Partitioning"},{"location":"articles/stage3/#get-gentoo-installation-files","text":"We will assume an x86_64 architecture here. If you're on x86 (32 bits), change \"amd64\" with \"x86\". export ARCH=\"amd64\" Pick up a mirror near you from this list: http://www.gentoo.org/main/en/mirrors.xml export MIRROR=\"ftp://distfiles.gentoo.org/pub/gentoo\" We will refer to your arch as $ARCH and to your chosen mirror as $MIRROR from now on.","title":"Get Gentoo installation files"},{"location":"articles/stage3/#download-and-verify-stage3-archive","text":"wget -r $MIRROR/releases/$ARCH/current-stage3/ cat stage3-$ARCH-*.tar.bz2.DIGESTS & & md5sum stage3-$ARCH-*.tar.bz2 & & sha1sum stage3-$ARCH-*.tar.bz2","title":"Download and verify stage3 archive"},{"location":"articles/stage3/#download-and-verify-portage-snapshot","text":"wget $MIRROR/snapshots/portage-latest.tar.bz2 wget $MIRROR/snapshots/portage-latest.tar.bz2.md5sum cat portage-latest.tar.bz2.DIGESTS & & md5sum portage-latest.tar.bz2 & & sha1sum portage-latest.tar.bz2","title":"Download and verify portage snapshot"},{"location":"articles/stage3/#unpack-stage3-and-portage","text":"tar xfpj stage3-$ARCH-*.tar.bz2 -C /mnt/sabayon tar xfpj portage-latest.tar.bz2 -C /mnt/sabayon/usr Note the p option: it's for preserving file permissions and it's very important!","title":"Unpack stage3 and portage"},{"location":"articles/stage3/#chroot-into-your-new-gentoo","text":"Everything that follows is done while in /mnt/sabayon : cd /mnt/sabayon","title":"Chroot into your new Gentoo"},{"location":"articles/stage3/#mounting-filesystems","text":"mount -o bind /dev ./dev mount -t devpts none ./dev/pts mount -t tmpfs none ./dev/shm mount -t proc none ./proc mount -t sysfs none ./sys","title":"Mounting filesystems"},{"location":"articles/stage3/#copying-etcresolvconf","text":"cp /etc/resolv.conf ./etc","title":"Copying /etc/resolv.conf"},{"location":"articles/stage3/#chroot","text":"chroot /mnt/sabayon /bin/bash Now you are on your Gentoo chroot!","title":"Chroot!"},{"location":"articles/stage3/#configure-environnment","text":"export LANG=en_US export LANGUAGE=${LANG} export LC_ALL=${LANG}.UTF-8 env-update eselect python set 1 #sets python 2.7 as default source /etc/profile","title":"Configure environnment"},{"location":"articles/stage3/#some-early-configuration","text":"","title":"Some early configuration"},{"location":"articles/stage3/#set-up-a-root-password","text":"As I '''regulary''' forget to setup the root password, let's do that as first thing: passwd","title":"Set up a root password"},{"location":"articles/stage3/#timezone","text":"cd /etc/ ln -sf ../usr/share/zoneinfo/ / localtime Where is your region and the nearest big city.","title":"Timezone"},{"location":"articles/stage3/#hostname","text":"Be original and change \"localhost\" to something else. Update /etc/hosts accordingly. nano -w /etc/conf.d/hostname nano -w /etc/hosts","title":"Hostname"},{"location":"articles/stage3/#mount-points","text":"nano -w /etc/fstab","title":"Mount points"},{"location":"articles/stage3/#part-2-sabayon-overlay-setup-and-installation-of-entropyequo","text":"","title":"Part 2: Sabayon overlay setup and installation of entropy+equo"},{"location":"articles/stage3/#layman","text":"layman is a gentoo tool to manage portage overlays. We will use it to get our hands on the sabayon overlay. {{Note|entropy and equo are in regular portage, hence: '''skip this step'''. # emerge --sync # make sure portage is fully up to date... or not. Up to you. portage snapshots are done daily, i see no need to sync. # USE=\"git\" emerge -avt layman # now equo is in regular portage! # layman -a sabayon # see above","title":"Layman"},{"location":"articles/stage3/#entropy-and-equo","text":"emerge -avt equo --autounmask-write etc-update emerge -avt equo Now we have entropy and equo installed. To make use of it, we should first generate the entropy database ('''only the very first time!'''): equo rescue generate Yes, you are sure about this. You should answer yes three times to make it happy. Perfect. Now we need to setup sabayon repositories. As an example, we use '''sabayonlinux.org''' (i.e. updated daily), but you can use '''sabayon-weekly''' instead if you want to upgrade less often. See [[En:Entropy#Package_Repositories]]. cd /etc/entropy/repositories.conf.d cp entropy_sabayonlinux.org.example entropy_sabayonlinux.org cd - Let's use equo to populate the repo db (if you used sabayon-weekly, substitute \"sabayonlinux.org\" with sabayon-weekly here): equo update equo repo mirrorsort sabayonlinux.org We're set! equo is now in a working state!","title":"Entropy and Equo"},{"location":"articles/stage3/#optional-entropy-the-missing-bits","text":"So you will be using portage and/or want to have the same portage settings used to build your sabayon packages? Very well, here's how! When you install entropy you'll miss some vital portage bits, namely the /etc/portage/* files used to build the sabayon packages. Hopefully you can find those here: http://github.com/Sabayon/build Let's make use of them!","title":"Optional: Entropy: the missing bits"},{"location":"articles/stage3/#fetch-the-bits","text":"cd /opt git clone git://github.com/Sabayon/build.git sabayon-build cd /opt/sabayon-build/conf/intel/portage","title":"fetch the bits!"},{"location":"articles/stage3/#keep-your-specific-stuff-in-myconf-branch","text":"git checkout -b myconf","title":"keep your specific stuff in \"myconf\" branch:"},{"location":"articles/stage3/#symlink-to-your","text":"ln -sf make.conf.amd64 make.conf ln -sf package.env.amd64 package.env","title":"symlink to your :"},{"location":"articles/stage3/#add-commit","text":"git add make.conf package.env git config --global user.name \"Your Name\" git config --global user.email \"your@email\" git commit","title":"add &amp; commit:"},{"location":"articles/stage3/#rename-the-gentoo-etcmakeconf-and-etcportage","text":"cd /etc/ mv portage portage-gentoo mv make.conf make.conf-gentoo","title":"rename the gentoo /etc/make.conf and /etc/portage/:"},{"location":"articles/stage3/#symlink-to-sabayon-etcmakeconf-etcportage","text":"ln -sf /opt/sabayon-build/conf/intel/portage portage Of course, change make.conf.amd64 and package.env.amd64 to make.conf.x86 and package.env.x86 if you are not on x86_64. If you want to change some USE flags on certain packages you should: update your /etc/portage/package.use mask the package in /etc/entropy/packages/package.mask so that emerge will use your specified USE flags and entropy will not handle the specified package again. i.e. you want ruby support for app-editors/vim : cd /etc/portage sed -i package.use -e \"s,app-editors/vim vim-pager,app-editors/vim vim-pager ruby\" # or just use VIM! git add package.use git commit -m \"app-editors/vim +ruby\" equo mask app-editors/vim","title":"symlink to sabayon /etc/make.conf /etc/portage/:"},{"location":"articles/stage3/#part-3-finish-installation-using-equo","text":"","title":"Part 3: Finish installation using equo"},{"location":"articles/stage3/#eix","text":"To make your life easier, let's install eix (a tool for portage searching) and also the sabayon-distribution overlay (i.e. the entropy packages as a portage overlay): equo install eix layman -a sabayon-distro cd /etc/portage echo \"source /var/lib/layman/make.conf\" >> make.conf git commit -m \"source layman/make.conf in /etc/make.conf\" eix-sync Now you can use eix to quickly search for installed/installable/upgradable packages and see their versions and use flags.","title":"eix"},{"location":"articles/stage3/#filesystem-progs","text":"From gentoo quickinstall, code listing 2.27: equo install xfsprogs # (if you use the XFS file system) equo install jfsutils # (if you use the JFS file system)","title":"Filesystem progs"},{"location":"articles/stage3/#network-stuff","text":"equo install dhcpcd # (if you need a DHCP client) equo install ppp # (if you need PPPoE ADSL connectivity) equo install wireless-tools # (if you need wireless connectivity) equo install wpa_supplicant # (if you need WPA/WPA2 authentication) equo install wicd # (if you do like wicd)","title":"Network stuff"},{"location":"articles/stage3/#kernel-bootloader","text":"equo install linux-sabayon equo install grub2 nano -w /etc/default/sabayon-grub /etc/default/sabayon-grub example: GRUB_CMDLINE_LINUX=\" console=tty1 splash=silent,theme:sabayon quiet\" Put boot options according to your system. It should at least be able to mount your rootfs (/). Run grub2-mkconfig to generate /boot/grub/grub.cfg mount /boot grub2-mkconfig -o /boot/grub/grub.cfg umount /boot","title":"Kernel &amp; bootloader"},{"location":"articles/stage3/#system-logger-and-cron-daemon","text":"equo install syslog-ng vixie-cron systemctl enable syslog-ng systemctl enable vixie-cron This is just a suggestion: please go for the system logger and cron daemon of your choice!","title":"System logger and Cron daemon"},{"location":"articles/stage3/#everything-else","text":"Install any other packages you want using equo: equo install For example, if you want KDE, the base packages needed can be installed with equo install kdebase-meta","title":"Everything else"},{"location":"articles/stage3/#exit-cleanup","text":"","title":"Exit &amp; cleanup"},{"location":"articles/stage3/#exit-the-chroot","text":"exit","title":"Exit the chroot"},{"location":"articles/stage3/#unmount-filesystems","text":"cd /mnt/sabayon umount ./sys umount ./proc umount ./dev/shm umount ./dev/pts umount ./dev Unmount any other filesystem inside /mnt/sabayon. Then unmount the root filesystem of your new sabayon system: umount /mnt/sabayon","title":"Unmount filesystems"},{"location":"articles/stage3/#reboot","text":"You are now ready to reboot (well, you were ready since the \"setup grub\" step, actually) reboot Enjoy your new shiny Sabayon system installed like it should be! (please forgive the troll in me)","title":"Reboot"},{"location":"articles/systemd/","text":"Systemd Guide systemd is a System and Service Manager for Linux , compatible with SysV and LSB init scripts. systemd provides aggressive parallelization capabilities, uses socket and D-Bus activation for starting services, offers on-demand starting of daemons, keeps track of processes using Linux control groups, supports snapshotting and restoring of the system state, maintains mount and automount points and implements an elaborate transactional dependency-based service control logic. systemctl usage the basics Verifying Bootup As many of you know, systemd is the new init system. Traditionally, when booting up a Linux system, you see a lot of little messages passing by on your screen, if they are shown at all, given we use graphical boot splash technology like Plymouth these days. Nonetheless the information of the boot screens was and still is very relevant, because it shows you for each service that is being started as part of bootup, whether it managed to start up successfully or failed (with those green or red [ OK ] or [ FAILED ] indicators). systemd has feature that tracks and remembers for each service whether it started up successfully, whether it exited with a non-zero exit code, whether it timed out, or whether it terminated abnormally (by segfaulting or similar), both during start-up and runtime. By simply typing systemctl in your shell you can query the state of all services, both systemd native and SysV/LSB services: # root @ 15:51:25 ] bwg-inc # ]\u00ac systemctl # UNIT LOAD ACTIVE SUB DESCRIPTION # boot.automount loaded active waiting boot.automount # proc-sys...t_misc.automount loaded active waiting Arbitrary Executable File Fo # sys-devi...und-card0.device loaded active plugged NM10/ICH7 Family High Defini # sys-devi...-net-p1p1.device loaded active plugged RTL8101E/RTL8102E PCI Expres # sys-devi...et-wlp3s0.device loaded active plugged AR242x / AR542x Wireless Net # -.mount loaded active mounted / # home2.mount loaded active mounted /home2 # tmp.mount loaded active mounted /tmp # ntpd.service loaded maintenance maintenance Network Time Service # LOAD = Reflects whether the unit definition was properly loaded. # ACTIVE = The high-level unit activation state, i.e. generalization of SUB. # SUB = The low-level unit activation state, values depend on unit type. # # 99 loaded units listed. Pass --all to see loaded but inactive units, too. # To show all installed unit files use 'systemctl list-unit-files'. Look at the ACTIVE column, which shows you the high-level state of a service, whether it is active (i.e. running), inactive (i.e. not running) or in any other state. If you look closely you'll see one item in the list that is marked maintenance and highlighted in red. This informs you about a service that failed to run or otherwise encountered a problem. In this case this is ntpd. Now, let's find out what actually happened to ntpd, with the systemctl status command: # root @ 15:52:45 ] bwg-inc # ]\u00ac systemctl status ntpd.service # ntpd.service - Network Time Service # Loaded: loaded (/etc/systemd/system/ntpd.service) # Active: maintenance # Main: 953 (code#exited, status#255) # CGroup: name=systemd:/systemd-1/ntpd.service This shows us that NTP terminated during runtime (when it ran as PID 953), and tells us exactly the error condition: the process exited with an exit status of 255. Killing Services Killing a system daemon is easy, right? Or is it? Sure, as long as your daemon persists only of a single process this might actually be somewhat true. You type killall rsyslogd and the syslog daemon is gone. But here comes systemd to the rescue: With 'systemctl kill' you can easily send a signal to all processes of a service. Example: # systemctl kill crond.service This will ensure that SIGTERM is delivered to all processes of the crond service, not just the main process. Of course, you can also send a different signal if you wish. For example, if you are bad-ass you might want to go for SIGKILL right-away: # systemctl kill -s SIGKILL crond.service And there you go, the service will be brutally slaughtered in its entirety, regardless how many times it forked, whether it tried to escape supervision by double forking or fork bombing. Sometimes all you need is to send a specific signal to the main process of a service, maybe because you want to trigger a reload via SIGHUP. Instead of going via the PID file, here's an easier way to do this: # systemctl kill -s HUP --kill-who=main crond.service How does this relate to systemctl stop? kill goes directly and sends a signal to every process in the group, however stop goes through the official configured way to shut down a service, i.e. invokes the stop command configured with ExecStop= in the service file. Usually stop should be sufficient. kill is the tougher version. stop, disable, or mask a service... The Three Levels of \"Off\" In systemd, there are three levels of turning off a service (or other unit). Let's have a look which those are: You can stop a service. That simply terminates the running instance of the service and does little else.: # systemctl stop ntpd.service You can disable a service. This unhooks a service from its activation triggers. That means, that depending on your service it will no longer be activated on boot, by socket or bus activation or by hardware plug (or any other trigger that applies to it). However, you can still start it manually if you wish. If there is already a started instance disabling a service will not have the effect of stopping it. : # systemctl disable ntpd.service Disabling a service is a permanent change; until you undo it it will be kept, even across reboots. You can mask a service. This is like disabling a service, but on steroids. It not only makes sure that service is not started automatically anymore, but even ensures that a service cannot even be started manually anymore. This is a bit of a hidden feature in systemd, since it is not commonly useful and might be confusing the user. But here's how you do it: # systemctl mask ntpd.service # ln -s /dev/null /etc/systemd/system/ntpd.service By symlinking a service file to /dev/null you tell systemd to never start the service in question and completely block its execution. Unit files stored in /etc/systemd/system override those from /usr/lib/systemd/system that carry the same name. The former directory is administrator territory, the latter terroritory of your package manager. By installing your symlink in /etc/systemd/system/ntpd.service you make sure that systemd will never read the upstream shipped service file /usr/lib/systemd/system/ntpd.service . Processes and Common Admin Tools Which Service Owns Which Processes? In systemd every process that is spawned is placed in a control group named after its service. Control groups (or cgroups) are simply groups of processes that can be arranged in a hierarchy and labelled individually. When processes spawn other processes, these children-processes are automatically made members of the parents cgroup. Cgroups can be used as an effective way to label processes after the service they belong to and be sure that the service cannot escape from the label, Regardless how often it forks or renames itself. Here i discuss two commands you may use to relate systemd services and processes. ps and systemd-cgls ps # ps xawf -eo pid,user,cgroup,args # PID USER CGROUP COMMAND # 271 root 4:cpuacct,cpu:/system/crond /usr/sbin/crond -n # 272 root 4:cpuacct,cpu:/system/atd.s /usr/sbin/atd -f # 273 root 4:cpuacct,cpu:/system/kdm.s /usr/bin/kdm vt1 # 281 root 4:cpuacct,cpu:/system/kdm.s _ /usr/bin/X :0 vt2 -background none -nolisten tcp -seat seat0 -auth /var/run/kdm/A:0-DZRMfb # 287 root 2:name=systemd:/user/1000.u _ -:0 # 351 apostee+ 2:name=systemd:/user/1000.u _ awesome # 376 apostee+ 2:name=systemd:/user/1000.u _ /usr/bin/ssh-agent /bin/sh -c exec -l /bin/bash -c \"awesome\" # 296 polkitd 4:cpuacct,cpu:/system/polki /usr/lib/polkit-1/polkitd --no-debug # 311 root 4:cpuacct,cpu:/system/dbus. /usr/sbin/modem-manager # 316 root 4:cpuacct,cpu:/system/bluet /usr/sbin/bluetoothd -n # 326 rpc 4:cpuacct,cpu:/system/rpcbi /sbin/rpcbind -w # 339 root 4:cpuacct,cpu:/system/wpa_s /usr/sbin/wpa_supplicant -u -f /var/log/wpa_supplicant.log -c /etc/wpa_supplicant/wpa_supplicant. # 365 apostee+ 2:name=systemd:/user/1000.u dbus-launch --sh-syntax --exit-with-session # 366 apostee+ 2:name=systemd:/user/1000.u /bin/dbus-daemon --fork --print-pid 4 --print-address 6 --session # 422 apostee+ 2:name=systemd:/user/1000.u xscreensaver # 424 apostee+ 2:name=systemd:/user/1000.u conky In the third column you see the cgroup systemd assigned to each process. If you want, you can set the shell alias psc (~/,bashrc) to the ps command line shown above: # alias psc='ps xawf -eo pid,user,cgroup,args' systemd-cgls Another way to present the same information is the systemd-cgls tool which is shipped with systemd. It shows the cgroup hierarchy in a pretty tree. Its output looks like this: # systemd-cgls # \u2502 \u251c\u2500systemd-logind.service # \u2502 \u251c\u2500alsa-state.service # \u2502 \u2502 \u2514\u2500253 /usr/sbin/alsactl -s -n 19 -c -E ALSA_CONFIG_PATH#/etc/alsa/alsactl.conf --initfile#/lib/alsa/init/00main rdaemon # \u2502 \u251c\u2500systemd-udevd.service # \u2502 \u2502 \u2514\u2500163 /usr/lib/systemd/systemd-udevd # \u2502 \u2514\u2500systemd-journald.service # \u2502 \u2514\u2500147 /usr/lib/systemd/systemd-journald # \u2514\u2500user # \u2514\u25001000.user # \u2514\u25001.session # \u251c\u2500 287 -:0 # \u251c\u2500 351 awesome # \u251c\u2500 365 dbus-launch --sh-syntax --exit-with-session # \u251c\u2500 366 /bin/dbus-daemon --fork --print-pid 4 --print-address 6 --session # \u251c\u2500 376 /usr/bin/ssh-agent /bin/sh -c exec -l /bin/bash -c \"awesome\" # \u251c\u2500 422 xscreensaver # \u251c\u2500 424 conky # \u251c\u2500 464 /usr/libexec/at-spi-bus-launcher # \u251c\u2500 469 /usr/libexec/gvfsd # \u251c\u2500 497 /usr/lib/firefox/firefox # \u251c\u25002267 /usr/bin/python /usr/bin/terminator # \u251c\u25002275 gnome-pty-helper # \u251c\u25002276 /bin/bash # \u251c\u25002318 su # \u251c\u25002326 bash # \u251c\u25002480 systemd-cgls # \u2514\u25002481 less As you can see, this command shows the processes by their cgroup, as systemd labels the cgroups after the services. If you look closely you will notice that a number of processes have been assigned to the cgroup /user. systemd does not only maintains services in cgroups, but user session processes as well. journalctl usage let's start with some basics. To access the logs of the journal use the journalctl tool. To have a first look at the logs, just type in: # journalctl If you run this as root you will see all logs generated on the system, from system components the same way as for logged in users. The output you will get looks like a pixel-perfect copy of the traditional /var/log/messages format, but actually has a couple of improvements over it: Lines of error priority (and higher) will be highlighted red. Lines of notice/warning priority will be highlighted bold. The timestamps are converted into your local time-zone. The output is auto-paged with your pager of choice (defaults to less). This will show all available data, including rotated logs. Access Control Browsing logs this way is already pretty nice. But requiring to be root sucks of course, even administrators tend to do most of their work as unprivileged users these days. By default, Journal users can only watch their own logs, unless they are root or in the adm group. To make watching system logs more fun, you could add yourselve to adm: # usermod -a -G adm yourusername After logging out and back in as yourusername you have access to the full journal of the system and all users: $ journalctl Live View If invoked without parameters journalctl will show you the current log database. Sometimes one needs to watch logs as they grow, where one previously used tail -f /var/log/messages : $ journalctl -f Yes, this does exactly what you expect it to do: it will show you the last ten logs lines, and then wait for changes and show them as they take place. Basic Filtering When invoking journalctl without parameters you'll see the whole set of logs, beginning with the oldest message stored. That of course, can be a lot of data. Much more useful is just viewing the logs of the current boot: $ journalctl -b This will show you only the logs of the current boot, with all the gimmicks mentioned. But sometimes even this is way too much data to process. So let's just listing all the real issues to care about: all messages of priority levels ERRORS and worse, from the current boot: $ journalctl -b -p err But, if you reboot only seldom the -b makes little sense, filtering based on time is much more useful: $ journalctl --since#yesterday And there you go, all log messages from the day before at 00:00 in the morning until right now. Awesome! Of course, we can combine this with -p err or a similar match. But suppose, we are looking for something that happened on the 15th of October, or was it the 16th? $ journalctl --since#2012-10-15 --until#\"2011-10-16 23:59:59\" And there we go, we found what we were looking for. But i noticed that some CGI script in Apache was acting up earlier today, let's see what Apache logged at that time: $ journalctl -u httpd --since#00:00 --until#9:30 There we found it. But... , wasn't there an issue with that disk /dev/sdc? Let's figure out what was going on there: $ journalctl /dev/sdc Ouch ! a disk error! Hmm, maybe quickly replace the disk before we lose data. Wait... didn't I see that the vpnc binary was nagging? Let's check for that: $ journalctl /usr/sbin/vpnc I don't get this, this seems to be some weird interaction with dhclient, let's see both outputs, interleaved: $ journalctl /usr/sbin/vpnc /usr/sbin/dhclient As you can see here with the given examples, Journalctl is a pretty advanced tool, than can track down pretty much anything. But we're not done yet. Journalctl has some more to offer, which will be showed in the section Advanced Usage. Advanced Administration Disable Paging You can change and disable paging using the $SYSTEMD_PAGER environment variable. You may end up with truncated lines, if you set it to \"\" or cat as suggested in the manual. Try this: export SYSTEMD_PAGER#\"cat|cat\" Add it to ~/.bashrc or /etc/profile.d/ to make it permanent. Advanced Filtering Internally systemd stores each log entry with a set of implicit meta data. This meta data looks a lot like an environment block, but actually is a bit more powerful. This implicit meta data is collected for each and every log message, without user intervention. The data will be there, and wait to be used by you. Let's see how this looks: $ journalctl -o verbose -n $ Fri, 2013-11-01 19:22:34 CET [s#ac9e9c423355411d87bf0ba1a9b424e8;i#4301;b#5335e9cf5d954633bb99aefc0ec38c25;m#882ee28d2;t#4ccc0f98326e6;x#f21e8b1b0994d7ee] PRIORITY=6 SYSLOG_FACILITY=3 _MACHINE_ID=a91663387a90b89f185d4e860000001a _HOSTNAME=epsilon _TRANSPORT=syslog SYSLOG_IDENTIFIER=avahi-daemon _COMM=avahi-daemon _EXE=/usr/sbin/avahi-daemon _SYSTEMD_CGROUP=/system/avahi-daemon.service _SYSTEMD_UNIT=avahi-daemon.service _SELINUX_CONTEXT=system_u:system_r:avahi_t:s0 _UID=70 _GID=70 _CMDLINE=avahi-daemon: registering [epsilon.local] MESSAGE=Joining mDNS multicast group on interface wlan0.IPv4 with address 172.31.0.53. _BOOT_ID=5335e9cf5d954633bb99aefc0ec38c25 _PID=27937 SYSLOG_PID=27937 _SOURCE_REALTIME_TIMESTAMP=1351029098747042 (I cut out a lot here, I don't want to make this story overly long. Without the -n parameter it shows you the last 10 log entries, but I cut out all but the last.) With the -o verbose switch we enabled verbose output. Instead of showing a pixel-perfect copy of classic /var/log/messages that only includes a minimimal subset of what is available, we now see all the details the journal has about each entry, but it's highly interesting: there is user credential information. Now, as it turns out the journal database is indexed by all of these fields, out-of-the-box! Let's try this out: $ journalctl _UID=70 And there you go, this will show all log messages logged from Linux user ID 70. As it turns out you can easily combine these matches: $ journalctl _UID=70 _UID=71 Specifying two matches for the same field will result in a logical OR combination of the matches. All entries matching either will be shown, i.e. all messages from either UID 70 or 71 If you specify two matches for different field names, they will be combined with a logical AND. All entries matching both will be shown now, meaning that all messages from processes named avahi-daemon and host bwg-inc. $ journalctl _HOSTNAME=bwg-inc _COMM=avahi-daemon But of course, that's not fancy enough for us. We must go deeper: $ journalctl _HOSTNAME=bwg-inc _UID=70 + _HOSTNAME#epsilon _COMM=avahi-daemon The + is an explicit OR you can use in addition to the implied OR when you match the same field twice. The line above means: show me everything from host bwg-inc with UID 70, or of host epsilon with a process name of avahi-daemon. And now it becomes Magic Who can remember all those values a field can take in the journal, I mean, who has that kind of photographic memory? Well, the journal has: $ journalctl -F _SYSTEMD_UNIT This will show us all values the field _SYSTEMD_UNIT takes in the database, or in other words: the names of all systemd services which ever logged into the journal. This makes it super-easy to build nice matches. Systemd Timers systemd is capable of taking on a significant subset of the functionality of Cron through built-in support for calendar time events as well as monotonic time events. While we previously used Cron, systemd also provides a good structure to set up Cron-scheduling. Running a single script Let\u2019s say you have a script /usr/local/bin/myscript that you want to run every hour. service file First, create a service file, and put it in /etc/systemd/system/ # nano -w /etc/systemd/system/myscript.service with the following content: [Unit] Description=MyScript [Service] Type=simple ExecStart=/usr/local/bin/myscript Note that it is important to set the Type variable to be \u201csimple\u201d, not \u201coneshot\u201d. Using \u201coneshot\u201d makes it so that the script will be run the first time, and then systemd thinks that you don\u2019t want to run it again, and will turn off the timer we make next. timer file Next, create a timer file, and put it also in the same directory as the service file above. # nano -w /etc/systemd/system/myscript.timer with the following content: [Unit] Description=Runs myscript every hour [Timer] Time to wait after booting before we run first time OnBootSec=10min Time between running each consecutive time OnUnitActiveSec=1h Unit=myscript.service [Install] WantedBy=multi-user.target enable/start Rather than starting / enabling the service file, you use the timer. # systemctl start myscript.timer and enable it with each boot: # systemctl enable myscript.timer Running Multiple Scripts on the Same Timer Now let\u2019s say there are a bunch of scripts you want to run, all at the same time. In this case, you will want make a couple changes on the above formula. service files Create the service files to run your scripts as showed previously, but include the following section at the end of each service file: [Install] WantedBy=mytimer.target If there is any ordering dependency in your service files, be sure you specify it with the After=something.service and/or Before=whatever.service parameters within the Description section. timer file You only need a single timer file. Create mytimer.timer, as outlined above. target file You can create the target that all these scripts depend upon., # nano -w /etc/systemd/system/mytimer.target with the following content: [Unit] Description=Mytimer Lots more stuff could go here, but it's situational. Look at systemd.unit man page. enable/start You need to enable each of the service files, as well as the timer: systemctl enable script1.service systemctl enable script2.service ... systemctl enable mytimer.timer systemctl start mytimer.service Hourly, daily and weekly events One strategy which can be used for creating this functionality is through timers which call in targets. All services which need to be run hourly can be called in as dependencies of these targets. First, the creation of a few directories is required: # mkdir /etc/systemd/system/timer-{hourly,daily,weekly}.target.wants The following files will need to be created in the paths specified in order for this to work. hourly events # nano -w /etc/systemd/system/timer-hourly.timer with it's content: [Unit] Description=Hourly Timer [Timer] OnBootSec=5min OnUnitActiveSec=1h Unit=timer-hourly.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-hourly.target with it's content: [Unit] Description=Hourly Timer Target StopWhenUnneeded=yes daily events # nano -w /etc/systemd/system/timer-daily.timer content: [Unit] Description=Daily Timer [Timer] OnBootSec=10min OnUnitActiveSec=1d Unit=timer-daily.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-daily.target content: [Unit] Description=Daily Timer Target StopWhenUnneeded=yes weekly events # nano -w /etc/systemd/system/timer-weekly.timer content: [Unit] Description=Weekly Timer [Timer] OnBootSec=15min OnUnitActiveSec=1w Unit=timer-weekly.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-weekly.target content: [Unit] Description=Weekly Timer Target StopWhenUnneeded=yes adding events Adding events to these targets is as easy as dropping them into the correct wants folder. So if you wish for a particular event to take place daily, create a systemd service file and drop it into the relevant folder. For example, if you wish to run mlocate-update.service daily (which runs mlocate), you would create the following file: # nano -w /etc/systemd/system/timer-daily.target.wants/mlocate-update.service [Unit] Description=updates the mlocate database [Service] User= # Add a user if you wish the service to be executes as a particular user, else delete this line Type= # Simple by default, change it if you know what you are doing, else delete this line Nice=19 IOSchedulingClass=2 IOSchedulingPriority=7 ExecStart=/usr/bin/updatedb --option1 --option2 # More than one ExecStart can be used if required enable and start the timers # systemctl enable timer-{hourly,daily,weekly}.timer systemctl start timer-{hourly,daily,weekly}.timer Starting events according to the calendar If you wish to start a service according to a calendar event and not a monotonic interval (i.e. you wish to replace the functionality of crontab), you will need to create a new timer and link your service file to that. An example would be: nano -w /etc/systemd/system/foo.timer content: [Unit] Description=foo timer [Timer] OnCalendar=Mon-Thu -9-28 :30:00 # To add a time of your choosing here, please refer to systemd.time manual page for the correct format Unit=foo.service [Install] WantedBy=basic.target The service file may be created the same way as the events for monotonic clocks. However, take care to put them in the /etc/systemd/system/ folder. timedatectl - - Control the system time and date. systemd brings a new way of setting the system time and date, and making sure that time in system is correct. time, date, and timezone The check status: # timedatectl status gives you a very nice overview of the current settings of the system clock and RTC. Example: Local time: Sun 2014-02-02 15:56:40 CET Universal time: Sun 2014-02-02 14:56:40 UTC RTC time: Sun 2014-02-02 14:56:40 Timezone: Europe/Amsterdam (CET, +0100) NTP enabled: n/a NTP synchronized: no RTC in local TZ: no DST active: no Last DST change: DST ended at Sun 2013-10-27 02:59:59 CEST Sun 2013-10-27 02:00:00 CET Next DST change: DST begins (the clock jumps one hour forward) at Sun 2014-03-30 01:59:59 CET Sun 2014-03-30 03:00:00 CEST As you can see, it even shows at which date the clock will jump one hour forward/back. If, for some reason the time or date is not right., you can change it. Synax: # timedatectl set-time [time] The time may be specified in the format: \"2013-11-30 18:17:16\". Thus: timedatectl set-time 2013-11-30 18:17:16 Your Timezone can also be specified, using timedatectl set-timezone . Available time zones can be listed with: timedatectl list-timezones Set your time zone of choice: timedatectl set-timezone Europe/Amsterdam time synchronization (NTP) To enable NTP (NTP based network time synchronization): * Install NTP: equo install net-misc/ntp Enable service to start at boot and start it now: systemctl enable ntpd systemctl start ntpd Enable time synchronization with NTP: timedatectl set-ntp 1 Fore more info: # timedatectl -h # man timedatectl localectl - - Control the system locale and keyboard layout settings localectl may be used to query and change the system locale and keyboard layout settings. *The system locale controls the language settings of system services and of the UI before the user logs in, such as the display manager, as well as the default for users after login. *The keyboard settings control the keyboard layout used on the text console and of the graphical UI before the user logs in, such as the display manager, as well as the default for users after login. The syntaxes are: # localectl status (shows your current locale settings: # localectl set-locale (\"localectl list-locales\" will show all known locales) # localectl set-keymap (\"localectl list-keymaps\" will show all known virtual console keyboard mappings) # localectl set-x11-keymap LAYOUT [MODEL] [VARIANT] [OPTIONS] for a complete listing of all available x11-keymap layouts, models, variants and options use: # localectl list-x11-keymap-layouts # localectl list-x11-keymap-models # localectl list-x11-keymap-variants # localectl list-x11-keymap-options Now, say you want to set the system locale to: \"en_US.UTF-8\", enter: localectl set-locale LANG#en_US.UTF-8 To set the virtual console keyboard map to US, enter: localectl set-keymap us it Note here that you can enter a second keymap to define a toggle keyboard mapping. To set the system default keyboard mapping for X11, and define your model, variant, and some options, enter: localectl set-x11-keymap us apple mac_nodeadkeys numpad:pc So, in the above example the user has a Apple aluminum mac keyboard, no deadkeys, and a PC compatible numeric pad. --no-convert If set-keymap or set-x11-keymap is invoked and this option is passed then the keymap will not be converted from the console to X11, or X11 to console, respectively. It means that if this option is NOT passed to set-keymap, the selected setting is also applied to the default keyboard mapping of X11, after converting it to the closest matching X11 keyboard mapping, and vice versa. For a complete overview and list of all possible commands/options of localectl, please enter: # localectl --help or # man localectl analyzing and performance analyzing the boot process WARNING !!! Before actually trying to speedup the boot process, you really have to know what you are doing and how to revert your actions. When moving, disabling or masking service files without knowing why, the boot process can take even longer than before. systemd provides a tool called systemd-analyze that can be used to show timing details about the boot process, including an svg plot showing units waiting for their dependencies. You can see which unit files are causing your boot process to slow down. You can then optimize your system accordingly. To see how much time was spent in kernelspace and userspace on boot, simply use: systemd-analyze To list the started unit files, sorted by the time each of them took to start up: systemd-analyze blame At some points of the boot process, things can not proceed until a given unit succeeds. To see which units find themselves at these critical points in the startup chain, do: systemd-analyze critical-chain You can also create a SVG file which describes your boot process graphically, similiar to Bootchart: systemd-analyze plot plot.svg See man systemd-analyze for details. analyzing using bootchart readahead Systemd comes with its own readahead implementation, this should in principle improve boot time. However, depending on your kernel version and the type of your hard drive, your mileage may vary (i.e. it might be slower). To enable, do: systemctl enable systemd-readahead-collect systemd-readahead-replay In order for the readahead to work, you should reboot a couple of times, because it needs to adapt to the changed boot process. filesystem mounts If btrfs is in use for the root filesystem, there is no need for a fsck on every boot like other filesystems. If this is the case,you may want to mask the systemd-fsck-root.service systemd will still fsck any relevant filesystems with the systemd-fsck@.service You can also remove API filesystems from /etc/fstab, as systemd will mount them itself. It is not uncommon for users to have a /tmp and/or /dev/shm entry carried over from sysvinit, but you may have noticed that systemd already takes care of this. If you want to give /tmp a size, say: 4Gb., you can edit the file: nano -w /usr/lib/systemd/system/tmp.mount and add size#4096M to section: [Mount] : [Mount] What#tmpfs Where#/tmp Type#tmpfs Options#mode#1777,strictatime,size#4096M If on seperate partitions, other filesystems like /home and /boot can be mounted with custom mount units. Adding noauto,x-systemd.automount will buffer all access to that partition, and will fsck and mount it on first access, reducing the number of filesystems it must fsck/mount during the boot process. NOTE: this will make your /home and /boot filesystem type autofs, which is ignored by mlocate by default. If you use mlocate, and want /home and/or /boot still to be indexed by mlocate., edit the file: /etc/updatedb.conf }} and remove the entries from the \"PRUNEPATHS#\" \" : PRUNE_BIND_MOUNTS = \"yes\" PRUNEFS = \"9p afs anon_inodefs auto autofs bdev binfmt_misc cgroup cifs coda configfs cpuset cramfs debugfs devpts devtmpfs ecryptfs exofs ftpfs fuse fuse.enc$ PRUNENAMES = \".git .hg .svn\" PRUNEPATHS = \"/afs /media /mnt /home/home2 /net /sfs /tmp /udev /var/cache /var/lib/pacman/local /var/lock /var/run /var/spool /var/tmp\" The speedup of automounting /home /boot may not be more than a second or two, depending on your system, so this trick may not be worth it. nano -w /etc/fstab /dev/sda3 / ext4 noatime,defaults 1 1 /dev/sda1 /boot ext4 noatime,noauto,x-systemd.automount 1 2 /dev/sda2 /home ext4 noatime,noauto,x-systemd.automount 1 2 /dev/sda5 none swap sw 0 0 debugging [http://freedesktop.org/wiki/Software/systemd/Debugging/ Debugging systemd Problems )] systemd for Administrators All links mentioned here, will lead you outside this Wiki... [http://0pointer.de/blog/projects/changing-roots.html Changing Roots )] [http://0pointer.de/blog/projects/the-new-configuration-files The New Configuration Files )] [http://0pointer.de/blog/projects/instances.html Instantiated Services )] [http://0pointer.de/blog/projects/inetd.html Converting inetd Services )] [http://0pointer.de/blog/projects/systemd-for-admins-3.html Converting a SysVinit script into systemd service file )] [http://0pointer.de/blog/projects/security.html Securing Your Services )] [http://0pointer.de/blog/projects/watchdog.html Watchdogs )] [http://0pointer.de/blog/projects/serial-console.html *Gettys on Serial Consoles)] [http://0pointer.de/blog/projects/resources.html *Managing Resources)] [http://0pointer.de/blog/projects/detect-virt.html Detecting Virtualization )] [http://www.freedesktop.org/wiki/Software/systemd/APIFileSystems/ API File Systems )] SysVinit to systemd cheatcheet http://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet systemd -index \u2014 - List of all manpages from the systemd project http://www.freedesktop.org/software/systemd/man/","title":"Systemd Guide"},{"location":"articles/systemd/#systemd-guide","text":"systemd is a System and Service Manager for Linux , compatible with SysV and LSB init scripts. systemd provides aggressive parallelization capabilities, uses socket and D-Bus activation for starting services, offers on-demand starting of daemons, keeps track of processes using Linux control groups, supports snapshotting and restoring of the system state, maintains mount and automount points and implements an elaborate transactional dependency-based service control logic.","title":"Systemd Guide"},{"location":"articles/systemd/#systemctl-usage","text":"","title":"systemctl usage"},{"location":"articles/systemd/#the-basics","text":"","title":"the basics"},{"location":"articles/systemd/#verifying-bootup","text":"As many of you know, systemd is the new init system. Traditionally, when booting up a Linux system, you see a lot of little messages passing by on your screen, if they are shown at all, given we use graphical boot splash technology like Plymouth these days. Nonetheless the information of the boot screens was and still is very relevant, because it shows you for each service that is being started as part of bootup, whether it managed to start up successfully or failed (with those green or red [ OK ] or [ FAILED ] indicators). systemd has feature that tracks and remembers for each service whether it started up successfully, whether it exited with a non-zero exit code, whether it timed out, or whether it terminated abnormally (by segfaulting or similar), both during start-up and runtime. By simply typing systemctl in your shell you can query the state of all services, both systemd native and SysV/LSB services: # root @ 15:51:25 ] bwg-inc # ]\u00ac systemctl # UNIT LOAD ACTIVE SUB DESCRIPTION # boot.automount loaded active waiting boot.automount # proc-sys...t_misc.automount loaded active waiting Arbitrary Executable File Fo # sys-devi...und-card0.device loaded active plugged NM10/ICH7 Family High Defini # sys-devi...-net-p1p1.device loaded active plugged RTL8101E/RTL8102E PCI Expres # sys-devi...et-wlp3s0.device loaded active plugged AR242x / AR542x Wireless Net # -.mount loaded active mounted / # home2.mount loaded active mounted /home2 # tmp.mount loaded active mounted /tmp # ntpd.service loaded maintenance maintenance Network Time Service # LOAD = Reflects whether the unit definition was properly loaded. # ACTIVE = The high-level unit activation state, i.e. generalization of SUB. # SUB = The low-level unit activation state, values depend on unit type. # # 99 loaded units listed. Pass --all to see loaded but inactive units, too. # To show all installed unit files use 'systemctl list-unit-files'. Look at the ACTIVE column, which shows you the high-level state of a service, whether it is active (i.e. running), inactive (i.e. not running) or in any other state. If you look closely you'll see one item in the list that is marked maintenance and highlighted in red. This informs you about a service that failed to run or otherwise encountered a problem. In this case this is ntpd. Now, let's find out what actually happened to ntpd, with the systemctl status command: # root @ 15:52:45 ] bwg-inc # ]\u00ac systemctl status ntpd.service # ntpd.service - Network Time Service # Loaded: loaded (/etc/systemd/system/ntpd.service) # Active: maintenance # Main: 953 (code#exited, status#255) # CGroup: name=systemd:/systemd-1/ntpd.service This shows us that NTP terminated during runtime (when it ran as PID 953), and tells us exactly the error condition: the process exited with an exit status of 255.","title":"Verifying Bootup"},{"location":"articles/systemd/#killing-services","text":"Killing a system daemon is easy, right? Or is it? Sure, as long as your daemon persists only of a single process this might actually be somewhat true. You type killall rsyslogd and the syslog daemon is gone. But here comes systemd to the rescue: With 'systemctl kill' you can easily send a signal to all processes of a service. Example: # systemctl kill crond.service This will ensure that SIGTERM is delivered to all processes of the crond service, not just the main process. Of course, you can also send a different signal if you wish. For example, if you are bad-ass you might want to go for SIGKILL right-away: # systemctl kill -s SIGKILL crond.service And there you go, the service will be brutally slaughtered in its entirety, regardless how many times it forked, whether it tried to escape supervision by double forking or fork bombing. Sometimes all you need is to send a specific signal to the main process of a service, maybe because you want to trigger a reload via SIGHUP. Instead of going via the PID file, here's an easier way to do this: # systemctl kill -s HUP --kill-who=main crond.service How does this relate to systemctl stop? kill goes directly and sends a signal to every process in the group, however stop goes through the official configured way to shut down a service, i.e. invokes the stop command configured with ExecStop= in the service file. Usually stop should be sufficient. kill is the tougher version.","title":"Killing Services"},{"location":"articles/systemd/#stop-disable-or-mask-a-service-the-three-levels-of-off","text":"In systemd, there are three levels of turning off a service (or other unit). Let's have a look which those are: You can stop a service. That simply terminates the running instance of the service and does little else.: # systemctl stop ntpd.service You can disable a service. This unhooks a service from its activation triggers. That means, that depending on your service it will no longer be activated on boot, by socket or bus activation or by hardware plug (or any other trigger that applies to it). However, you can still start it manually if you wish. If there is already a started instance disabling a service will not have the effect of stopping it. : # systemctl disable ntpd.service Disabling a service is a permanent change; until you undo it it will be kept, even across reboots. You can mask a service. This is like disabling a service, but on steroids. It not only makes sure that service is not started automatically anymore, but even ensures that a service cannot even be started manually anymore. This is a bit of a hidden feature in systemd, since it is not commonly useful and might be confusing the user. But here's how you do it: # systemctl mask ntpd.service # ln -s /dev/null /etc/systemd/system/ntpd.service By symlinking a service file to /dev/null you tell systemd to never start the service in question and completely block its execution. Unit files stored in /etc/systemd/system override those from /usr/lib/systemd/system that carry the same name. The former directory is administrator territory, the latter terroritory of your package manager. By installing your symlink in /etc/systemd/system/ntpd.service you make sure that systemd will never read the upstream shipped service file /usr/lib/systemd/system/ntpd.service .","title":"stop, disable, or mask a service...   The Three Levels of \"Off\""},{"location":"articles/systemd/#processes-and-common-admin-tools","text":"","title":"Processes and Common Admin Tools"},{"location":"articles/systemd/#which-service-owns-which-processes","text":"In systemd every process that is spawned is placed in a control group named after its service. Control groups (or cgroups) are simply groups of processes that can be arranged in a hierarchy and labelled individually. When processes spawn other processes, these children-processes are automatically made members of the parents cgroup. Cgroups can be used as an effective way to label processes after the service they belong to and be sure that the service cannot escape from the label, Regardless how often it forks or renames itself. Here i discuss two commands you may use to relate systemd services and processes. ps and systemd-cgls","title":"Which Service Owns Which Processes?"},{"location":"articles/systemd/#ps","text":"# ps xawf -eo pid,user,cgroup,args # PID USER CGROUP COMMAND # 271 root 4:cpuacct,cpu:/system/crond /usr/sbin/crond -n # 272 root 4:cpuacct,cpu:/system/atd.s /usr/sbin/atd -f # 273 root 4:cpuacct,cpu:/system/kdm.s /usr/bin/kdm vt1 # 281 root 4:cpuacct,cpu:/system/kdm.s _ /usr/bin/X :0 vt2 -background none -nolisten tcp -seat seat0 -auth /var/run/kdm/A:0-DZRMfb # 287 root 2:name=systemd:/user/1000.u _ -:0 # 351 apostee+ 2:name=systemd:/user/1000.u _ awesome # 376 apostee+ 2:name=systemd:/user/1000.u _ /usr/bin/ssh-agent /bin/sh -c exec -l /bin/bash -c \"awesome\" # 296 polkitd 4:cpuacct,cpu:/system/polki /usr/lib/polkit-1/polkitd --no-debug # 311 root 4:cpuacct,cpu:/system/dbus. /usr/sbin/modem-manager # 316 root 4:cpuacct,cpu:/system/bluet /usr/sbin/bluetoothd -n # 326 rpc 4:cpuacct,cpu:/system/rpcbi /sbin/rpcbind -w # 339 root 4:cpuacct,cpu:/system/wpa_s /usr/sbin/wpa_supplicant -u -f /var/log/wpa_supplicant.log -c /etc/wpa_supplicant/wpa_supplicant. # 365 apostee+ 2:name=systemd:/user/1000.u dbus-launch --sh-syntax --exit-with-session # 366 apostee+ 2:name=systemd:/user/1000.u /bin/dbus-daemon --fork --print-pid 4 --print-address 6 --session # 422 apostee+ 2:name=systemd:/user/1000.u xscreensaver # 424 apostee+ 2:name=systemd:/user/1000.u conky In the third column you see the cgroup systemd assigned to each process. If you want, you can set the shell alias psc (~/,bashrc) to the ps command line shown above: # alias psc='ps xawf -eo pid,user,cgroup,args'","title":"ps"},{"location":"articles/systemd/#systemd-cgls","text":"Another way to present the same information is the systemd-cgls tool which is shipped with systemd. It shows the cgroup hierarchy in a pretty tree. Its output looks like this: # systemd-cgls # \u2502 \u251c\u2500systemd-logind.service # \u2502 \u251c\u2500alsa-state.service # \u2502 \u2502 \u2514\u2500253 /usr/sbin/alsactl -s -n 19 -c -E ALSA_CONFIG_PATH#/etc/alsa/alsactl.conf --initfile#/lib/alsa/init/00main rdaemon # \u2502 \u251c\u2500systemd-udevd.service # \u2502 \u2502 \u2514\u2500163 /usr/lib/systemd/systemd-udevd # \u2502 \u2514\u2500systemd-journald.service # \u2502 \u2514\u2500147 /usr/lib/systemd/systemd-journald # \u2514\u2500user # \u2514\u25001000.user # \u2514\u25001.session # \u251c\u2500 287 -:0 # \u251c\u2500 351 awesome # \u251c\u2500 365 dbus-launch --sh-syntax --exit-with-session # \u251c\u2500 366 /bin/dbus-daemon --fork --print-pid 4 --print-address 6 --session # \u251c\u2500 376 /usr/bin/ssh-agent /bin/sh -c exec -l /bin/bash -c \"awesome\" # \u251c\u2500 422 xscreensaver # \u251c\u2500 424 conky # \u251c\u2500 464 /usr/libexec/at-spi-bus-launcher # \u251c\u2500 469 /usr/libexec/gvfsd # \u251c\u2500 497 /usr/lib/firefox/firefox # \u251c\u25002267 /usr/bin/python /usr/bin/terminator # \u251c\u25002275 gnome-pty-helper # \u251c\u25002276 /bin/bash # \u251c\u25002318 su # \u251c\u25002326 bash # \u251c\u25002480 systemd-cgls # \u2514\u25002481 less As you can see, this command shows the processes by their cgroup, as systemd labels the cgroups after the services. If you look closely you will notice that a number of processes have been assigned to the cgroup /user. systemd does not only maintains services in cgroups, but user session processes as well.","title":"systemd-cgls"},{"location":"articles/systemd/#journalctl-usage","text":"let's start with some basics. To access the logs of the journal use the journalctl tool. To have a first look at the logs, just type in: # journalctl If you run this as root you will see all logs generated on the system, from system components the same way as for logged in users. The output you will get looks like a pixel-perfect copy of the traditional /var/log/messages format, but actually has a couple of improvements over it: Lines of error priority (and higher) will be highlighted red. Lines of notice/warning priority will be highlighted bold. The timestamps are converted into your local time-zone. The output is auto-paged with your pager of choice (defaults to less). This will show all available data, including rotated logs.","title":"journalctl usage"},{"location":"articles/systemd/#access-control","text":"Browsing logs this way is already pretty nice. But requiring to be root sucks of course, even administrators tend to do most of their work as unprivileged users these days. By default, Journal users can only watch their own logs, unless they are root or in the adm group. To make watching system logs more fun, you could add yourselve to adm: # usermod -a -G adm yourusername After logging out and back in as yourusername you have access to the full journal of the system and all users: $ journalctl","title":"Access Control"},{"location":"articles/systemd/#live-view","text":"If invoked without parameters journalctl will show you the current log database. Sometimes one needs to watch logs as they grow, where one previously used tail -f /var/log/messages : $ journalctl -f Yes, this does exactly what you expect it to do: it will show you the last ten logs lines, and then wait for changes and show them as they take place.","title":"Live View"},{"location":"articles/systemd/#basic-filtering","text":"When invoking journalctl without parameters you'll see the whole set of logs, beginning with the oldest message stored. That of course, can be a lot of data. Much more useful is just viewing the logs of the current boot: $ journalctl -b This will show you only the logs of the current boot, with all the gimmicks mentioned. But sometimes even this is way too much data to process. So let's just listing all the real issues to care about: all messages of priority levels ERRORS and worse, from the current boot: $ journalctl -b -p err But, if you reboot only seldom the -b makes little sense, filtering based on time is much more useful: $ journalctl --since#yesterday And there you go, all log messages from the day before at 00:00 in the morning until right now. Awesome! Of course, we can combine this with -p err or a similar match. But suppose, we are looking for something that happened on the 15th of October, or was it the 16th? $ journalctl --since#2012-10-15 --until#\"2011-10-16 23:59:59\" And there we go, we found what we were looking for. But i noticed that some CGI script in Apache was acting up earlier today, let's see what Apache logged at that time: $ journalctl -u httpd --since#00:00 --until#9:30 There we found it. But... , wasn't there an issue with that disk /dev/sdc? Let's figure out what was going on there: $ journalctl /dev/sdc Ouch ! a disk error! Hmm, maybe quickly replace the disk before we lose data. Wait... didn't I see that the vpnc binary was nagging? Let's check for that: $ journalctl /usr/sbin/vpnc I don't get this, this seems to be some weird interaction with dhclient, let's see both outputs, interleaved: $ journalctl /usr/sbin/vpnc /usr/sbin/dhclient As you can see here with the given examples, Journalctl is a pretty advanced tool, than can track down pretty much anything. But we're not done yet. Journalctl has some more to offer, which will be showed in the section Advanced Usage.","title":"Basic Filtering"},{"location":"articles/systemd/#advanced-administration","text":"","title":"Advanced Administration"},{"location":"articles/systemd/#disable-paging","text":"You can change and disable paging using the $SYSTEMD_PAGER environment variable. You may end up with truncated lines, if you set it to \"\" or cat as suggested in the manual. Try this: export SYSTEMD_PAGER#\"cat|cat\" Add it to ~/.bashrc or /etc/profile.d/ to make it permanent.","title":"Disable Paging"},{"location":"articles/systemd/#advanced-filtering","text":"Internally systemd stores each log entry with a set of implicit meta data. This meta data looks a lot like an environment block, but actually is a bit more powerful. This implicit meta data is collected for each and every log message, without user intervention. The data will be there, and wait to be used by you. Let's see how this looks: $ journalctl -o verbose -n $ Fri, 2013-11-01 19:22:34 CET [s#ac9e9c423355411d87bf0ba1a9b424e8;i#4301;b#5335e9cf5d954633bb99aefc0ec38c25;m#882ee28d2;t#4ccc0f98326e6;x#f21e8b1b0994d7ee] PRIORITY=6 SYSLOG_FACILITY=3 _MACHINE_ID=a91663387a90b89f185d4e860000001a _HOSTNAME=epsilon _TRANSPORT=syslog SYSLOG_IDENTIFIER=avahi-daemon _COMM=avahi-daemon _EXE=/usr/sbin/avahi-daemon _SYSTEMD_CGROUP=/system/avahi-daemon.service _SYSTEMD_UNIT=avahi-daemon.service _SELINUX_CONTEXT=system_u:system_r:avahi_t:s0 _UID=70 _GID=70 _CMDLINE=avahi-daemon: registering [epsilon.local] MESSAGE=Joining mDNS multicast group on interface wlan0.IPv4 with address 172.31.0.53. _BOOT_ID=5335e9cf5d954633bb99aefc0ec38c25 _PID=27937 SYSLOG_PID=27937 _SOURCE_REALTIME_TIMESTAMP=1351029098747042 (I cut out a lot here, I don't want to make this story overly long. Without the -n parameter it shows you the last 10 log entries, but I cut out all but the last.) With the -o verbose switch we enabled verbose output. Instead of showing a pixel-perfect copy of classic /var/log/messages that only includes a minimimal subset of what is available, we now see all the details the journal has about each entry, but it's highly interesting: there is user credential information. Now, as it turns out the journal database is indexed by all of these fields, out-of-the-box! Let's try this out: $ journalctl _UID=70 And there you go, this will show all log messages logged from Linux user ID 70. As it turns out you can easily combine these matches: $ journalctl _UID=70 _UID=71 Specifying two matches for the same field will result in a logical OR combination of the matches. All entries matching either will be shown, i.e. all messages from either UID 70 or 71 If you specify two matches for different field names, they will be combined with a logical AND. All entries matching both will be shown now, meaning that all messages from processes named avahi-daemon and host bwg-inc. $ journalctl _HOSTNAME=bwg-inc _COMM=avahi-daemon But of course, that's not fancy enough for us. We must go deeper: $ journalctl _HOSTNAME=bwg-inc _UID=70 + _HOSTNAME#epsilon _COMM=avahi-daemon The + is an explicit OR you can use in addition to the implied OR when you match the same field twice. The line above means: show me everything from host bwg-inc with UID 70, or of host epsilon with a process name of avahi-daemon.","title":"Advanced Filtering"},{"location":"articles/systemd/#and-now-it-becomes-magic","text":"Who can remember all those values a field can take in the journal, I mean, who has that kind of photographic memory? Well, the journal has: $ journalctl -F _SYSTEMD_UNIT This will show us all values the field _SYSTEMD_UNIT takes in the database, or in other words: the names of all systemd services which ever logged into the journal. This makes it super-easy to build nice matches.","title":"And now it becomes Magic"},{"location":"articles/systemd/#systemd-timers","text":"systemd is capable of taking on a significant subset of the functionality of Cron through built-in support for calendar time events as well as monotonic time events. While we previously used Cron, systemd also provides a good structure to set up Cron-scheduling.","title":"Systemd Timers"},{"location":"articles/systemd/#running-a-single-script","text":"Let\u2019s say you have a script /usr/local/bin/myscript that you want to run every hour. service file First, create a service file, and put it in /etc/systemd/system/ # nano -w /etc/systemd/system/myscript.service with the following content: [Unit] Description=MyScript [Service] Type=simple ExecStart=/usr/local/bin/myscript Note that it is important to set the Type variable to be \u201csimple\u201d, not \u201coneshot\u201d. Using \u201coneshot\u201d makes it so that the script will be run the first time, and then systemd thinks that you don\u2019t want to run it again, and will turn off the timer we make next. timer file Next, create a timer file, and put it also in the same directory as the service file above. # nano -w /etc/systemd/system/myscript.timer with the following content: [Unit] Description=Runs myscript every hour [Timer]","title":"Running a single script"},{"location":"articles/systemd/#time-to-wait-after-booting-before-we-run-first-time","text":"OnBootSec=10min","title":"Time to wait after booting before we run first time"},{"location":"articles/systemd/#time-between-running-each-consecutive-time","text":"OnUnitActiveSec=1h Unit=myscript.service [Install] WantedBy=multi-user.target enable/start Rather than starting / enabling the service file, you use the timer. # systemctl start myscript.timer and enable it with each boot: # systemctl enable myscript.timer","title":"Time between running each consecutive time"},{"location":"articles/systemd/#running-multiple-scripts-on-the-same-timer","text":"Now let\u2019s say there are a bunch of scripts you want to run, all at the same time. In this case, you will want make a couple changes on the above formula. service files Create the service files to run your scripts as showed previously, but include the following section at the end of each service file: [Install] WantedBy=mytimer.target If there is any ordering dependency in your service files, be sure you specify it with the After=something.service and/or Before=whatever.service parameters within the Description section. timer file You only need a single timer file. Create mytimer.timer, as outlined above. target file You can create the target that all these scripts depend upon., # nano -w /etc/systemd/system/mytimer.target with the following content: [Unit] Description=Mytimer","title":"Running Multiple Scripts on the Same Timer"},{"location":"articles/systemd/#lots-more-stuff-could-go-here-but-its-situational","text":"","title":"Lots more stuff could go here, but it's situational."},{"location":"articles/systemd/#look-at-systemdunit-man-page","text":"enable/start You need to enable each of the service files, as well as the timer: systemctl enable script1.service systemctl enable script2.service ... systemctl enable mytimer.timer systemctl start mytimer.service","title":"Look at systemd.unit man page."},{"location":"articles/systemd/#hourly-daily-and-weekly-events","text":"One strategy which can be used for creating this functionality is through timers which call in targets. All services which need to be run hourly can be called in as dependencies of these targets. First, the creation of a few directories is required: # mkdir /etc/systemd/system/timer-{hourly,daily,weekly}.target.wants The following files will need to be created in the paths specified in order for this to work. hourly events # nano -w /etc/systemd/system/timer-hourly.timer with it's content: [Unit] Description=Hourly Timer [Timer] OnBootSec=5min OnUnitActiveSec=1h Unit=timer-hourly.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-hourly.target with it's content: [Unit] Description=Hourly Timer Target StopWhenUnneeded=yes daily events # nano -w /etc/systemd/system/timer-daily.timer content: [Unit] Description=Daily Timer [Timer] OnBootSec=10min OnUnitActiveSec=1d Unit=timer-daily.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-daily.target content: [Unit] Description=Daily Timer Target StopWhenUnneeded=yes weekly events # nano -w /etc/systemd/system/timer-weekly.timer content: [Unit] Description=Weekly Timer [Timer] OnBootSec=15min OnUnitActiveSec=1w Unit=timer-weekly.target [Install] WantedBy=basic.target # nano -w /etc/systemd/system/timer-weekly.target content: [Unit] Description=Weekly Timer Target StopWhenUnneeded=yes adding events Adding events to these targets is as easy as dropping them into the correct wants folder. So if you wish for a particular event to take place daily, create a systemd service file and drop it into the relevant folder. For example, if you wish to run mlocate-update.service daily (which runs mlocate), you would create the following file: # nano -w /etc/systemd/system/timer-daily.target.wants/mlocate-update.service [Unit] Description=updates the mlocate database [Service] User= # Add a user if you wish the service to be executes as a particular user, else delete this line Type= # Simple by default, change it if you know what you are doing, else delete this line Nice=19 IOSchedulingClass=2 IOSchedulingPriority=7 ExecStart=/usr/bin/updatedb --option1 --option2 # More than one ExecStart can be used if required enable and start the timers # systemctl enable timer-{hourly,daily,weekly}.timer systemctl start timer-{hourly,daily,weekly}.timer","title":"Hourly, daily and weekly events"},{"location":"articles/systemd/#starting-events-according-to-the-calendar","text":"If you wish to start a service according to a calendar event and not a monotonic interval (i.e. you wish to replace the functionality of crontab), you will need to create a new timer and link your service file to that. An example would be:","title":"Starting events according to the calendar"},{"location":"articles/systemd/#nano-w-etcsystemdsystemfootimer","text":"content: [Unit] Description=foo timer [Timer] OnCalendar=Mon-Thu -9-28 :30:00 # To add a time of your choosing here, please refer to systemd.time manual page for the correct format Unit=foo.service [Install] WantedBy=basic.target The service file may be created the same way as the events for monotonic clocks. However, take care to put them in the /etc/systemd/system/ folder.","title":"nano -w /etc/systemd/system/foo.timer"},{"location":"articles/systemd/#timedatectl-control-the-system-time-and-date","text":"systemd brings a new way of setting the system time and date, and making sure that time in system is correct.","title":"timedatectl - - Control the system time and date."},{"location":"articles/systemd/#time-date-and-timezone","text":"The check status: # timedatectl status gives you a very nice overview of the current settings of the system clock and RTC. Example: Local time: Sun 2014-02-02 15:56:40 CET Universal time: Sun 2014-02-02 14:56:40 UTC RTC time: Sun 2014-02-02 14:56:40 Timezone: Europe/Amsterdam (CET, +0100) NTP enabled: n/a NTP synchronized: no RTC in local TZ: no DST active: no Last DST change: DST ended at Sun 2013-10-27 02:59:59 CEST Sun 2013-10-27 02:00:00 CET Next DST change: DST begins (the clock jumps one hour forward) at Sun 2014-03-30 01:59:59 CET Sun 2014-03-30 03:00:00 CEST As you can see, it even shows at which date the clock will jump one hour forward/back. If, for some reason the time or date is not right., you can change it. Synax: # timedatectl set-time [time] The time may be specified in the format: \"2013-11-30 18:17:16\". Thus: timedatectl set-time 2013-11-30 18:17:16 Your Timezone can also be specified, using timedatectl set-timezone . Available time zones can be listed with: timedatectl list-timezones Set your time zone of choice: timedatectl set-timezone Europe/Amsterdam","title":"time, date, and timezone"},{"location":"articles/systemd/#time-synchronization-ntp","text":"To enable NTP (NTP based network time synchronization): * Install NTP: equo install net-misc/ntp Enable service to start at boot and start it now: systemctl enable ntpd systemctl start ntpd Enable time synchronization with NTP: timedatectl set-ntp 1 Fore more info: # timedatectl -h # man timedatectl","title":"time synchronization (NTP)"},{"location":"articles/systemd/#localectl-control-the-system-locale-and-keyboard-layout-settings","text":"localectl may be used to query and change the system locale and keyboard layout settings. *The system locale controls the language settings of system services and of the UI before the user logs in, such as the display manager, as well as the default for users after login. *The keyboard settings control the keyboard layout used on the text console and of the graphical UI before the user logs in, such as the display manager, as well as the default for users after login. The syntaxes are: # localectl status (shows your current locale settings: # localectl set-locale (\"localectl list-locales\" will show all known locales) # localectl set-keymap (\"localectl list-keymaps\" will show all known virtual console keyboard mappings) # localectl set-x11-keymap LAYOUT [MODEL] [VARIANT] [OPTIONS] for a complete listing of all available x11-keymap layouts, models, variants and options use: # localectl list-x11-keymap-layouts # localectl list-x11-keymap-models # localectl list-x11-keymap-variants # localectl list-x11-keymap-options Now, say you want to set the system locale to: \"en_US.UTF-8\", enter: localectl set-locale LANG#en_US.UTF-8 To set the virtual console keyboard map to US, enter: localectl set-keymap us it Note here that you can enter a second keymap to define a toggle keyboard mapping. To set the system default keyboard mapping for X11, and define your model, variant, and some options, enter: localectl set-x11-keymap us apple mac_nodeadkeys numpad:pc So, in the above example the user has a Apple aluminum mac keyboard, no deadkeys, and a PC compatible numeric pad. --no-convert If set-keymap or set-x11-keymap is invoked and this option is passed then the keymap will not be converted from the console to X11, or X11 to console, respectively. It means that if this option is NOT passed to set-keymap, the selected setting is also applied to the default keyboard mapping of X11, after converting it to the closest matching X11 keyboard mapping, and vice versa. For a complete overview and list of all possible commands/options of localectl, please enter: # localectl --help or # man localectl","title":"localectl - - Control the system locale and keyboard layout settings"},{"location":"articles/systemd/#analyzing-and-performance","text":"","title":"analyzing and performance"},{"location":"articles/systemd/#analyzing-the-boot-process","text":"WARNING !!! Before actually trying to speedup the boot process, you really have to know what you are doing and how to revert your actions. When moving, disabling or masking service files without knowing why, the boot process can take even longer than before. systemd provides a tool called systemd-analyze that can be used to show timing details about the boot process, including an svg plot showing units waiting for their dependencies. You can see which unit files are causing your boot process to slow down. You can then optimize your system accordingly. To see how much time was spent in kernelspace and userspace on boot, simply use: systemd-analyze To list the started unit files, sorted by the time each of them took to start up: systemd-analyze blame At some points of the boot process, things can not proceed until a given unit succeeds. To see which units find themselves at these critical points in the startup chain, do: systemd-analyze critical-chain You can also create a SVG file which describes your boot process graphically, similiar to Bootchart: systemd-analyze plot plot.svg See man systemd-analyze for details.","title":"analyzing the boot process"},{"location":"articles/systemd/#analyzing-using-bootchart","text":"","title":"analyzing using bootchart"},{"location":"articles/systemd/#readahead","text":"Systemd comes with its own readahead implementation, this should in principle improve boot time. However, depending on your kernel version and the type of your hard drive, your mileage may vary (i.e. it might be slower). To enable, do: systemctl enable systemd-readahead-collect systemd-readahead-replay In order for the readahead to work, you should reboot a couple of times, because it needs to adapt to the changed boot process.","title":"readahead"},{"location":"articles/systemd/#filesystem-mounts","text":"If btrfs is in use for the root filesystem, there is no need for a fsck on every boot like other filesystems. If this is the case,you may want to mask the systemd-fsck-root.service systemd will still fsck any relevant filesystems with the systemd-fsck@.service You can also remove API filesystems from /etc/fstab, as systemd will mount them itself. It is not uncommon for users to have a /tmp and/or /dev/shm entry carried over from sysvinit, but you may have noticed that systemd already takes care of this. If you want to give /tmp a size, say: 4Gb., you can edit the file: nano -w /usr/lib/systemd/system/tmp.mount and add size#4096M to section: [Mount] : [Mount] What#tmpfs Where#/tmp Type#tmpfs Options#mode#1777,strictatime,size#4096M If on seperate partitions, other filesystems like /home and /boot can be mounted with custom mount units. Adding noauto,x-systemd.automount will buffer all access to that partition, and will fsck and mount it on first access, reducing the number of filesystems it must fsck/mount during the boot process. NOTE: this will make your /home and /boot filesystem type autofs, which is ignored by mlocate by default. If you use mlocate, and want /home and/or /boot still to be indexed by mlocate., edit the file: /etc/updatedb.conf }} and remove the entries from the \"PRUNEPATHS#\" \" : PRUNE_BIND_MOUNTS = \"yes\" PRUNEFS = \"9p afs anon_inodefs auto autofs bdev binfmt_misc cgroup cifs coda configfs cpuset cramfs debugfs devpts devtmpfs ecryptfs exofs ftpfs fuse fuse.enc$ PRUNENAMES = \".git .hg .svn\" PRUNEPATHS = \"/afs /media /mnt /home/home2 /net /sfs /tmp /udev /var/cache /var/lib/pacman/local /var/lock /var/run /var/spool /var/tmp\" The speedup of automounting /home /boot may not be more than a second or two, depending on your system, so this trick may not be worth it. nano -w /etc/fstab /dev/sda3 / ext4 noatime,defaults 1 1 /dev/sda1 /boot ext4 noatime,noauto,x-systemd.automount 1 2 /dev/sda2 /home ext4 noatime,noauto,x-systemd.automount 1 2 /dev/sda5 none swap sw 0 0","title":"filesystem mounts"},{"location":"articles/systemd/#debugging","text":"[http://freedesktop.org/wiki/Software/systemd/Debugging/ Debugging systemd Problems )]","title":"debugging"},{"location":"articles/systemd/#systemd-for-administrators","text":"All links mentioned here, will lead you outside this Wiki... [http://0pointer.de/blog/projects/changing-roots.html Changing Roots )] [http://0pointer.de/blog/projects/the-new-configuration-files The New Configuration Files )] [http://0pointer.de/blog/projects/instances.html Instantiated Services )] [http://0pointer.de/blog/projects/inetd.html Converting inetd Services )] [http://0pointer.de/blog/projects/systemd-for-admins-3.html Converting a SysVinit script into systemd service file )] [http://0pointer.de/blog/projects/security.html Securing Your Services )] [http://0pointer.de/blog/projects/watchdog.html Watchdogs )] [http://0pointer.de/blog/projects/serial-console.html *Gettys on Serial Consoles)] [http://0pointer.de/blog/projects/resources.html *Managing Resources)] [http://0pointer.de/blog/projects/detect-virt.html Detecting Virtualization )] [http://www.freedesktop.org/wiki/Software/systemd/APIFileSystems/ API File Systems )]","title":"systemd for Administrators"},{"location":"articles/systemd/#sysvinit-to-systemd-cheatcheet","text":"http://fedoraproject.org/wiki/SysVinit_to_Systemd_Cheatsheet","title":"SysVinit to systemd cheatcheet"},{"location":"articles/systemd/#systemd-index-list-of-all-manpages-from-the-systemd-project","text":"http://www.freedesktop.org/software/systemd/man/","title":"systemd -index \u2014 - List of all manpages from the systemd project"},{"location":"articles/user/","text":"Add a User To create a user that is a member of the wheel, users, and audio groups. As root: useradd -m -G users,wheel,audio -s /bin/bash UserName This will also create a shell and home directory for the UserName. After that, assign a password to the user account. As root: passwd UserName So to add the user wolfden I would run useradd -m -G users,wheel,audio -s /bin/bash wolfden passwd wolfden Type the password, as you type, it will not show any characters, retype password when it asks. To see what groups you belong to: groups or groups UserName Delete a User To remove a user along with home directory and mail spool, as root: userdel -r UserName Add an existing user to a group As root, run the command: gpasswd -a UserName wheel You can add a user to multiple groups at same time by running usermod -aG wheel,audio UserName Warning on the usermod, do not forget the -a or you will remove yourself from all existing groups and only belong to wheel and audio Remove user from group As root, run the command: gpasswd -d UserName audio Add a user to sudo As root, run the command visudo Than you need to uncomment a line ## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL Change it so it looks like ## Uncomment to allow members of group wheel to execute any command %wheel ALL=(ALL) ALL Save the file.","title":"User"},{"location":"articles/user/#add-a-user","text":"To create a user that is a member of the wheel, users, and audio groups. As root: useradd -m -G users,wheel,audio -s /bin/bash UserName This will also create a shell and home directory for the UserName. After that, assign a password to the user account. As root: passwd UserName So to add the user wolfden I would run useradd -m -G users,wheel,audio -s /bin/bash wolfden passwd wolfden Type the password, as you type, it will not show any characters, retype password when it asks. To see what groups you belong to: groups or groups UserName","title":"Add a User"},{"location":"articles/user/#delete-a-user","text":"To remove a user along with home directory and mail spool, as root: userdel -r UserName","title":"Delete a User"},{"location":"articles/user/#add-an-existing-user-to-a-group","text":"As root, run the command: gpasswd -a UserName wheel You can add a user to multiple groups at same time by running usermod -aG wheel,audio UserName Warning on the usermod, do not forget the -a or you will remove yourself from all existing groups and only belong to wheel and audio","title":"Add an existing user to a group"},{"location":"articles/user/#remove-user-from-group","text":"As root, run the command: gpasswd -d UserName audio","title":"Remove user from group"},{"location":"articles/user/#add-a-user-to-sudo","text":"As root, run the command visudo Than you need to uncomment a line ## Uncomment to allow members of group wheel to execute any command # %wheel ALL=(ALL) ALL Change it so it looks like ## Uncomment to allow members of group wheel to execute any command %wheel ALL=(ALL) ALL Save the file.","title":"Add a user to sudo"},{"location":"articles/wireguard/","text":"Wireguard WireGuard is a new, experimental VPN protocol that aims to offer a simpler, faster, and more secure solution for VPN tunneling than the existing VPN protocols. WireGuard has some major differences when compared to OpenVPN and IPSec, such as the code size (under 4,000 lines!), speed, and encryption standards. You can learn more about it here https://www.wireguard.com/ and https://restoreprivacy.com/wireguard/ Setting up Wireguard First you'll need to install wireguard as it hasn't been submitted to the mainline kernel yet. Then as you user (NOT ROOT) you'll want to generate your keys similar to generating Private an Public SSH keys. THis will need done both Server and Client(s) side. sudo equo install wireguard sudo modprobe wireguard mkdir .wireguard cd .wireguard wg genkey | tee privatekey | wg pubkey publickey Next, as root, you'll want to add your config for a wireguard interface # mkdir /etc/wireguard # touch /etc/wireguard/wg0.conf # nano /etc/wireguard/wg0.conf SERVER SIDE CONFIG You'll want to have you're PRIVATE key handy from ~/.wireguard/privatekey for the server and you'll want to have the connecting client's PUBLIC key as well. Also, due to wireguard not having a dynamic IP function, you'll need to enter static IPs. Enter the data as necessary like below: /etc/wireguard/wg0.conf [Interface] Address = 172.16.0.1 ListenPort = 51820 PrivateKey = {Your Server PRIVATE Key HERE} [Peer] PublicKey = {Your Client PUBLIC Key HERE} AllowedIPs = 172.16.0.2 Afterwards you'll want to connect to your wireless router and setup port-forwarding to send inbound communications on a port of your choice (51820 is fine) to the Reserved or Static IP of your server on port 51820. That is the default port, but can be changed to whatever you wish. If you have a Dynamic DNS, it will make your life a lot easier to reach your VPN. CLIENT SIDE CONFIG You'll want to have you're PRIVATE key handy from ~/.wireguard/privatekey for the Client and you'll want to have the connecting Servers's PUBLIC key as well. Also, due to wireguard not having a dynamic IP function, you'll need to enter static IPs. You can also add alternative DNS Addresses. Enter the data as necessary like below: /etc/wireguard/wg0.conf [Interface] Address = 172.16.0.2 DNS = 1.1.1.1 PrivateKey = {Your client PRIVATE Key HERE} [Peer] AllowedIPs = 0.0.0.0/0 Endpoint = {Your SERVER's External IP or Dynamic DNS Name}:51820 PersistentKeepalive = 25 PublicKey = {Your SERVER's PUBLIC Key HERE} Enabling your Wireguard Interface Systemd is used to enable/disable/start/stop all services. This includes your VPNs. sudo systemctl start wg-quick@wg0 View the systemd guide for more information on enabling upon boot, starting/stopping/restarting/disabling/etc. And there you have it! You have your own personal VPN using wireguard. As a side note, wireguard also has a free Android app so you can connect your new VPN to you phone. This makes you safe on those sketchy free wifi connections in stores and restuarants.","title":"Wireguard"},{"location":"articles/wireguard/#wireguard","text":"WireGuard is a new, experimental VPN protocol that aims to offer a simpler, faster, and more secure solution for VPN tunneling than the existing VPN protocols. WireGuard has some major differences when compared to OpenVPN and IPSec, such as the code size (under 4,000 lines!), speed, and encryption standards. You can learn more about it here https://www.wireguard.com/ and https://restoreprivacy.com/wireguard/","title":"Wireguard"},{"location":"articles/wireguard/#setting-up-wireguard","text":"First you'll need to install wireguard as it hasn't been submitted to the mainline kernel yet. Then as you user (NOT ROOT) you'll want to generate your keys similar to generating Private an Public SSH keys. THis will need done both Server and Client(s) side. sudo equo install wireguard sudo modprobe wireguard mkdir .wireguard cd .wireguard wg genkey | tee privatekey | wg pubkey publickey Next, as root, you'll want to add your config for a wireguard interface # mkdir /etc/wireguard # touch /etc/wireguard/wg0.conf # nano /etc/wireguard/wg0.conf","title":"Setting up Wireguard"},{"location":"articles/wireguard/#server-side-config","text":"You'll want to have you're PRIVATE key handy from ~/.wireguard/privatekey for the server and you'll want to have the connecting client's PUBLIC key as well. Also, due to wireguard not having a dynamic IP function, you'll need to enter static IPs. Enter the data as necessary like below: /etc/wireguard/wg0.conf [Interface] Address = 172.16.0.1 ListenPort = 51820 PrivateKey = {Your Server PRIVATE Key HERE} [Peer] PublicKey = {Your Client PUBLIC Key HERE} AllowedIPs = 172.16.0.2 Afterwards you'll want to connect to your wireless router and setup port-forwarding to send inbound communications on a port of your choice (51820 is fine) to the Reserved or Static IP of your server on port 51820. That is the default port, but can be changed to whatever you wish. If you have a Dynamic DNS, it will make your life a lot easier to reach your VPN.","title":"SERVER SIDE CONFIG"},{"location":"articles/wireguard/#client-side-config","text":"You'll want to have you're PRIVATE key handy from ~/.wireguard/privatekey for the Client and you'll want to have the connecting Servers's PUBLIC key as well. Also, due to wireguard not having a dynamic IP function, you'll need to enter static IPs. You can also add alternative DNS Addresses. Enter the data as necessary like below: /etc/wireguard/wg0.conf [Interface] Address = 172.16.0.2 DNS = 1.1.1.1 PrivateKey = {Your client PRIVATE Key HERE} [Peer] AllowedIPs = 0.0.0.0/0 Endpoint = {Your SERVER's External IP or Dynamic DNS Name}:51820 PersistentKeepalive = 25 PublicKey = {Your SERVER's PUBLIC Key HERE}","title":"CLIENT SIDE CONFIG"},{"location":"articles/wireguard/#enabling-your-wireguard-interface","text":"Systemd is used to enable/disable/start/stop all services. This includes your VPNs. sudo systemctl start wg-quick@wg0 View the systemd guide for more information on enabling upon boot, starting/stopping/restarting/disabling/etc. And there you have it! You have your own personal VPN using wireguard. As a side note, wireguard also has a free Android app so you can connect your new VPN to you phone. This makes you safe on those sketchy free wifi connections in stores and restuarants.","title":"Enabling your Wireguard Interface"}]}